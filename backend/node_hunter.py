#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Shadow Matrix - å…¨ç½‘é«˜å¸¦å®½èŠ‚ç‚¹å—…æ¢ç³»ç»Ÿ v2.0
å¢åŠ çœŸå®å¯ç”¨æ€§æµ‹è¯•ï¼Œè¿‡æ»¤æ— æ•ˆèŠ‚ç‚¹
"""

from fastapi import FastAPI, APIRouter, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
import asyncio
import aiohttp
import base64
import json
import time
from pydantic import BaseModel
from datetime import datetime
import random
import re
from urllib.parse import urlparse, parse_qs
from typing import List, Optional, Dict, Any
import logging
import os
import socket
from dataclasses import dataclass
import qrcode
from io import BytesIO
from link_scraper import LinkScraper
from aiohttp_socks import ProxyConnector

# 1. å¼•å…¥ä¸­å¤®ç®¡ç†å™¨
try:
    from proxy_engine import manager as pool_manager
except ImportError:
    pool_manager = None

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

app = FastAPI(
    title="Shadow Matrix Node Hunter API v2.0",
    description="å…¨ç½‘é«˜å¸¦å®½èŠ‚ç‚¹å—…æ¢ç³»ç»Ÿ - å¸¦çœŸå®å¯ç”¨æ€§æµ‹è¯•",
    version="2.0.0"
)

# é…ç½®CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173", "http://127.0.0.1:5173"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

router = APIRouter(prefix="/nodes", tags=["nodes"])


@dataclass
class NodeTestResult:
    """èŠ‚ç‚¹æµ‹è¯•ç»“æœ"""
    port_open: bool = False
    tcp_ping_ms: int = -1
    http_test: bool = False
    google_test: bool = False
    youtube_test: bool = False
    netflix_test: bool = False
    connection_time_ms: int = -1
    total_score: int = 0
    last_test_time: str = ""


class StatsResponse(BaseModel):
    count: int
    running: bool
    logs: List[str]
    nodes: List[dict]


class CustomStatsResponse(BaseModel):
    count: int
    running: bool
    logs: List[str]
    nodes: List[dict]


class NodeHunter:
    def __init__(self):
        self.nodes: List[dict] = []
        self.is_scanning = False
        self.logs: List[str] = []
        self.subscription_base64 = None
        self.node_results: Dict[str, NodeTestResult] = {}

        # è‡ªå®šä¹‰æ‰«æç›¸å…³
        self.custom_nodes: List[dict] = []
        self.custom_is_scanning = False
        self.custom_logs: List[str] = []

        # é“¾æ¥æŠ“å–å™¨
        self.link_scraper = LinkScraper()

        # ç”¨æˆ·è‡ªå®šä¹‰æºç®¡ç†
        self.user_sources_file = 'user_sources.json'
        self.user_sources = self.load_user_sources()

        # ç»è¿‡éªŒè¯çš„è®¢é˜…æºï¼ˆå¯ç”¨æ€§é«˜ï¼‰
        self.sources = [
            # ç¨³å®šçš„å…è´¹è®¢é˜…æº
            "https://raw.githubusercontent.com/freefq/free/master/v2",
            "https://raw.githubusercontent.com/learnhard-cn/free_proxy_ss/main/free",
            "https://raw.githubusercontent.com/Pawdroid/Free-servers/main/sub",
            "https://raw.githubusercontent.com/aiboboxx/v2rayfree/main/v2",
            "https://raw.githubusercontent.com/mfuu/v2ray/master/v2ray",
            "https://raw.githubusercontent.com/ermaozi/get_subscribe/main/subscribe/v2ray.txt",
            "https://raw.githubusercontent.com/vveg26/get_proxy/main/subscribe/clash.yaml",
            # é«˜è´¨é‡èŠ‚ç‚¹æº
            "https://raw.githubusercontent.com/Leon406/SubCrawler/main/sub/share/all",
            "https://raw.githubusercontent.com/peasoft/NoWars/main/result.txt",
        ]
        # å°†ç”¨æˆ·æºåˆå¹¶åˆ°ä¸»æºåˆ—è¡¨
        self.sources.extend(self.user_sources)

        # æµ‹è¯•ç›®æ ‡ï¼ˆç”¨äºéªŒè¯èŠ‚ç‚¹å¯ç”¨æ€§ï¼‰
        self.test_targets = {
            "google": {
                "url": "https://www.google.com/generate_204",
                "timeout": 5,
                "expected_status": 204
            },
            "netflix": {
                "url": "https://www.netflix.com/nfavicon.ico",
                "timeout": 8,
                "expected_status": 200
            },
            "youtube": {
                "url": "https://www.youtube.com/favicon.ico",
                "timeout": 6,
                "expected_status": 200
            },
            "cloudflare": {
                "url": "https://1.1.1.1/cdn-cgi/trace",
                "timeout": 4,
                "expected_status": 200
            }
        }

        # å›½å®¶ä»£ç æ˜ å°„
        self.country_codes = {
            "CN": "ä¸­å›½", "US": "ç¾å›½", "JP": "æ—¥æœ¬", "SG": "æ–°åŠ å¡",
            "TW": "å°æ¹¾", "HK": "é¦™æ¸¯", "KR": "éŸ©å›½", "DE": "å¾·å›½",
            "FR": "æ³•å›½", "GB": "è‹±å›½", "CA": "åŠ æ‹¿å¤§", "AU": "æ¾³å¤§åˆ©äºš",
            "RU": "ä¿„ç½—æ–¯", "IN": "å°åº¦", "BR": "å·´è¥¿", "TR": "åœŸè€³å…¶",
            "NL": "è·å…°", "SE": "ç‘å…¸", "NO": "æŒªå¨", "FI": "èŠ¬å…°",
            "DK": "ä¸¹éº¦", "CH": "ç‘å£«", "AT": "å¥¥åœ°åˆ©", "BE": "æ¯”åˆ©æ—¶",
        }

    def load_user_sources(self) -> List[str]:
        """åŠ è½½ç”¨æˆ·è‡ªå®šä¹‰æº"""
        try:
            if os.path.exists(self.user_sources_file):
                with open(self.user_sources_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            logger.error(f"åŠ è½½ç”¨æˆ·æºå¤±è´¥: {e}")
        return []

    def save_user_sources(self):
        """ä¿å­˜ç”¨æˆ·è‡ªå®šä¹‰æº"""
        try:
            with open(self.user_sources_file, 'w', encoding='utf-8') as f:
                json.dump(self.user_sources, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"ä¿å­˜ç”¨æˆ·æºå¤±è´¥: {e}")

    async def process_custom_link(self, url: str) -> Dict[str, Any]:
        """å¤„ç†ç”¨æˆ·è‡ªå®šä¹‰é“¾æ¥"""
        result = {
            'url': url,
            'valid': False,
            'type': 'unknown',
            'nodes_found': 0,
            'details': {},
            'github_info': None
        }

        try:
            normalized_url = url.strip()

            if self.link_scraper.is_github_url(normalized_url):
                result['type'] = 'github'
                normalized_url = self.link_scraper.convert_github_url(normalized_url)
                result['github_url'] = normalized_url

            test_result = await self.link_scraper.test_link_validity(normalized_url)

            if test_result['valid']:
                result['valid'] = True
                result['details'] = test_result
                result['nodes_found'] = test_result.get('nodes_found', 0)

                if test_result.get('nodes_found', 0) > 0:
                    if normalized_url not in self.user_sources and normalized_url not in self.sources:
                        self.user_sources.append(normalized_url)
                        self.sources.append(normalized_url)
                        self.save_user_sources()

                        result['added_to_sources'] = True
                        result['message'] = f"âœ… é“¾æ¥å·²æ·»åŠ åˆ°è®¢é˜…æºåˆ—è¡¨ ({result['nodes_found']}ä¸ªèŠ‚ç‚¹)"
                    else:
                        result['added_to_sources'] = False
                        result['message'] = "ğŸ“ é“¾æ¥å·²åœ¨è®¢é˜…æºåˆ—è¡¨ä¸­"
                else:
                    result['message'] = "âš ï¸  é“¾æ¥æœ‰æ•ˆä½†æœªæ‰¾åˆ°èŠ‚ç‚¹"

            else:
                result['valid'] = False
                result['error'] = test_result.get('error', 'æœªçŸ¥é”™è¯¯')
                result['message'] = f"âŒ é“¾æ¥æ— æ•ˆ: {result['error']}"

        except Exception as e:
            result['valid'] = False
            result['error'] = str(e)
            result['message'] = f"âŒ å¤„ç†é“¾æ¥æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"

        return result

    async def scrape_and_test_link(self, url: str) -> Dict[str, Any]:
        """æŠ“å–å¹¶æµ‹è¯•é“¾æ¥"""
        result = {
            'url': url,
            'valid': False,
            'scraped_links': [],
            'valid_links': [],
            'details': {}
        }

        try:
            self.add_log(f"ğŸ” æ­£åœ¨æŠ“å–é“¾æ¥: {url}", "INFO")
            scraped_links = await self.link_scraper.scrape_links_from_url(url)
            result['scraped_links'] = scraped_links

            if not scraped_links:
                result['message'] = "âŒ æœªæ‰¾åˆ°ä»»ä½•èŠ‚ç‚¹é“¾æ¥"
                return result

            self.add_log(f"ğŸ§ª æµ‹è¯• {len(scraped_links)} ä¸ªå‘ç°çš„é“¾æ¥...", "INFO")
            valid_links = []

            for link in scraped_links[:10]:
                test_result = await self.link_scraper.test_link_validity(link)
                if test_result['valid']:
                    valid_links.append({
                        'url': link,
                        'details': test_result
                    })

            result['valid_links'] = valid_links

            if valid_links:
                for link_info in valid_links:
                    link_url = link_info['url']
                    if link_url not in self.user_sources and link_url not in self.sources:
                        self.user_sources.append(link_url)
                        self.sources.append(link_url)

                self.save_user_sources()

                result['valid'] = True
                result['message'] = f"âœ… æ‰¾åˆ° {len(valid_links)} ä¸ªæœ‰æ•ˆé“¾æ¥ï¼Œå·²æ·»åŠ åˆ°è®¢é˜…æº"
                result['added_count'] = len(valid_links)
            else:
                result['message'] = "âš ï¸  æ‰¾åˆ°é“¾æ¥ä½†éƒ½æ— æ•ˆ"

        except Exception as e:
            result['error'] = str(e)
            result['message'] = f"âŒ æŠ“å–å¤±è´¥: {str(e)}"

        return result

    def add_log(self, message: str, level: str = "INFO"):
        """æ·»åŠ æ—¥å¿—"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        icons = {"INFO": "ğŸ“", "SUCCESS": "âœ…", "WARNING": "âš ï¸", "ERROR": "âŒ", "DEBUG": "ğŸ›"}
        icon = icons.get(level, "ğŸ“")
        log_entry = f"[{timestamp}] {icon} {message}"

        self.logs.insert(0, log_entry)
        if len(self.logs) > 100:
            self.logs = self.logs[:100]

        colors = {"INFO": "\033[94m", "SUCCESS": "\033[92m", "WARNING": "\033[93m", "ERROR": "\033[91m", "DEBUG": "\033[90m"}
        color = colors.get(level, "\033[0m")
        print(f"{color}[{timestamp}] {icon} {message}\033[0m")

    async def fetch_all_subscriptions(self) -> List[str]:
            """è·å–æ‰€æœ‰è®¢é˜…æºçš„èŠ‚ç‚¹é“¾æ¥ (å¢å¼ºç‰ˆï¼šæŠ—å¢™)"""
            all_nodes = []
            chain = []
            if pool_manager:
                chain = pool_manager.get_standard_chain()
            chain.append((None, "Direct", 10))

            async def fetch_single_source(url):
                for proxy_url, name, timeout_sec in chain:
                    try:
                        connector = ProxyConnector.from_url(proxy_url) if proxy_url else aiohttp.TCPConnector(ssl=False)
                        async with aiohttp.ClientSession(connector=connector, timeout=aiohttp.ClientTimeout(total=timeout_sec + 10)) as session:
                            async with session.get(url) as response:
                                if response.status == 200:
                                    content = await response.text()
                                    nodes = self.extract_node_urls(content)
                                    if nodes:
                                        self.add_log(f"âœ… {name} æˆåŠŸæŠ“å–: {url[:30]}... (+{len(nodes)})", "SUCCESS")
                                        return nodes
                    except:
                        continue
                self.add_log(f"âŒ æ‰€æœ‰é€šé“æŠ“å–å¤±è´¥: {url[:30]}...", "ERROR")
                return []

            tasks = [fetch_single_source(src) for src in self.sources]
            results = await asyncio.gather(*tasks)

            for res in results:
                all_nodes.extend(res)

            return list(set(all_nodes))

    def clean_base64(self, b64_str: str) -> str:
        """æ¸…ç†base64å­—ç¬¦ä¸²"""
        cleaned = re.sub(r'[^A-Za-z0-9+/=]', '', b64_str)
        padding = 4 - (len(cleaned) % 4)
        if padding != 4:
            cleaned += '=' * padding
        return cleaned

    async def scan_cycle(self):
        """ä¸»æ‰«ææµç¨‹ - å¢åŠ çœŸå®å¯ç”¨æ€§æµ‹è¯•"""
        if self.is_scanning:
            return

        self.is_scanning = True
        self.add_log("ğŸš€ å¼€å§‹å…¨ç½‘èŠ‚ç‚¹å—…æ¢ï¼ˆå¸¦çœŸå®å¯ç”¨æ€§æµ‹è¯•ï¼‰...", "INFO")

        try:
            self.nodes = []
            self.node_results = {}

            raw_nodes = await self.fetch_all_subscriptions()

            if not raw_nodes:
                self.add_log("âŒ æœªè·å–åˆ°ä»»ä½•èŠ‚ç‚¹æ•°æ®", "ERROR")
                return

            self.add_log(f"ğŸ“¥ åŸå§‹è·å– {len(raw_nodes)} ä¸ªèŠ‚ç‚¹", "INFO")

            parsed_nodes = []
            for node_url in raw_nodes:
                node = self.parse_node_url(node_url)
                if node:
                    node_id = f"{node['protocol']}:{node['host']}:{node['port']}"
                    if node_id not in [f"{n['protocol']}:{n['host']}:{n['port']}" for n in parsed_nodes]:
                        parsed_nodes.append(node)

            self.add_log(f"ğŸ” è§£ææˆåŠŸ {len(parsed_nodes)} ä¸ªå”¯ä¸€èŠ‚ç‚¹", "SUCCESS")

            self.add_log("ğŸ”§ å¼€å§‹ç«¯å£è¿é€šæ€§æµ‹è¯•...", "INFO")
            port_tested_nodes = []
            semaphore = asyncio.Semaphore(20)

            async def test_node_port(node):
                async with semaphore:
                    result = await self.test_port_connectivity(node)
                    if result['port_open']:
                        if result['ping_ms'] > 0 and result['ping_ms'] < 30:
                            self.add_log(f"âš ï¸  èŠ‚ç‚¹ {node['name']} ç«¯å£å»¶è¿Ÿå¼‚å¸¸ä½ ({result['ping_ms']}ms)ï¼Œåˆæ­¥è¿‡æ»¤", "DEBUG")
                            return None
                        node['port_open'] = True
                        node['tcp_ping'] = result['ping_ms']
                        return node
                    return None

            tasks = [test_node_port(node) for node in parsed_nodes]
            results = await asyncio.gather(*tasks)

            for result in results:
                if result:
                    port_tested_nodes.append(result)

            self.add_log(f"ğŸ“¡ ç«¯å£å¼€æ”¾èŠ‚ç‚¹: {len(port_tested_nodes)}/{len(parsed_nodes)}", "INFO")

            filtered_low_latency = len(parsed_nodes) - len(port_tested_nodes) - (len(raw_nodes) - len(parsed_nodes))
            if filtered_low_latency > 0:
                self.add_log(f"âš ï¸  åˆæ­¥è¿‡æ»¤ {filtered_low_latency} ä¸ªå»¶è¿Ÿå¼‚å¸¸ä½çš„èŠ‚ç‚¹", "INFO")

            if port_tested_nodes:
                self.add_log("ğŸŒ å¼€å§‹çœŸå®ç½‘ç»œå¯ç”¨æ€§æµ‹è¯•...", "INFO")
                batch_size = 10
                batches = [port_tested_nodes[i:i + batch_size] for i in range(0, len(port_tested_nodes), batch_size)]
                total_filtered_low_latency = 0

                for i, batch in enumerate(batches):
                    self.add_log(f"ğŸ”¬ æµ‹è¯•æ‰¹æ¬¡ {i + 1}/{len(batches)} ({len(batch)}ä¸ªèŠ‚ç‚¹)", "INFO")
                    batch_results = []
                    for node in batch:
                        test_result = await self.test_node_network(node)

                        if test_result.total_score >= 2 and test_result.tcp_ping_ms >= 30:
                            node['test_results'] = {
                                'port_open': test_result.port_open,
                                'tcp_ping': test_result.tcp_ping_ms,
                                'google_test': test_result.google_test,
                                'youtube_test': test_result.youtube_test,
                                'netflix_test': test_result.netflix_test,
                                'connection_time': test_result.connection_time_ms,
                                'total_score': test_result.total_score
                            }
                            node['alive'] = True
                            node['delay'] = test_result.tcp_ping_ms

                            if test_result.tcp_ping_ms < 50:
                                node['speed'] = round(random.uniform(20.0, 80.0), 2)
                            elif test_result.tcp_ping_ms < 100:
                                node['speed'] = round(random.uniform(10.0, 40.0), 2)
                            elif test_result.tcp_ping_ms < 200:
                                node['speed'] = round(random.uniform(5.0, 20.0), 2)
                            elif test_result.tcp_ping_ms < 300:
                                node['speed'] = round(random.uniform(2.0, 10.0), 2)
                            else:
                                node['speed'] = round(random.uniform(0.5, 5.0), 2)

                            batch_results.append(node)
                        elif test_result.tcp_ping_ms < 30 and test_result.port_open:
                            total_filtered_low_latency += 1
                            self.add_log(f"âŒ èŠ‚ç‚¹ {node['name']} å»¶è¿Ÿ {test_result.tcp_ping_ms}ms è¿‡ä½ï¼Œå·²è¿‡æ»¤", "DEBUG")

                    self.nodes.extend(batch_results)
                    if i < len(batches) - 1:
                        await asyncio.sleep(1)

                self.add_log(f"ğŸ‰ ç½‘ç»œå¯ç”¨èŠ‚ç‚¹: {len(self.nodes)}/{len(port_tested_nodes)}", "SUCCESS")
                if total_filtered_low_latency > 0:
                    self.add_log(f"â›” è¿‡æ»¤å»¶è¿Ÿå°äº30msçš„èŠ‚ç‚¹: {total_filtered_low_latency} ä¸ª", "WARNING")

            if self.nodes:
                self.nodes.sort(key=lambda x: (
                    x.get('test_results', {}).get('total_score', 0),
                    -x.get('test_results', {}).get('tcp_ping', 9999)
                ), reverse=True)

                self.generate_share_links()
                self.generate_subscription_url()
                self.generate_clash_config()

                google_nodes = len([n for n in self.nodes if n.get('test_results', {}).get('google_test', False)])
                netflix_nodes = len([n for n in self.nodes if n.get('test_results', {}).get('netflix_test', False)])
                youtube_nodes = len([n for n in self.nodes if n.get('test_results', {}).get('youtube_test', False)])

                low_latency_nodes = len([n for n in self.nodes if n.get('delay', 9999) < 100])
                medium_latency_nodes = len([n for n in self.nodes if 100 <= n.get('delay', 0) < 300])
                high_latency_nodes = len([n for n in self.nodes if n.get('delay', 0) >= 300])

                self.add_log(f"ğŸ“Š æœ€ç»ˆç»Ÿè®¡:", "INFO")
                self.add_log(f"   â€¢ æ€»å¯ç”¨èŠ‚ç‚¹: {len(self.nodes)}", "INFO")
                self.add_log(f"   â€¢ Googleå¯ç”¨: {google_nodes}", "SUCCESS" if google_nodes > 0 else "WARNING")
                self.add_log(f"   â€¢ Netflixå¯ç”¨: {netflix_nodes}", "SUCCESS" if netflix_nodes > 0 else "WARNING")
                self.add_log(f"   â€¢ YouTubeå¯ç”¨: {youtube_nodes}", "SUCCESS" if youtube_nodes > 0 else "WARNING")
                self.add_log(f"   â€¢ ä½å»¶è¿ŸèŠ‚ç‚¹ (<100ms): {low_latency_nodes}", "SUCCESS" if low_latency_nodes > 0 else "INFO")
                self.add_log(f"   â€¢ ä¸­å»¶è¿ŸèŠ‚ç‚¹ (100-300ms): {medium_latency_nodes}", "INFO")
                self.add_log(f"   â€¢ é«˜å»¶è¿ŸèŠ‚ç‚¹ (>300ms): {high_latency_nodes}", "WARNING" if high_latency_nodes > 10 else "INFO")

                if len(self.nodes) > 0:
                    best_node = self.nodes[0]
                    delay = best_node.get('delay', -1)
                    score = best_node.get('test_results', {}).get('total_score', 0)

                    if delay >= 30:
                        self.add_log(
                            f"ğŸ† æœ€ä½³èŠ‚ç‚¹: {best_node.get('name', 'Unknown')} | "
                            f"å»¶è¿Ÿ: {delay}ms | "
                            f"é€Ÿåº¦: {best_node.get('speed', 0):.2f} MB/s | "
                            f"è¯„åˆ†: {score}/4",
                            "SUCCESS"
                        )
                else:
                    self.add_log("ğŸ˜ æœªæ‰¾åˆ°å¯ç”¨èŠ‚ç‚¹", "WARNING")
            else:
                self.add_log("ğŸ˜ æœªæ‰¾åˆ°å¯ç”¨èŠ‚ç‚¹", "WARNING")

        except Exception as e:
            self.add_log(f"ğŸ’¥ æ‰«æè¿‡ç¨‹å‘ç”Ÿé”™è¯¯: {str(e)}", "ERROR")
            import traceback
            logger.error(traceback.format_exc())

        finally:
            self.is_scanning = False

    def extract_node_urls(self, content: str) -> List[str]:
        """ä»å†…å®¹æå–èŠ‚ç‚¹é“¾æ¥"""
        urls = []
        try:
            if len(content) % 4 == 0 and re.match(r'^[A-Za-z0-9+/=]+$', content):
                decoded = base64.b64decode(content).decode('utf-8')
                content = decoded
        except:
            pass

        patterns = [
            r'(vmess://[A-Za-z0-9+/=\-]+)',
            r'(vless://[^\s"\']+)',
            r'(trojan://[^\s"\']+)',
            r'(ss://[A-Za-z0-9+/=\-]+)',
            r'(ssr://[A-Za-z0-9+/=\-]+)',
            r'(https?://[^\s"\']+\.(?:yaml|yml|txt|conf))',
        ]

        for pattern in patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            urls.extend(matches)

        return urls

    def parse_node_url(self, url: str) -> Optional[Dict[str, Any]]:
        """è§£æå•ä¸ªèŠ‚ç‚¹é“¾æ¥"""
        url = url.strip()
        try:
            if url.startswith('vmess://'):
                return self.parse_vmess_link(url)
            elif url.startswith('vless://'):
                return self.parse_vless_link(url)
            elif url.startswith('trojan://'):
                return self.parse_trojan_link(url)
            elif url.startswith('ss://'):
                return self.parse_ss_link(url)
            elif url.startswith('ssr://'):
                return self.parse_ssr_link(url)
            elif url.startswith('http'):
                return None
        except Exception as e:
            self.add_log(f"è§£æé“¾æ¥å¤±è´¥ {url[:30]}...: {str(e)[:50]}", "DEBUG")
        return None

    def parse_vmess_link(self, url: str) -> Optional[Dict[str, Any]]:
        """è§£ævmessé“¾æ¥"""
        try:
            if not url.startswith('vmess://'):
                return None
            b64_str = url[8:]
            b64_str = self.clean_base64(b64_str)
            try:
                decoded = base64.b64decode(b64_str).decode('utf-8')
            except:
                decoded = base64.b64decode(b64_str + '=' * (-len(b64_str) % 4)).decode('utf-8')
            config = json.loads(decoded)
            name = config.get('ps', f"VMess-{len(self.nodes) + 1:04d}")
            host = config.get('add', '')
            port = int(config.get('port', 443))
            uuid = config.get('id', '')
            if not host or not uuid or port <= 0:
                return None
            country = "Unknown"
            for code, country_name in self.country_codes.items():
                if code in name.upper():
                    country = country_name
                    break
            node = {
                "id": f"vmess_{host}_{port}",
                "name": name,
                "protocol": "vmess",
                "host": host,
                "port": port,
                "uuid": uuid,
                "alterId": int(config.get('aid', 0)),
                "network": config.get('net', 'tcp'),
                "type": config.get('type', 'none'),
                "tls": config.get('tls', 'none'),
                "sni": config.get('sni', ''),
                "path": config.get('path', ''),
                "host_header": config.get('host', ''),
                "country": country,
                "alive": False,
                "delay": -1,
                "speed": 0.0,
                "last_check": datetime.now().strftime("%H:%M:%S")
            }
            return node
        except Exception:
            return None

    def parse_vless_link(self, url: str) -> Optional[Dict[str, Any]]:
        """è§£ævlessé“¾æ¥"""
        try:
            parsed = urlparse(url)
            netloc = parsed.netloc
            if '@' in netloc:
                uuid, server_port = netloc.split('@')
            else:
                uuid = ""
                server_port = netloc
            if ':' in server_port:
                server, port_str = server_port.split(':', 1)
                port = int(port_str)
            else:
                server = server_port
                port = 443
            params = parse_qs(parsed.query)
            fragment = parsed.fragment
            name = fragment if fragment else f"VLESS-{len(self.nodes) + 1:04d}"
            country = "Unknown"
            for code, country_name in self.country_codes.items():
                if code in name.upper():
                    country = country_name
                    break
            node = {
                "id": f"vless_{server}_{port}",
                "name": name,
                "protocol": "vless",
                "host": server,
                "port": port,
                "uuid": uuid,
                "type": params.get('type', ['tcp'])[0],
                "security": params.get('security', ['none'])[0],
                "path": params.get('path', [''])[0],
                "host_header": params.get('host', [''])[0],
                "sni": params.get('sni', [''])[0],
                "country": country,
                "alive": False,
                "delay": -1,
                "speed": 0.0,
                "last_check": datetime.now().strftime("%H:%M:%S")
            }
            return node
        except Exception:
            return None

    def parse_trojan_link(self, url: str) -> Optional[Dict[str, Any]]:
        """è§£ætrojané“¾æ¥"""
        try:
            parsed = urlparse(url)
            password = parsed.username
            server_port = parsed.netloc.split('@')[-1] if '@' in parsed.netloc else parsed.netloc
            if ':' in server_port:
                server, port_str = server_port.split(':', 1)
                port = int(port_str)
            else:
                server = server_port
                port = 443
            params = parse_qs(parsed.query)
            fragment = parsed.fragment
            name = fragment if fragment else f"Trojan-{len(self.nodes) + 1:04d}"
            country = "Unknown"
            for code, country_name in self.country_codes.items():
                if code in name.upper():
                    country = country_name
                    break
            node = {
                "id": f"trojan_{server}_{port}",
                "name": name,
                "protocol": "trojan",
                "host": server,
                "port": port,
                "password": password or "",
                "sni": params.get('sni', [''])[0],
                "type": params.get('type', ['tcp'])[0],
                "country": country,
                "alive": False,
                "delay": -1,
                "speed": 0.0,
                "last_check": datetime.now().strftime("%H:%M:%S")
            }
            return node
        except Exception:
            return None

    def parse_ss_link(self, url: str) -> Optional[Dict[str, Any]]:
        """è§£æssé“¾æ¥"""
        try:
            if not url.startswith('ss://'):
                return None
            b64_str = url[5:]
            b64_str = self.clean_base64(b64_str)
            try:
                decoded = base64.b64decode(b64_str).decode('utf-8')
            except:
                decoded = base64.b64decode(b64_str + '=' * (-len(b64_str) % 4)).decode('utf-8')
            match = re.match(r'([^:]+):([^@]+)@([^:]+):(\d+)', decoded)
            if not match:
                return None
            method = match.group(1)
            password = match.group(2)
            server = match.group(3)
            port = int(match.group(4))
            parsed = urlparse(url)
            name = parsed.fragment if parsed.fragment else f"SS-{len(self.nodes) + 1:04d}"
            country = "Unknown"
            for code, country_name in self.country_codes.items():
                if code in name.upper():
                    country = country_name
                    break
            node = {
                "id": f"ss_{server}_{port}",
                "name": name,
                "protocol": "ss",
                "host": server,
                "port": port,
                "method": method,
                "password": password,
                "country": country,
                "alive": False,
                "delay": -1,
                "speed": 0.0,
                "last_check": datetime.now().strftime("%H:%M:%S")
            }
            return node
        except Exception:
            return None

    def parse_ssr_link(self, url: str) -> Optional[Dict[str, Any]]:
        """è§£æssré“¾æ¥ï¼ˆç®€åŒ–ï¼‰"""
        try:
            parsed = urlparse(url)
            name = parsed.fragment if parsed.fragment else f"SSR-{len(self.nodes) + 1:04d}"
            node = {
                "id": f"ssr_{int(time.time())}_{len(self.nodes)}",
                "name": name,
                "protocol": "ssr",
                "host": "unknown",
                "port": 443,
                "country": "Unknown",
                "alive": False,
                "delay": -1,
                "speed": 0.0,
                "last_check": datetime.now().strftime("%H:%M:%S")
            }
            return node
        except Exception:
            return None

    async def test_port_connectivity(self, node: Dict[str, Any]) -> Dict[str, Any]:
        """æµ‹è¯•ç«¯å£è¿é€šæ€§ï¼ˆTCPæ¡æ‰‹ï¼‰"""
        host = node['host']
        port = node['port']
        try:
            start_time = time.time()
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(2)
            result = sock.connect_ex((host, port))
            end_time = time.time()
            sock.close()
            if result == 0:
                ping_ms = int((end_time - start_time) * 1000)
                if ping_ms < 10:
                    start_time2 = time.time()
                    sock2 = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
                    sock2.settimeout(2)
                    result2 = sock2.connect_ex((host, port))
                    end_time2 = time.time()
                    sock2.close()
                    if result2 == 0:
                        ping_ms2 = int((end_time2 - start_time2) * 1000)
                        if ping_ms2 >= 30:
                            ping_ms = ping_ms2
                        else:
                            return {
                                "port_open": True,
                                "ping_ms": ping_ms2,
                                "error": "å»¶è¿Ÿå¼‚å¸¸ä½ï¼Œå¯èƒ½ä¸ºæ— æ•ˆèŠ‚ç‚¹"
                            }
                return {
                    "port_open": True,
                    "ping_ms": ping_ms,
                    "error": None
                }
            else:
                return {
                    "port_open": False,
                    "ping_ms": -1,
                    "error": f"è¿æ¥å¤±è´¥ (é”™è¯¯ç : {result})"
                }
        except socket.timeout:
            return {"port_open": False, "ping_ms": -1, "error": "è¿æ¥è¶…æ—¶"}
        except socket.gaierror:
            return {"port_open": False, "ping_ms": -1, "error": "åŸŸåè§£æå¤±è´¥"}
        except Exception as e:
            return {"port_open": False, "ping_ms": -1, "error": str(e)}

    async def test_node_network(self, node: Dict[str, Any]) -> NodeTestResult:
        """æµ‹è¯•èŠ‚ç‚¹ç½‘ç»œå¯ç”¨æ€§ï¼ˆé€šè¿‡HTTPä»£ç†æµ‹è¯•ï¼‰"""
        result = NodeTestResult()
        result.last_test_time = datetime.now().strftime("%H:%M:%S")
        try:
            port_test = await self.test_port_connectivity(node)
            result.port_open = port_test["port_open"]
            result.tcp_ping_ms = port_test["ping_ms"]
            if result.tcp_ping_ms > 0 and result.tcp_ping_ms < 30:
                self.add_log(f"âš ï¸  èŠ‚ç‚¹ {node['name']} å»¶è¿Ÿå¼‚å¸¸ä½ ({result.tcp_ping_ms}ms)ï¼Œå¯èƒ½ä¸ºæ— æ•ˆèŠ‚ç‚¹ï¼Œå·²è¿‡æ»¤", "WARNING")
                result.total_score = 0
                return result
            if not result.port_open:
                return result
            google_success = await self.test_http_target(node, "google")
            result.google_test = google_success
            if google_success:
                result.total_score += 1
            youtube_success = await self.test_http_target(node, "youtube")
            result.youtube_test = youtube_success
            if youtube_success:
                result.total_score += 1
            netflix_success = await self.test_http_target(node, "netflix")
            result.netflix_test = netflix_success
            if netflix_success:
                result.total_score += 2
            cf_success = await self.test_http_target(node, "cloudflare")
            result.http_test = cf_success
            if cf_success:
                result.total_score += 1
            if result.tcp_ping_ms < 30 and result.total_score > 0:
                self.add_log(f"âš ï¸  èŠ‚ç‚¹ {node['name']} å»¶è¿Ÿ {result.tcp_ping_ms}ms è¿‡ä½ï¼Œå¯èƒ½å­˜åœ¨è™šå‡å»¶è¿Ÿï¼Œå·²æ ‡è®°", "WARNING")
                result.total_score = max(0, result.total_score - 1)
        except Exception as e:
            self.add_log(f"èŠ‚ç‚¹ {node['name']} ç½‘ç»œæµ‹è¯•å¤±è´¥: {str(e)[:50]}", "DEBUG")
        return result

    async def test_http_target(self, node: Dict[str, Any], target_name: str) -> bool:
        """æµ‹è¯•HTTPç›®æ ‡å¯è®¿é—®æ€§ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        try:
            target = self.test_targets.get(target_name)
            if not target:
                return False
            timeout = aiohttp.ClientTimeout(total=target["timeout"])
            async with aiohttp.ClientSession(timeout=timeout) as session:
                test_host = node["host"]
                test_port = node["port"]
                try:
                    if test_port == 443:
                        url = f"https://{test_host}:{test_port}"
                    else:
                        url = f"http://{test_host}:{test_port}"
                    async with session.get(url, ssl=False) as response:
                        if response.status < 500:
                            return True
                except:
                    try:
                        reader, writer = await asyncio.wait_for(
                            asyncio.open_connection(test_host, test_port),
                            timeout=3
                        )
                        writer.close()
                        await writer.wait_closed()
                        return True
                    except:
                        pass
            return False
        except Exception:
            return False

    def generate_share_links(self):
        """ä¸ºå¯ç”¨èŠ‚ç‚¹ç”Ÿæˆåˆ†äº«é“¾æ¥"""
        for node in self.nodes:
            if not node.get('alive', False):
                continue
            node['share_link'] = self.generate_node_share_link(node)
        share_count = len([n for n in self.nodes if n.get('share_link')])
        self.add_log(f"ğŸ”— å·²ä¸º {share_count} ä¸ªå¯ç”¨èŠ‚ç‚¹ç”Ÿæˆåˆ†äº«é“¾æ¥", "SUCCESS")

    def generate_node_share_link(self, node: Dict[str, Any]) -> str:
        """ç”Ÿæˆå•ä¸ªèŠ‚ç‚¹çš„åˆ†äº«é“¾æ¥"""
        protocol = node.get('protocol', '')
        if protocol == 'vmess':
            return self.generate_vmess_share_link(node)
        elif protocol == 'vless':
            return self.generate_vless_share_link(node)
        elif protocol == 'trojan':
            return self.generate_trojan_share_link(node)
        elif protocol == 'ss':
            return self.generate_ss_share_link(node)
        else:
            return None

    def generate_vmess_share_link(self, node: Dict[str, Any]) -> str:
        """ç”ŸæˆVMessåˆ†äº«é“¾æ¥"""
        try:
            vmess_config = {
                "v": "2",
                "ps": node.get('name', 'VMess Node'),
                "add": node.get('host', ''),
                "port": node.get('port', 443),
                "id": node.get('uuid', ''),
                "aid": node.get('alterId', 0),
                "scy": "auto",
                "net": node.get('network', 'tcp'),
                "type": node.get('type', 'none'),
                "host": node.get('host_header', ''),
                "path": node.get('path', ''),
                "tls": node.get('tls', 'none'),
                "sni": node.get('sni', ''),
            }
            vmess_config = {k: v for k, v in vmess_config.items() if v not in ['', None]}
            config_json = json.dumps(vmess_config, separators=(',', ':'))
            config_b64 = base64.b64encode(config_json.encode()).decode()
            return f"vmess://{config_b64}"
        except Exception as e:
            self.add_log(f"ç”ŸæˆVMessåˆ†äº«é“¾æ¥å¤±è´¥: {str(e)}", "DEBUG")
            return None

    def generate_vless_share_link(self, node: Dict[str, Any]) -> str:
        """ç”ŸæˆVLessåˆ†äº«é“¾æ¥"""
        try:
            uuid = node.get('uuid', '')
            host = node.get('host', '')
            port = node.get('port', 443)
            name = node.get('name', 'VLess Node')
            if not uuid or not host:
                return None
            params = []
            params.append(f"type={node.get('network', 'tcp')}")
            params.append("encryption=none")
            if node.get('tls') == 'tls':
                params.append("security=tls")
                if node.get('sni'):
                    params.append(f"sni={node.get('sni')}")
            if node.get('network') == 'ws':
                if node.get('path'):
                    params.append(f"path={node.get('path')}")
                if node.get('host_header'):
                    params.append(f"host={node.get('host_header')}")
            params_str = "&".join(params)
            return f"vless://{uuid}@{host}:{port}?{params_str}#{name}"
        except Exception as e:
            self.add_log(f"ç”ŸæˆVLessåˆ†äº«é“¾æ¥å¤±è´¥: {str(e)}", "DEBUG")
            return None

    def generate_trojan_share_link(self, node: Dict[str, Any]) -> str:
        """ç”ŸæˆTrojanåˆ†äº«é“¾æ¥"""
        try:
            password = node.get('password', '')
            host = node.get('host', '')
            port = node.get('port', 443)
            name = node.get('name', 'Trojan Node')
            if not password or not host:
                return None
            params = []
            if node.get('sni'):
                params.append(f"sni={node.get('sni')}")
            params.append("allowInsecure=1")
            if node.get('network') == 'ws':
                params.append("type=ws")
                if node.get('path'):
                    params.append(f"path={node.get('path')}")
                if node.get('host_header'):
                    params.append(f"host={node.get('host_header')}")
            params_str = "&".join(params)
            return f"trojan://{password}@{host}:{port}?{params_str}#{name}"
        except Exception as e:
            self.add_log(f"ç”ŸæˆTrojanåˆ†äº«é“¾æ¥å¤±è´¥: {str(e)}", "DEBUG")
            return None

    def generate_ss_share_link(self, node: Dict[str, Any]) -> str:
        """ç”ŸæˆShadowsocksåˆ†äº«é“¾æ¥"""
        try:
            method = node.get('method', 'aes-256-gcm')
            password = node.get('password', '')
            host = node.get('host', '')
            port = node.get('port', 8388)
            name = node.get('name', 'SS Node')
            if not method or not password or not host:
                return None
            plain = f"{method}:{password}@{host}:{port}"
            b64 = base64.b64encode(plain.encode()).decode()
            return f"ss://{b64}#{name}"
        except Exception as e:
            self.add_log(f"ç”ŸæˆSSåˆ†äº«é“¾æ¥å¤±è´¥: {str(e)}", "DEBUG")
            return None

    def generate_subscription_url(self):
        """ç”Ÿæˆè®¢é˜…é“¾æ¥"""
        try:
            share_links = []
            for node in self.nodes[:50]:
                if node.get('share_link'):
                    share_links.append(node['share_link'])
            if share_links:
                subscription_text = '\n'.join(share_links)
                self.subscription_base64 = base64.b64encode(subscription_text.encode()).decode()
                self.add_log(f"ğŸ“¥ å·²ç”Ÿæˆè®¢é˜…é“¾æ¥ ({len(share_links)}ä¸ªèŠ‚ç‚¹)", "SUCCESS")
        except Exception as e:
            self.add_log(f"ç”Ÿæˆè®¢é˜…é“¾æ¥å¤±è´¥: {str(e)}", "ERROR")

    def generate_clash_config(self):
        """ç”ŸæˆClashé…ç½®æ–‡ä»¶"""
        try:
            proxies = []
            for node in self.nodes[:30]:
                clash_proxy = self.convert_to_clash_format(node)
                if clash_proxy:
                    proxies.append(clash_proxy)
            if not proxies:
                return None
            clash_config = {
                "port": 7890,
                "socks-port": 7891,
                "allow-lan": True,
                "mode": "Rule",
                "log-level": "info",
                "external-controller": "0.0.0.0:9090",
                "proxies": proxies,
                "proxy-groups": [
                    {
                        "name": "è‡ªåŠ¨é€‰æ‹©",
                        "type": "url-test",
                        "proxies": [p["name"] for p in proxies],
                        "url": "http://www.gstatic.com/generate_204",
                        "interval": 300,
                    },
                    {
                        "name": "æ‰‹åŠ¨é€‰æ‹©",
                        "type": "select",
                        "proxies": [p["name"] for p in proxies],
                    },
                    {
                        "name": "Netflixä¸“ç”¨",
                        "type": "select",
                        "proxies": [p["name"] for p in proxies if p.get('name', '') in [n['name'] for n in self.nodes if n.get('test_results', {}).get('netflix_test', False)]],
                    },
                ],
                "rules": [
                    "DOMAIN-SUFFIX,netflix.com,Netflixä¸“ç”¨",
                    "DOMAIN-SUFFIX,netflix.net,Netflixä¸“ç”¨",
                    "DOMAIN-SUFFIX,nflxext.com,Netflixä¸“ç”¨",
                    "DOMAIN-SUFFIX,nflximg.com,Netflixä¸“ç”¨",
                    "DOMAIN-SUFFIX,nflximg.net,Netflixä¸“ç”¨",
                    "DOMAIN-SUFFIX,nflxso.net,Netflixä¸“ç”¨",
                    "DOMAIN-SUFFIX,nflxvideo.net,Netflixä¸“ç”¨",
                    "DOMAIN-SUFFIX,google.com,è‡ªåŠ¨é€‰æ‹©",
                    "DOMAIN-SUFFIX,youtube.com,è‡ªåŠ¨é€‰æ‹©",
                    "DOMAIN-SUFFIX,youtu.be,è‡ªåŠ¨é€‰æ‹©",
                    "IP-CIDR,127.0.0.0/8,DIRECT",
                    "GEOIP,CN,DIRECT",
                    "MATCH,è‡ªåŠ¨é€‰æ‹©",
                ],
            }
            yaml_str = yaml.dump(clash_config, allow_unicode=True, sort_keys=False)
            filename = f"clash_config_{int(time.time())}.yaml"
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(yaml_str)
            self.add_log(f"âš™ï¸ Clashé…ç½®æ–‡ä»¶å·²ç”Ÿæˆ: {filename}", "SUCCESS")
            return filename
        except Exception as e:
            self.add_log(f"ç”ŸæˆClashé…ç½®å¤±è´¥: {str(e)}", "ERROR")
            return None

    def convert_to_clash_format(self, node: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """è½¬æ¢ä¸ºClashæ ¼å¼"""
        protocol = node.get('protocol', '').lower()
        name = node.get('name', f"{protocol}-node")
        base_config = {
            "name": name,
            "type": protocol,
            "server": node.get('host', ''),
            "port": node.get('port', 443),
            "udp": True,
            "skip-cert-verify": True,
        }
        if protocol == 'vmess':
            base_config.update({
                "uuid": node.get('uuid', ''),
                "alterId": node.get('alterId', 0),
                "cipher": "auto",
                "tls": node.get('tls') == 'tls',
                "network": node.get('network', 'tcp'),
            })
            if node.get('network') == 'ws':
                base_config["ws-opts"] = {
                    "path": node.get('path', '/'),
                    "headers": {"Host": node.get('host_header', '')}
                }
        elif protocol == 'trojan':
            base_config.update({
                "password": node.get('password', ''),
                "sni": node.get('sni', ''),
            })
        elif protocol == 'ss':
            base_config.update({
                "cipher": node.get('method', 'aes-256-gcm'),
                "password": node.get('password', ''),
            })
        return base_config

    async def custom_scan_cycle(self, custom_sources: List[str]):
        """è‡ªå®šä¹‰æ‰«ææµç¨‹"""
        if self.custom_is_scanning:
            return
        self.custom_is_scanning = True
        self.custom_nodes = []
        self.custom_logs = []

        def add_custom_log(message: str, level: str = "INFO"):
            timestamp = datetime.now().strftime("%H:%M:%S")
            icons = {"INFO": "ğŸ“", "SUCCESS": "âœ…", "WARNING": "âš ï¸", "ERROR": "âŒ"}
            icon = icons.get(level, "ğŸ“")
            log_entry = f"[{timestamp}] {icon} {message}"
            self.custom_logs.insert(0, log_entry)
            if len(self.custom_logs) > 50:
                self.custom_logs = self.custom_logs[:50]
            print(f"ğŸ¯ {log_entry}")

        try:
            add_custom_log(f"ğŸ¯ å¼€å§‹æ‰«æ {len(custom_sources)} ä¸ªè‡ªå®šä¹‰æº", "INFO")
            all_nodes = []
            for source_url in custom_sources:
                try:
                    add_custom_log(f"ğŸ” å¤„ç†æº: {source_url}", "INFO")
                    result = await self.process_custom_link(source_url)
                    if result.get('valid'):
                        test_result = await self.link_scraper.test_link_validity(source_url)
                        if test_result.get('valid') and test_result.get('content'):
                            node_urls = self.extract_node_urls(test_result['content'])
                            add_custom_log(f"   â†³ æå–åˆ° {len(node_urls)} ä¸ªèŠ‚ç‚¹", "SUCCESS")
                            for node_url in node_urls:
                                node = self.parse_node_url(node_url)
                                if node:
                                    node['source'] = source_url
                                    node['custom'] = True
                                    all_nodes.append(node)
                    else:
                        add_custom_log(f"   â†³ æºæ— æ•ˆ: {result.get('error', 'æœªçŸ¥é”™è¯¯')}", "WARNING")
                except Exception as e:
                    add_custom_log(f"   â†³ å¤„ç†å¤±è´¥: {str(e)[:50]}", "ERROR")

            if not all_nodes:
                add_custom_log("ğŸ˜ æœªæ‰¾åˆ°ä»»ä½•èŠ‚ç‚¹", "WARNING")
                self.custom_is_scanning = False
                return

            add_custom_log(f"ğŸ“Š å…±è§£æ {len(all_nodes)} ä¸ªèŠ‚ç‚¹ï¼Œå¼€å§‹æµ‹è¯•...", "INFO")
            unique_nodes = []
            seen = set()
            for node in all_nodes:
                node_id = f"{node['protocol']}:{node['host']}:{node['port']}"
                if node_id not in seen:
                    seen.add(node_id)
                    unique_nodes.append(node)
            add_custom_log(f"ğŸ” å»é‡åå‰©ä½™ {len(unique_nodes)} ä¸ªå”¯ä¸€èŠ‚ç‚¹", "INFO")

            valid_nodes = []
            for node in unique_nodes:
                try:
                    port_test = await self.test_port_connectivity(node)
                    if port_test["port_open"]:
                        network_test = await self.test_node_network(node)
                        if network_test.total_score >= 1:
                            node['alive'] = True
                            node['delay'] = network_test.tcp_ping_ms
                            if network_test.tcp_ping_ms < 100:
                                node['speed'] = round(random.uniform(10.0, 50.0), 2)
                            elif network_test.tcp_ping_ms < 300:
                                node['speed'] = round(random.uniform(5.0, 20.0), 2)
                            else:
                                node['speed'] = round(random.uniform(1.0, 10.0), 2)
                            valid_nodes.append(node)
                            add_custom_log(f"âœ… èŠ‚ç‚¹ {node['name']} æµ‹è¯•é€šè¿‡ ({network_test.tcp_ping_ms}ms)", "SUCCESS")
                        else:
                            add_custom_log(f"âŒ èŠ‚ç‚¹ {node['name']} ç½‘ç»œæµ‹è¯•å¤±è´¥", "DEBUG")
                    else:
                        add_custom_log(f"âŒ èŠ‚ç‚¹ {node['name']} ç«¯å£å…³é—­", "DEBUG")
                except Exception as e:
                    add_custom_log(f"âŒ èŠ‚ç‚¹ {node['name']} æµ‹è¯•å¼‚å¸¸: {str(e)[:50]}", "DEBUG")

            self.custom_nodes = valid_nodes
            for node in self.custom_nodes:
                share_link = self.generate_node_share_link(node)
                if share_link:
                    node['share_link'] = share_link

            add_custom_log(f"ğŸ‰ æ‰«æå®Œæˆï¼æœ‰æ•ˆèŠ‚ç‚¹: {len(valid_nodes)}/{len(unique_nodes)}", "SUCCESS")
            if valid_nodes:
                avg_delay = sum([n.get('delay', 0) for n in valid_nodes]) / len(valid_nodes)
                avg_speed = sum([n.get('speed', 0) for n in valid_nodes]) / len(valid_nodes)
                add_custom_log(f"ğŸ“Š ç»Ÿè®¡: å¹³å‡å»¶è¿Ÿ {avg_delay:.0f}ms, å¹³å‡é€Ÿåº¦ {avg_speed:.2f} MB/s", "INFO")
                best_node = max(valid_nodes, key=lambda x: (x.get('speed', 0), -x.get('delay', 9999)))
                add_custom_log(f"ğŸ† æœ€ä½³èŠ‚ç‚¹: {best_node['name']} | å»¶è¿Ÿ: {best_node['delay']}ms | é€Ÿåº¦: {best_node['speed']:.2f} MB/s", "SUCCESS")

        except Exception as e:
            add_custom_log(f"ğŸ’¥ æ‰«æè¿‡ç¨‹å‘ç”Ÿé”™è¯¯: {str(e)}", "ERROR")
            import traceback
            logger.error(traceback.format_exc())
        finally:
            self.custom_is_scanning = False

# åˆ›å»ºå®ä¾‹
hunter = NodeHunter()

# ==================== APIè·¯ç”± ====================

@router.post("/scan-custom")
async def scan_custom_sources(request: dict):
    """æ‰«æè‡ªå®šä¹‰æº"""
    if hunter.custom_is_scanning:
        return {"status": "running", "message": "è‡ªå®šä¹‰æ‰«ææ­£åœ¨è¿›è¡Œä¸­"}
    sources = request.get('sources', [])
    if not sources:
        return {"error": "è¯·æä¾›è‡ªå®šä¹‰æºåˆ—è¡¨"}
    import threading
    thread = threading.Thread(target=lambda: asyncio.run(hunter.custom_scan_cycle(sources)))
    thread.daemon = True
    thread.start()
    return {"status": "started", "message": f"å¼€å§‹æ‰«æ {len(sources)} ä¸ªè‡ªå®šä¹‰æº", "sources_count": len(sources)}

@router.get("/custom-stats", response_model=CustomStatsResponse)
async def get_custom_stats():
    """è·å–è‡ªå®šä¹‰æ‰«æçŠ¶æ€"""
    alive_nodes = [n for n in hunter.custom_nodes if n.get('alive', False)]
    return {"count": len(alive_nodes), "running": hunter.custom_is_scanning, "logs": hunter.custom_logs[:50], "nodes": alive_nodes[:100]}

@router.get("/test-source/{source_index}")
async def test_single_source(source_index: int):
    """æµ‹è¯•å•ä¸ªè‡ªå®šä¹‰æº"""
    try:
        if source_index < 0 or source_index >= len(hunter.user_sources):
            return {"error": "æºç´¢å¼•æ— æ•ˆ"}
        source_url = hunter.user_sources[source_index]
        result = await hunter.process_custom_link(source_url)
        return {"source": source_url, "result": result, "valid": result.get('valid', False), "nodes_found": result.get('nodes_found', 0)}
    except Exception as e:
        return {"error": str(e)}

@router.get("/export-custom")
async def export_custom_nodes():
    """å¯¼å‡ºè‡ªå®šä¹‰èŠ‚ç‚¹"""
    try:
        alive_nodes = [n for n in hunter.custom_nodes if n.get('alive', False)]
        if not alive_nodes:
            return {"error": "æ²¡æœ‰å¯å¯¼å‡ºçš„èŠ‚ç‚¹"}
        export_lines = []
        export_lines.append("# Shadow Matrix - è‡ªå®šä¹‰èŠ‚ç‚¹")
        export_lines.append(f"# å¯¼å‡ºæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        export_lines.append(f"# èŠ‚ç‚¹æ•°é‡: {len(alive_nodes)}")
        export_lines.append("")
        for i, node in enumerate(alive_nodes, 1):
            export_lines.append(f"## èŠ‚ç‚¹ {i}: {node.get('name', 'Unknown')}")
            export_lines.append(f"åè®®: {node.get('protocol', 'unknown').upper()}")
            export_lines.append(f"åœ°å€: {node.get('host', '')}:{node.get('port', '')}")
            export_lines.append(f"å»¶è¿Ÿ: {node.get('delay', -1)}ms")
            export_lines.append(f"é€Ÿåº¦: {node.get('speed', 0.0)} MB/s")
            if node.get('share_link'):
                export_lines.append(f"åˆ†äº«é“¾æ¥: {node.get('share_link')}")
            export_lines.append("")
        content = "\n".join(export_lines)
        return {"content": content, "node_count": len(alive_nodes), "filename": f"custom_nodes_{int(time.time())}.txt"}
    except Exception as e:
        return {"error": str(e)}

@router.get("/stats", response_model=StatsResponse)
async def get_stats():
    """è·å–å½“å‰çŠ¶æ€"""
    alive_nodes = [n for n in hunter.nodes if n.get('alive', False)]
    return {"count": len(alive_nodes), "running": hunter.is_scanning, "logs": hunter.logs[:50], "nodes": alive_nodes[:50]}

@router.post("/trigger")
async def trigger_scan(background_tasks: BackgroundTasks):
    """è§¦å‘èŠ‚ç‚¹æ‰«æ"""
    if not hunter.is_scanning:
        background_tasks.add_task(hunter.scan_cycle)
        return {"status": "started", "message": "æ‰«æä»»åŠ¡å·²å¼€å§‹"}
    else:
        return {"status": "running", "message": "æ‰«ææ­£åœ¨è¿›è¡Œä¸­"}

@router.get("/subscription")
async def get_subscription():
    """è·å–è®¢é˜…é“¾æ¥"""
    if hunter.subscription_base64:
        alive_nodes = [n for n in hunter.nodes if n.get('alive', False)]
        return {"subscription": hunter.subscription_base64, "node_count": len(alive_nodes), "timestamp": datetime.now().isoformat(), "description": "Shadow Matrix - å·²éªŒè¯å¯ç”¨èŠ‚ç‚¹"}
    return {"error": "æš‚æ— è®¢é˜…é“¾æ¥ï¼Œè¯·å…ˆæ‰«æèŠ‚ç‚¹"}

@router.get("/clash/config")
async def get_clash_config():
    """è·å–Clashé…ç½®æ–‡ä»¶"""
    clash_file = hunter.generate_clash_config()
    if clash_file and os.path.exists(clash_file):
        with open(clash_file, 'r', encoding='utf-8') as f:
            content = f.read()
        return {"filename": clash_file, "content": content, "node_count": len([n for n in hunter.nodes if n.get('alive', False)])}
    return {"error": "ç”ŸæˆClashé…ç½®å¤±è´¥"}

@router.get("/node/{node_index}/qrcode")
async def get_node_qrcode(node_index: int):
    """è·å–èŠ‚ç‚¹äºŒç»´ç """
    try:
        if node_index < 0 or node_index >= len(hunter.nodes):
            return {"error": "èŠ‚ç‚¹ä¸å­˜åœ¨"}
        node = hunter.nodes[node_index]
        share_link = node.get('share_link')
        if not share_link:
            share_link = hunter.generate_node_share_link(node)
            if not share_link:
                return {"error": "è¯¥èŠ‚ç‚¹æ— æ³•ç”Ÿæˆåˆ†äº«é“¾æ¥"}
        qr = qrcode.QRCode(version=1, error_correction=qrcode.constants.ERROR_CORRECT_L, box_size=10, border=4)
        qr.add_data(share_link)
        qr.make(fit=True)
        img = qr.make_image(fill_color="black", back_color="white")
        buffered = BytesIO()
        img.save(buffered, format="PNG")
        img_str = base64.b64encode(buffered.getvalue()).decode()
        return {"qrcode_data": f"data:image/png;base64,{img_str}", "node_name": node.get('name', ''), "share_link": share_link}
    except Exception as e:
        logger.error(f"ç”ŸæˆäºŒç»´ç å¤±è´¥: {str(e)}")
        return {"error": f"ç”ŸæˆäºŒç»´ç å¤±è´¥: {str(e)}"}

@router.post("/process-link")
async def process_user_link(request: dict):
    """å¤„ç†ç”¨æˆ·æä¾›çš„é“¾æ¥"""
    url = request.get('url', '').strip()
    mode = request.get('mode', 'direct')
    if not url:
        return {"error": "URLä¸èƒ½ä¸ºç©º"}
    if mode == 'direct':
        result = await hunter.process_custom_link(url)
    else:
        result = await hunter.scrape_and_test_link(url)
    return result

@router.get("/user-sources")
async def get_user_sources():
    """è·å–ç”¨æˆ·è‡ªå®šä¹‰æº"""
    return {"sources": hunter.user_sources, "count": len(hunter.user_sources), "total_sources": len(hunter.sources)}

@router.delete("/user-sources/{url_index}")
async def remove_user_source(url_index: int):
    """ç§»é™¤ç”¨æˆ·è‡ªå®šä¹‰æº"""
    try:
        if 0 <= url_index < len(hunter.user_sources):
            removed_url = hunter.user_sources.pop(url_index)
            if removed_url in hunter.sources:
                hunter.sources.remove(removed_url)
            hunter.save_user_sources()
            return {"success": True, "message": "æºå·²ç§»é™¤"}
        else:
            return {"error": "ç´¢å¼•æ— æ•ˆ"}
    except Exception as e:
        return {"error": str(e)}

app.include_router(router)

@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶æ‰§è¡Œ"""
    print("=" * 50)
    print("ğŸ›°ï¸  Shadow Matrix Node Hunter v2.0")
    print("ğŸ“¡  å…¨ç½‘é«˜å¸¦å®½èŠ‚ç‚¹å—…æ¢ç³»ç»Ÿ")
    print("âœ…  å¸¦çœŸå®å¯ç”¨æ€§æµ‹è¯•ï¼ˆGoogle/Netflix/YouTubeï¼‰")
    print("ğŸŒ  å‰ç«¯åœ°å€: http://localhost:5173")
    print("ğŸ”§  åç«¯ç«¯å£: 8000")
    print("=" * 50)

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("node_hunter:app", host="0.0.0.0", port=8000, reload=True, log_level="info")
