# backend/app/core/ai_hub.py
import json
import os
import requests
import httpx
from pathlib import Path

# å»¶è¿Ÿå¯¼å…¥ï¼Œé¿å…å¾ªçŽ¯ä¾èµ–
pool_manager = None


def set_pool_manager(manager):
    global pool_manager
    pool_manager = manager


# ==================== ðŸ› ï¸ æ ¸å¿ƒä¿®å¤ï¼šæ‰‹å†™ç‰©ç†è¯»å–å™¨ ====================
def _manual_read_env_key(target_key: str):
    """
    ä¸ä¾èµ– load_dotenvï¼Œä¸ä¾èµ–ç³»ç»Ÿå˜é‡ï¼Œç›´æŽ¥æš´åŠ›è¯»å–æ–‡ä»¶ã€‚
    ä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼Œè‡ªåŠ¨å®šä½ .env (backend/.env)
    """
    try:
        # 1. èŽ·å– ai_hub.py æ‰€åœ¨çš„ç›®å½•
        current_dir = Path(__file__).resolve().parent
        # 2. å¾€ä¸Šæ‰¾ 2 å±‚ (app -> backend)ï¼Œæ‰¾åˆ° .env æ‰€åœ¨ç›®å½•
        # current: backend/app/core
        # parent:  backend/app
        # parent.parent: backend
        project_root = current_dir.parent.parent
        env_file = project_root / ".env"

        print(f"[DEBUG] æ­£åœ¨å°è¯•ä»Žæ–‡ä»¶è¯»å– Key: {env_file}")

        if not env_file.exists():
            print(f"[ERROR] .env æ–‡ä»¶æœªæ‰¾åˆ°! è·¯å¾„: {env_file}")
            return None

        # 3. é€è¡Œæ‰«æ
        with open(env_file, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                # å¿½ç•¥æ³¨é‡Šå’Œç©ºè¡Œ
                if not line or line.startswith("#"):
                    continue
                # æŸ¥æ‰¾ç›®æ ‡ Key
                if line.startswith(f"{target_key}="):
                    # åˆ†å‰²å¹¶æ¸…ç†ç©ºæ ¼ã€å¼•å·
                    key_value = line.split("=", 1)[1].strip().strip("'").strip('"')
                    if key_value:
                        print(f"[DEBUG] æˆåŠŸä»Žæ–‡ä»¶è¯»å–åˆ° {target_key} (é•¿åº¦: {len(key_value)})")
                        return key_value
    except Exception as e:
        print(f"[ERROR] è¯»å– .env å‘ç”Ÿå¼‚å¸¸: {e}")

    return None


# ==================== ðŸ¤– é…ç½®å®šä¹‰ ====================
AI_PROVIDERS = {
    "silicon": {
        # Base URL ä¹Ÿå¯ä»¥å°è¯•è¯»å–ï¼Œè¿™é‡Œç»™é»˜è®¤å€¼
        "base_url": "https://api.siliconflow.cn/v1",
        "api_key": "",  # å ä½ç¬¦ï¼Œä¸‹é¢åŠ¨æ€èŽ·å–
    }
}


def get_provider_config(model_name: str):
    return AI_PROVIDERS["silicon"], model_name.replace("silicon/", "")


def _get_dynamic_api_key():
    """
    ä¸‰çº§ç«ç®­èŽ·å– Keyï¼š
    1. ç³»ç»ŸçŽ¯å¢ƒå˜é‡ (æœ€é«˜çº§)
    2. æ‰‹åŠ¨è¯»å– .env æ–‡ä»¶ (ä¿åº•çº§)
    3. ç¡¬ç¼–ç å…œåº• (æœ€åŽé˜²çº¿)
    """
    # 1. å°è¯•ç³»ç»Ÿå˜é‡
    key = os.getenv("SILICON_API_KEY")
    if key and len(key) > 10:
        return key

    # 2. å°è¯•æ‰‹åŠ¨è¯»å–æ–‡ä»¶
    key = _manual_read_env_key("SILICON_API_KEY")
    if key and len(key) > 10:
        return key

    # 3. å¦‚æžœå®žåœ¨è¯»ä¸åˆ°ï¼Œä¸ºäº†é˜²æ­¢æœåŠ¡å´©æºƒï¼Œè¿™é‡Œä¿ç•™ä¸€ä¸ªç¡¬ç¼–ç çš„â€œå®‰å…¨ç½‘â€
    # å¦‚æžœä½ è§‰å¾—ä¸å®‰å…¨ï¼Œå¯ä»¥åˆ æŽ‰è¿™è¡Œï¼Œä½†è¿™æ˜¯è§£å†³â€œæ€Žä¹ˆéƒ½è¯»ä¸åˆ°â€çš„æœ€åŽåŠžæ³•
    # ä½ çš„ Key: sk-pbnkxfexbhsaxwbfrupdjpokwzkxsiwuqeysarxnnkuesdfn
    print("[WARNING] ä½¿ç”¨ç¡¬ç¼–ç  Key ä½œä¸ºæœ€åŽå…œåº•")
    return "sk-pbnkxfexbhsaxwbfrupdjpokwzkxsiwuqeysarxnnkuesdfn"


# --- ðŸš€ æ ¸å¿ƒï¼šå¼‚æ­¥è¯·æ±‚ (éžé˜»å¡ž) ---
async def _execute_request_async(client, url, headers, payload, timeout):
    try:
        if not url.endswith("/chat/completions"):
            url = f"{url.rstrip('/')}/chat/completions"

        resp = await client.post(url, headers=headers, json=payload, timeout=timeout)

        if resp.status_code == 200:
            data = resp.json()
            if "choices" in data and len(data["choices"]) > 0:
                return data['choices'][0]['message']['content'], None
            return None, f"Empty Resp: {resp.text[:100]}"
        return None, f"HTTP {resp.status_code}: {resp.text[:200]}"
    except Exception as e:
        return None, str(e)


# --- ðŸš€ æ ¸å¿ƒï¼šå¼‚æ­¥æµå¼ç”Ÿæˆ ---
async def call_ai_stream_async(system_prompt: str, user_text: str, model: str = "deepseek-ai/DeepSeek-V3",
                               temperature: float = 0.7):
    """
    å…¨å¼‚æ­¥æµå¼è°ƒç”¨
    """
    config = AI_PROVIDERS["silicon"]

    # ðŸ”¥ åŠ¨æ€èŽ·å– Key
    api_key = _get_dynamic_api_key()

    if not api_key:
        yield "Stream Error: Critical - API Key not found in env or file."
        return

    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}

    real_model = model
    if "r1" in model.lower(): real_model = "deepseek-ai/DeepSeek-R1"

    payload = {
        "model": real_model,
        "messages": [{"role": "system", "content": system_prompt}, {"role": "user", "content": user_text}],
        "temperature": temperature,
        "max_tokens": 8192,
        "stream": True
    }

    url = f"{config['base_url'].rstrip('/')}/chat/completions"

    try:
        async with httpx.AsyncClient(timeout=300) as client:
            async with client.stream("POST", url, headers=headers, json=payload) as response:
                if response.status_code != 200:
                    yield f"Error {response.status_code}: {await response.aread()}"
                    return

                async for line in response.aiter_lines():
                    if line.startswith("data: "):
                        json_str = line[6:]
                        if json_str.strip() == "[DONE]": break
                        try:
                            chunk = json.loads(json_str)
                            content = chunk['choices'][0]['delta'].get('content', '')
                            if content: yield content
                        except:
                            pass
    except Exception as e:
        yield f"Stream Error: {str(e)}"


# --- ðŸš€ æ ¸å¿ƒï¼šå¼‚æ­¥æ™®é€šè°ƒç”¨ ---
async def call_ai_async(system_prompt: str, user_text: str, model: str = "deepseek-ai/DeepSeek-V3",
                        temperature: float = 0.7):
    config = AI_PROVIDERS["silicon"]
    api_key = _get_dynamic_api_key()

    if not api_key:
        raise Exception("API Key Missing")

    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    payload = {
        "model": model,
        "messages": [{"role": "system", "content": system_prompt}, {"role": "user", "content": user_text}],
        "temperature": temperature,
        "max_tokens": 8192
    }

    async with httpx.AsyncClient() as client:
        content, error = await _execute_request_async(client, config["base_url"], headers, payload, 120)
        if error: raise Exception(error)
        return content


# ==================== ðŸ‘‡ å…¼å®¹æ—§ä»£ç  ====================
def _execute_request(session, url, headers, payload, proxies, timeout):
    try:
        if not url.endswith("/chat/completions"): url = f"{url.rstrip('/')}/chat/completions"
        resp = session.post(url, headers=headers, json=payload, timeout=timeout, proxies=proxies, verify=False)
        if resp.status_code == 200:
            data = resp.json()
            if "choices" in data and len(data["choices"]) > 0:
                return data['choices'][0]['message']['content'], None
            return None, f"Empty Resp: {resp.text[:100]}"
        return None, f"HTTP {resp.status_code}: {resp.text[:200]}"
    except Exception as e:
        return None, str(e)


def call_ai(system_prompt: str, user_text: str, model: str = "deepseek-ai/DeepSeek-V3", temperature: float = 0.7,
            return_model_name: bool = False):
    chain = []
    if pool_manager: chain = pool_manager.get_standard_chain()
    chain.append((None, "Direct", 60))

    config = AI_PROVIDERS["silicon"]
    api_key = _get_dynamic_api_key()

    real_model = model
    if "gpt" in model or "smart" in model: real_model = "deepseek-ai/DeepSeek-V3"
    if "r1" in model.lower(): real_model = "deepseek-ai/DeepSeek-R1"

    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    payload = {
        "model": real_model,
        "messages": [{"role": "system", "content": system_prompt}, {"role": "user", "content": user_text}],
        "temperature": temperature,
        "max_tokens": 8192
    }

    last_error = None
    for proxy_url, _, timeout_sec in chain:
        proxies = {"http": proxy_url, "https": proxy_url} if proxy_url else None
        session = requests.Session()
        content, error = _execute_request(session, config["base_url"], headers, payload, proxies, 60 + timeout_sec)

        if content:
            if return_model_name:
                return content, f"SiliconFlow-{real_model.split('/')[-1]}"
            return content

        last_error = error
        if "401" in error: break
        continue

    raise Exception(f"è¯·æ±‚å¤±è´¥: {last_error}")