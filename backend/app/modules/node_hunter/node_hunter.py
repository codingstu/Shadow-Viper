# backend/app/modules/node_hunter/node_hunter.py
# !/usr/bin/env python3
# -*- coding: utf-8 -*-
from fastapi import APIRouter, BackgroundTasks, Body, Query, Request
import asyncio
import aiohttp
import time
from pydantic import BaseModel
from datetime import datetime
import random
from typing import List, Optional, Dict, Any
import logging
import os
import qrcode
from io import BytesIO
import json
import base64
from apscheduler.schedulers.asyncio import AsyncIOScheduler
import ipapi

from ..link_scraper.link_scraper import LinkScraper
from .parsers import parse_node_url
from .validators import test_node_network, NodeTestResult
from .config_generator import generate_node_share_link, generate_subscription_content, generate_clash_config
from .advanced_speed_test import run_advanced_speed_test
from .supabase_helper import upload_to_supabase, check_supabase_connection
from .clash_basic_check import (
    check_nodes_clash,
    ClashCheckResult,
    ClashBasicChecker,
)
from .v2ray_check import (
    check_nodes_v2ray,
    V2RayCheckResult,
)
from .simple_availability_check import (
    AvailabilityLevel,
    AvailabilityResult,
)
from .real_speed_test import RealSpeedTester
from .geolocation_helper import GeolocationHelper
from .persistence_helper import get_persistence

try:
    from ..proxy.proxy_engine import manager as pool_manager
except ImportError:
    pool_manager = None

logging.basicConfig(level=logging.INFO, format='[%(asctime)s] %(message)s', datefmt='%H:%M:%S')
logger = logging.getLogger(__name__)

router = APIRouter(prefix="/nodes", tags=["nodes"])

VERIFIED_NODES_FILE = "verified_nodes.json"

# ==================== äº‘ç«¯æ£€æµ‹é…ç½® ====================

# Aliyun FC URL (ç”¨äºå›½å†…èŠ‚ç‚¹æ£€æµ‹)
ALIYUN_FC_URL = os.environ.get("ALIYUN_FC_URL", "")

# Cloudflare Worker URL (ç”¨äºæµ·å¤–èŠ‚ç‚¹æ£€æµ‹)
CF_WORKER_URL = os.environ.get("CF_WORKER_URL", "")

# æ˜¯å¦å¯ç”¨äº‘ç«¯æ£€æµ‹
CLOUD_DETECTION_ENABLED = os.environ.get("CLOUD_DETECTION_ENABLED", "false").lower() == "true"  # ğŸ”¥ æ”¹ä¸ºé»˜è®¤falseï¼Œé¿å…èŠ‚ç‚¹è¢«è¿‡åº¦è¿‡æ»¤

NAME_TO_CODE = {
    # äºšæ´²
    "CN": "CN", "CHINA": "CN", "ä¸­å›½": "CN", "å›å›½": "CN", "BEIJING": "CN", "SHANGHAI": "CN", "SHENZHEN": "CN",
    "ğŸ‡¨ğŸ‡³": "CN",
    "HK": "HK", "HONG KONG": "HK", "HONGKONG": "HK", "ğŸ‡­ğŸ‡°": "HK",
    "TW": "TW", "TAIWAN": "TW", "TAIPEI": "TW", "ğŸ‡¹ğŸ‡¼": "TW",
    "MO": "MO", "MACAO": "MO", "MACAU": "MO", "ğŸ‡²ğŸ‡´": "MO",
    "JP": "JP", "JAPAN": "JP", "TOKYO": "JP", "OSAKA": "JP", "ğŸ‡¯ğŸ‡µ": "JP",
    "SG": "SG", "SINGAPORE": "SG", "ğŸ‡¸ğŸ‡¬": "SG",
    "KR": "KR", "KOREA": "KR", "SEOUL": "KR", "ğŸ‡°ğŸ‡·": "KR",
    "TH": "TH", "THAILAND": "TH", "BANGKOK": "TH", "ğŸ‡¹ğŸ‡­": "TH",
    "MY": "MY", "MALAYSIA": "MY", "KUALA LUMPUR": "MY", "ğŸ‡²ğŸ‡¾": "MY",
    "PH": "PH", "PHILIPPINES": "PH", "MANILA": "PH", "ğŸ‡µğŸ‡­": "PH",
    "VN": "VN", "VIETNAM": "VN", "HANOI": "VN", "HO CHI MINH": "VN", "ğŸ‡»ğŸ‡³": "VN",
    "ID": "ID", "INDONESIA": "ID", "JAKARTA": "ID", "ğŸ‡®ğŸ‡©": "ID",
    "IN": "IN", "INDIA": "IN", "DELHI": "IN", "MUMBAI": "IN", "ğŸ‡®ğŸ‡³": "IN",
    "PK": "PK", "PAKISTAN": "PK", "ISLAMABAD": "PK", "ğŸ‡µğŸ‡°": "PK",
    "BD": "BD", "BANGLADESH": "BD", "DHAKA": "BD", "ğŸ‡§ğŸ‡©": "BD",
    "LK": "LK", "SRI LANKA": "LK", "COLOMBO": "LK", "ğŸ‡±ğŸ‡°": "LK",
    # ä¸­ä¸œ
    "TR": "TR", "TURKEY": "TR", "ISTANBUL": "TR", "ANKARA": "TR", "ğŸ‡¹ğŸ‡·": "TR",
    "AE": "AE", "UAE": "AE", "UNITED ARAB EMIRATES": "AE", "DUBAI": "AE", "ğŸ‡¦ğŸ‡ª": "AE",
    "SA": "SA", "SAUDI ARABIA": "SA", "RIYADH": "SA", "ğŸ‡¸ğŸ‡¦": "SA",
    "IL": "IL", "ISRAEL": "IL", "TEL AVIV": "IL", "ğŸ‡®ğŸ‡±": "IL",
    "JO": "JO", "JORDAN": "JO", "AMMAN": "JO", "ğŸ‡¯ğŸ‡´": "JO",
    # æ¬§æ´²
    "GB": "GB", "UK": "GB", "UNITED KINGDOM": "GB", "LONDON": "GB", "ğŸ‡¬ğŸ‡§": "GB",
    "DE": "DE", "GERMANY": "DE", "FRANKFURT": "DE", "BERLIN": "DE", "ğŸ‡©ğŸ‡ª": "DE",
    "FR": "FR", "FRANCE": "FR", "PARIS": "FR", "LYON": "FR", "ğŸ‡«ğŸ‡·": "FR",
    "NL": "NL", "NETHERLANDS": "NL", "AMSTERDAM": "NL", "ROTTERDAM": "NL", "ğŸ‡³ğŸ‡±": "NL",
    "BE": "BE", "BELGIUM": "BE", "BRUSSELS": "BE", "ğŸ‡§ğŸ‡ª": "BE",
    "IT": "IT", "ITALY": "IT", "MILAN": "IT", "ROME": "IT", "ğŸ‡®ğŸ‡¹": "IT",
    "ES": "ES", "SPAIN": "ES", "MADRID": "ES", "BARCELONA": "ES", "ğŸ‡ªğŸ‡¸": "ES",
    "PT": "PT", "PORTUGAL": "PT", "LISBON": "PT", "ğŸ‡µğŸ‡¹": "PT",
    "PL": "PL", "POLAND": "PL", "WARSAW": "PL", "ğŸ‡µğŸ‡±": "PL",
    "SE": "SE", "SWEDEN": "SE", "STOCKHOLM": "SE", "ğŸ‡¸ğŸ‡ª": "SE",
    "NO": "NO", "NORWAY": "NO", "OSLO": "NO", "ğŸ‡³ğŸ‡´": "NO",
    "DK": "DK", "DENMARK": "DK", "COPENHAGEN": "DK", "ğŸ‡©ğŸ‡°": "DK",
    "FI": "FI", "FINLAND": "FI", "HELSINKI": "FI", "ğŸ‡«ğŸ‡®": "FI",
    "CH": "CH", "SWITZERLAND": "CH", "ZURICH": "CH", "GENEVA": "CH", "ğŸ‡¨ğŸ‡­": "CH",
    "AT": "AT", "AUSTRIA": "AT", "VIENNA": "AT", "ğŸ‡¦ğŸ‡¹": "AT",
    "CZ": "CZ", "CZECH": "CZ", "PRAGUE": "CZ", "ğŸ‡¨ğŸ‡¿": "CZ",
    "HU": "HU", "HUNGARY": "HU", "BUDAPEST": "HU", "ğŸ‡­ğŸ‡º": "HU",
    "RO": "RO", "ROMANIA": "RO", "BUCHAREST": "RO", "ğŸ‡·ğŸ‡´": "RO",
    "GR": "GR", "GREECE": "GR", "ATHENS": "GR", "ğŸ‡¬ğŸ‡·": "GR",
    "RU": "RU", "RUSSIA": "RU", "MOSCOW": "RU", "ST PETERSBURG": "RU", "SIBERIA": "RU", "ğŸ‡·ğŸ‡º": "RU",
    "UA": "UA", "UKRAINE": "UA", "KYIV": "UA", "ğŸ‡ºğŸ‡¦": "UA",
    "BG": "BG", "BULGARIA": "BG", "SOFIA": "BG", "ğŸ‡§ğŸ‡¬": "BG",
    # åŒ—ç¾
    "US": "US", "USA": "US", "AMERICA": "US", "UNITED STATES": "US", "LOS ANGELES": "US", "SAN FRANCISCO": "US",
    "NEW YORK": "US", "CHICAGO": "US", "DALLAS": "US", "SEATTLE": "US", "MIAMI": "US", "ğŸ‡ºğŸ‡¸": "US",
    "CA": "CA", "CANADA": "CA", "TORONTO": "CA", "VANCOUVER": "CA", "MONTREAL": "CA", "ğŸ‡¨ğŸ‡¦": "CA",
    "MX": "MX", "MEXICO": "MX", "MEXICO CITY": "MX", "ğŸ‡²ğŸ‡½": "MX",
    # å—ç¾
    "BR": "BR", "BRAZIL": "BR", "SAO PAULO": "BR", "RIO DE JANEIRO": "BR", "ğŸ‡§ğŸ‡·": "BR",
    "AR": "AR", "ARGENTINA": "AR", "BUENOS AIRES": "AR", "ğŸ‡¦ğŸ‡·": "AR",
    "CL": "CL", "CHILE": "CL", "SANTIAGO": "CL", "ğŸ‡¨ğŸ‡±": "CL",
    "CO": "CO", "COLOMBIA": "CO", "BOGOTA": "CO", "ğŸ‡¨ğŸ‡´": "CO",
    "PE": "PE", "PERU": "PE", "LIMA": "PE", "ğŸ‡µğŸ‡ª": "PE",
    "VE": "VE", "VENEZUELA": "VE", "CARACAS": "VE", "ğŸ‡»ğŸ‡ª": "VE",
    # å¤§æ´‹æ´²
    "AU": "AU", "AUSTRALIA": "AU", "SYDNEY": "AU", "MELBOURNE": "AU", "BRISBANE": "AU", "ğŸ‡¦ğŸ‡º": "AU",
    "NZ": "NZ", "NEW ZEALAND": "NZ", "AUCKLAND": "NZ", "WELLINGTON": "NZ", "ğŸ‡³ğŸ‡¿": "NZ",
    # éæ´²
    "ZA": "ZA", "SOUTH AFRICA": "ZA", "JOHANNESBURG": "ZA", "CAPE TOWN": "ZA", "ğŸ‡¿ğŸ‡¦": "ZA",
    "EG": "EG", "EGYPT": "EG", "CAIRO": "EG", "ğŸ‡ªğŸ‡¬": "EG",
    "NG": "NG", "NIGERIA": "NG", "LAGOS": "NG", "ğŸ‡³ğŸ‡¬": "NG",
}


class StatsResponse(BaseModel):
    count: int
    running: bool
    logs: List[str]
    nodes: List[dict]
    next_scan_time: Optional[float] = None  # ğŸ”¥ æ–°å¢ï¼šä¸‹æ¬¡æ‰«ææ—¶é—´æˆ³


class NodeTarget(BaseModel):
    host: str
    port: int


class SourceRequest(BaseModel):
    url: str


class NodeHunter:
    def __init__(self):
        self.nodes: List[dict] = []
        self.is_scanning = False
        self.logs: List[str] = []
        self.subscription_base64: Optional[str] = None
        self.link_scraper = LinkScraper(pool_manager)
        self.user_sources_file = 'user_sources.json'
        self.user_sources = self._load_user_sources()
        self.sources = self._get_default_sources() + self.user_sources
        self.scheduler = AsyncIOScheduler()
        
        # ğŸ”¥ åˆå§‹åŒ–æŒä¹…åŒ–ç®¡ç†å™¨
        self.persistence = get_persistence()
        
        self._load_nodes_from_file()

        self.source_stats: Dict[str, Dict] = {}
        self.scan_cycle_count = 0
        for src in self.sources:
            self.source_stats[src] = {"is_disabled": False, "disabled_at": 0, "retry_fails": 0}

        # ğŸ”¥ åˆå§‹åŒ–çœŸå®é€Ÿåº¦æµ‹è¯•å’Œåœ°ç†ä½ç½®åŠ©æ‰‹
        self.speed_tester = RealSpeedTester()
        self.geolocation_helper = GeolocationHelper()
        
        # ğŸ”¥ P3ä¼˜åŒ–: å¾…æ£€æµ‹èŠ‚ç‚¹é˜Ÿåˆ—ç³»ç»Ÿ (åˆ†æ‰¹å¤„ç†å¤§è§„æ¨¡èŠ‚ç‚¹)
        self.pending_nodes_queue: Dict[str, dict] = {}  # å¾…æ£€æµ‹èŠ‚ç‚¹é˜Ÿåˆ— {node_key: {node_data, retry_count, priority}}
        self.is_batch_testing = False  # æ‰¹é‡æ£€æµ‹è¿›è¡Œä¸­æ ‡å¿—
        self.last_batch_test_time = 0  # ä¸Šæ¬¡æ‰¹é‡æ£€æµ‹æ—¶é—´
        self.batch_test_interval = 3600  # 1å°æ—¶æ£€æµ‹ä¸€æ¬¡ (ç§’)
        self.batch_size = 50   # æ¯æ¬¡æ£€æµ‹50ä¸ªèŠ‚ç‚¹ (ğŸ”¥ æ”¹å°åˆ°50åŠ å¿«åé¦ˆé€Ÿåº¦ï¼Œçº¦3-4åˆ†é’Ÿå®Œæˆä¸€è½®)
        self.max_retries = 3  # å¤±è´¥é‡è¯•3æ¬¡
        self.last_sync_time = 0  # ä¸Šæ¬¡åŒæ­¥æ—¶é—´
        self.sync_interval = 3600  # 1å°æ—¶åŒæ­¥ä¸€æ¬¡ (ç§’)
        
        # ğŸ”¥ æ–°å¢ï¼šæµ‹é€Ÿé˜Ÿåˆ—è¿›åº¦è¿½è¸ªï¼ˆæ¥è‡ªæŒä¹…åŒ–ï¼‰
        self.testing_queue_tasks: List[Dict] = []  # æµ‹é€Ÿä»»åŠ¡é˜Ÿåˆ—
        self.current_queue_index = 0  # å½“å‰å¤„ç†çš„é˜Ÿåˆ—ç´¢å¼•
        
        # ğŸ”¥ æ–°å¢: socks/http å¼€å…³æ§åˆ¶ (é»˜è®¤å…³é—­)
        self.show_socks_http = False  # æ˜¯å¦æ˜¾ç¤º socks/http èŠ‚ç‚¹
        self.show_china_nodes = False  # æ˜¯å¦æ˜¾ç¤ºå›½å†…èŠ‚ç‚¹

    def start_scheduler(self):
        if not self.scheduler.running:
            # çˆ¬è™«: æ¯6å°æ—¶è‡ªåŠ¨æ‰«æä¸€æ¬¡
            self.scheduler.add_job(self.scan_cycle, 'interval', minutes=360, id='node_scan_refresh')
            
            # ğŸ”¥ P3: ç‹¬ç«‹çš„æ‰¹é‡æ£€æµ‹å®šæ—¶ä»»åŠ¡ (æ¯1å°æ—¶æ‰§è¡Œä¸€æ¬¡ï¼Œä»é˜Ÿåˆ—å–1000ä¸ªèŠ‚ç‚¹æ£€æµ‹)
            # initial_delay=65ç§’ ç¡®ä¿çˆ¬è™«å®Œæˆåç«‹å³å¼€å§‹æ£€æµ‹
            self.scheduler.add_job(
                self._batch_test_pending_nodes, 
                'interval', 
                minutes=60, 
                id='batch_node_test',
                seconds=0
            )
            
            # ğŸ”¥ P3: ç‹¬ç«‹çš„åŒæ­¥å®šæ—¶ä»»åŠ¡ (æ¯1å°æ—¶æ‰§è¡Œä¸€æ¬¡)
            # æ¯”æ£€æµ‹æ™š30ç§’å¼€å§‹ï¼Œç¡®ä¿æ£€æµ‹ç»“æœå·²å†™å…¥
            self.scheduler.add_job(
                self._sync_nodes_to_storage, 
                'interval', 
                minutes=60, 
                id='node_sync',
                seconds=30
            )
            
            # ğŸ”¥ æ–°å¢ï¼šSupabase åŒæ­¥å®šæ—¶ä»»åŠ¡ (æ¯3åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡)
            # å°†å·²éªŒè¯çš„èŠ‚ç‚¹å†™å…¥ Supabaseï¼Œä¾› viper-node-store è¯»å–
            self.scheduler.add_job(
                self._sync_to_supabase_task,
                'interval',
                minutes=3,
                id='supabase_sync',
                seconds=0
            )
            
            # ğŸ”¥ æ–°å¢ï¼šå®šæœŸæ¸…ç†è¿‡æœŸç¼“å­˜ (æ¯æ—¥å‡Œæ™¨ 3 ç‚¹)
            self.scheduler.add_job(
                self._cleanup_expired_cache_task,
                'cron',
                hour=3,
                minute=0,
                id='cache_cleanup'
            )
            
            self.scheduler.start()
            self.add_log("âœ… [System] èŠ‚ç‚¹çŒæ‰‹è‡ªåŠ¨å·¡èˆªå·²å¯åŠ¨ (6h/çˆ¬è™«, 1h/æ£€æµ‹, 1h/åŒæ­¥, 3min/Supabase, æ¯æ—¥3:00æ¸…ç†ç¼“å­˜)", "SUCCESS")
            
            # ğŸ”¥ æ”¹è¿›ï¼šPersistence åˆå§‹åŒ–å’Œçˆ¬è™«å¯åŠ¨éƒ½æ”¹ä¸ºåå°ä»»åŠ¡ï¼Œä¸é˜»å¡ FastAPI å¯åŠ¨
            async def init_persistence_background():
                """åå°åˆå§‹åŒ–æŒä¹…åŒ–ï¼Œä¸é˜»å¡å¯åŠ¨"""
                try:
                    await asyncio.sleep(2)  # ç­‰å¾… FastAPI å®Œå…¨å¯åŠ¨ï¼ˆ2ç§’ï¼‰
                    await self.persistence.init_persistence_tables()
                    self.add_log("âœ… æŒä¹…åŒ–è¡¨åˆå§‹åŒ–å®Œæˆ", "SUCCESS")
                    
                    # Persistence åˆå§‹åŒ–å®Œåï¼Œå†ç­‰å¾… 28 ç§’æ‰å¯åŠ¨çˆ¬è™«
                    await asyncio.sleep(28)
                    self.add_log("â° 30ç§’å»¶è¿Ÿå·²è¿‡æœŸï¼Œå¯åŠ¨é¦–æ¬¡èŠ‚ç‚¹æ‰«æ...", "INFO")
                    await self.scan_cycle()
                    
                    # ç­‰å¾…çˆ¬è™«å®Œæˆï¼Œç„¶åå¯åŠ¨æ£€æµ‹
                    max_retries = 5
                    for attempt in range(max_retries):
                        await asyncio.sleep(10)
                        
                        if self.pending_nodes_queue:
                            self.add_log(f"ğŸš€ çˆ¬è™«å®Œæˆï¼Œç«‹å³å¯åŠ¨é¦–æ¬¡æ‰¹é‡æ£€æµ‹... (é˜Ÿåˆ—: {len(self.pending_nodes_queue)} ä¸ªèŠ‚ç‚¹)", "INFO")
                            await self._batch_test_pending_nodes()
                            break
                        else:
                            self.add_log(f"â³ ç­‰å¾…çˆ¬è™«å®Œæˆ... å°è¯• {attempt+1}/{max_retries}", "WARNING")
                    
                    if not self.pending_nodes_queue:
                        self.add_log("âŒ çˆ¬è™«å®Œæˆåé˜Ÿåˆ—ä»ä¸ºç©ºï¼Œå¯èƒ½çˆ¬è™«å¤±è´¥", "ERROR")
                    
                except Exception as e:
                    self.add_log(f"âŒ [System] åå°åˆå§‹åŒ–å¼‚å¸¸: {str(e)}", "ERROR")
                    logger.exception("åå°åˆå§‹åŒ–å¼‚å¸¸")
            
            # ğŸ”¥ åˆ›å»ºåå°ä»»åŠ¡ï¼Œç«‹å³è¿”å›ï¼Œä¸é˜»å¡ FastAPI
            task = asyncio.create_task(init_persistence_background())
            task.add_done_callback(lambda t: logger.exception(t.exception()) if t.exception() else None)

    def get_alive_nodes(self) -> List[Dict[str, Any]]:
        return [node for node in self.nodes if node.get('alive')]

    def get_socks5_nodes(self) -> List[Dict[str, Any]]:
        return [
            node for node in self.nodes
            if node.get('alive') and node.get('protocol') in ['socks5', 'socks']
        ]

    def _load_user_sources(self) -> List[str]:
        try:
            if os.path.exists(self.user_sources_file):
                with open(self.user_sources_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            logger.error(f"åŠ è½½ç”¨æˆ·æºå¤±è´¥: {e}")
        return []
    
    def _convert_to_clash_node(self, node: Dict) -> Optional[Dict]:
        """
        å°†èŠ‚ç‚¹è½¬æ¢ä¸ºClashæ ¼å¼
        
        Args:
            node: åŸå§‹èŠ‚ç‚¹æ•°æ®
            
        Returns:
            Clashæ ¼å¼èŠ‚ç‚¹é…ç½®ï¼Œå¦‚æœè½¬æ¢å¤±è´¥åˆ™è¿”å›None
        """
        try:
            protocol = node.get('protocol', '').lower()
            
            clash_node = {
                "name": f"{node.get('host')}:{node.get('port')}",
                "server": node.get('host'),
                "port": int(node.get('port', 0)),
            }
            
            # æ ¹æ®åè®®ç±»å‹è½¬æ¢
            if protocol in ['vmess']:
                clash_node.update({
                    "type": "vmess",
                    "uuid": node.get('id') or node.get('uuid', ''),
                    "alterId": int(node.get('aid', 0)) if node.get('aid') else 0,
                    "cipher": node.get('scy', 'auto'),
                    "network": node.get('net', 'tcp'),
                })
                
                # WebSocketé…ç½®
                if clash_node['network'] == 'ws':
                    clash_node['ws-opts'] = {
                        "path": node.get('path', '/'),
                        "headers": {"Host": node.get('host', '')}
                    }
                    
            elif protocol in ['vless']:
                clash_node.update({
                    "type": "vless",
                    "uuid": node.get('id') or node.get('uuid', ''),
                    "flow": node.get('flow', ''),
                    "network": node.get('net', 'tcp'),
                })
                
            elif protocol in ['trojan']:
                clash_node.update({
                    "type": "trojan",
                    "password": node.get('password', ''),
                    "sni": node.get('sni', node.get('host')),
                })
                
            elif protocol in ['ss', 'shadowsocks']:
                clash_node.update({
                    "type": "ss",
                    "cipher": node.get('method', 'aes-256-gcm'),
                    "password": node.get('password', ''),
                })
                
            elif protocol in ['socks5', 'socks']:
                clash_node.update({
                    "type": "socks5",
                    "username": node.get('username', ''),
                    "password": node.get('password', ''),
                })
                
            elif protocol in ['http', 'https']:
                clash_node.update({
                    "type": "http",
                    "username": node.get('username', ''),
                    "password": node.get('password', ''),
                })
                
            else:
                # ğŸ”¥ ä¿®å¤ï¼šä¸æ”¯æŒçš„åè®®ä»ç„¶è¿”å›åŸºç¡€é…ç½®ï¼Œè€Œä¸æ˜¯None
                # è¿™æ ·å³ä½¿Clashæ— æ³•å¤„ç†ï¼Œåç»­çš„Xrayæ£€æµ‹ä»ç„¶å¯ä»¥å°è¯•
                logger.debug(f"Clashä¸æ”¯æŒåè®®{protocol}ï¼Œå°†ç”±Xrayå¤„ç†: {node.get('host')}:{node.get('port')}")
                return None  # Xrayä¼šå¤„ç†è¿™äº›åè®®
            
            return clash_node
            
        except Exception as e:
            logger.error(f"èŠ‚ç‚¹è½¬æ¢å¤±è´¥: {e}, èŠ‚ç‚¹: {node}")
            return None

    def _save_user_sources(self):
        try:
            with open(self.user_sources_file, 'w', encoding='utf-8') as f:
                json.dump(self.user_sources, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"ä¿å­˜ç”¨æˆ·æºå¤±è´¥: {e}")

    def _load_nodes_from_file(self):
        """
        ğŸ”¥ å¯åŠ¨æ—¶å…ˆä»æœ¬åœ°ç¼“å­˜å¿«é€ŸåŠ è½½ï¼Œç„¶ååœ¨åå°ä» Supabase æ›´æ–°
        è¿™æ ·å¯ä»¥ä¿è¯å¯åŠ¨é€Ÿåº¦ï¼ŒåŒæ—¶ä¹Ÿèƒ½è·å–æœ€æ–°æ•°æ®
        """
        # å…ˆä»æœ¬åœ°æ–‡ä»¶å¿«é€ŸåŠ è½½ï¼ˆä¿è¯å¯åŠ¨é€Ÿåº¦ï¼‰
        self._load_nodes_from_local_file()
        
        # ç„¶åå®‰æ’ä¸€ä¸ªåå°ä»»åŠ¡ä» Supabase æ›´æ–°
        # è¿™ä¼šåœ¨äº‹ä»¶å¾ªç¯å¯åŠ¨åæ‰§è¡Œ
        try:
            import asyncio
            loop = asyncio.get_event_loop()
            if loop.is_running():
                # FastAPI ç¯å¢ƒï¼šåˆ›å»ºåå°ä»»åŠ¡
                asyncio.create_task(self._load_and_merge_from_supabase())
        except Exception as e:
            self.add_log(f"âš ï¸ è®¾ç½® Supabase åŠ è½½ä»»åŠ¡å¤±è´¥: {e}", "WARNING")
    
    async def _load_and_merge_from_supabase(self):
        """åå°ä» Supabase åŠ è½½èŠ‚ç‚¹å¹¶åˆå¹¶åˆ°å†…å­˜"""
        await asyncio.sleep(5)  # ç­‰å¾… 5 ç§’ï¼Œè®©ç³»ç»Ÿå®Œå…¨å¯åŠ¨
        
        import os
        try:
            url = os.getenv("SUPABASE_URL", "")
            key = os.getenv("SUPABASE_SERVICE_ROLE_KEY") or os.getenv("SUPABASE_KEY", "")
            
            if not url or not key:
                self.add_log("âš ï¸ Supabase å‡­è¯æœªé…ç½®ï¼Œè·³è¿‡æ•°æ®åº“åŠ è½½", "WARNING")
                return
            
            from supabase import create_client
            supabase = create_client(url, key)
            
            # æŸ¥è¯¢æœ€æ–°çš„èŠ‚ç‚¹æ•°æ®ï¼ŒæŒ‰ speed é™åºï¼Œé™åˆ¶ 200 æ¡
            self.add_log("â˜ï¸ æ­£åœ¨ä» Supabase æ•°æ®åº“åŠ è½½èŠ‚ç‚¹...", "INFO")
            response = supabase.table("nodes").select("*").order("speed", desc=True).limit(200).execute()
            
            if response.data:
                loaded_nodes = []
                for row in response.data:
                    # ä» content å­—æ®µæå–å®Œæ•´èŠ‚ç‚¹æ•°æ®
                    node = row.get('content', {})
                    if isinstance(node, dict) and node.get('host'):
                        # è¡¥å……æ•°æ®åº“ä¸­çš„è¯„åˆ†æ•°æ®
                        node['mainland_score'] = row.get('mainland_score', 0)
                        node['overseas_score'] = row.get('overseas_score', 0)
                        node['mainland_latency'] = row.get('mainland_latency', 9999)
                        node['overseas_latency'] = row.get('overseas_latency', 9999)
                        node['alive'] = True  # æ•°æ®åº“ä¸­çš„éƒ½æ˜¯éªŒè¯è¿‡çš„æ´»è·ƒèŠ‚ç‚¹
                        
                        # åº”ç”¨å›½å®¶è¯†åˆ«
                        country = self._normalize_country(node.get('country', 'UNK'))
                        if country == 'UNK':
                            country = self._guess_country_from_name(node.get('name', ''))
                        node['country'] = country
                        
                        loaded_nodes.append(node)
                
                if loaded_nodes:
                    # ğŸ”¥ åˆå¹¶ç­–ç•¥ï¼šç”¨æ•°æ®åº“èŠ‚ç‚¹æ›¿æ¢æœ¬åœ°èŠ‚ç‚¹
                    # æŒ‰ host:port å»é‡ï¼Œæ•°æ®åº“ä¼˜å…ˆ
                    existing_keys = {f"{n.get('host')}:{n.get('port')}" for n in self.nodes}
                    db_keys = set()
                    merged_nodes = []
                    
                    # å…ˆåŠ å…¥æ•°æ®åº“èŠ‚ç‚¹ï¼ˆä¼˜å…ˆï¼‰
                    for node in loaded_nodes:
                        key = f"{node.get('host')}:{node.get('port')}"
                        if key not in db_keys:
                            db_keys.add(key)
                            merged_nodes.append(node)
                    
                    # å†åŠ å…¥æœ¬åœ°èŠ‚ç‚¹ä¸­ä¸åœ¨æ•°æ®åº“çš„éƒ¨åˆ†
                    for node in self.nodes:
                        key = f"{node.get('host')}:{node.get('port')}"
                        if key not in db_keys:
                            merged_nodes.append(node)
                    
                    old_count = len(self.nodes)
                    self.nodes = merged_nodes
                    self.add_log(f"â˜ï¸ ä» Supabase åŠ è½½äº† {len(loaded_nodes)} ä¸ªèŠ‚ç‚¹ï¼Œåˆå¹¶åå…± {len(self.nodes)} ä¸ª (åŸ {old_count} ä¸ª)", "SUCCESS")
                    return
            
            self.add_log("âš ï¸ Supabase ä¸­æ— èŠ‚ç‚¹æ•°æ®", "WARNING")
            
        except ImportError:
            self.add_log("âš ï¸ supabase åº“æœªå®‰è£…", "WARNING")
        except Exception as e:
            self.add_log(f"âš ï¸ Supabase æŸ¥è¯¢å¤±è´¥: {e}", "WARNING")

    async def _load_nodes_from_supabase(self):
        """ä» Supabase æ•°æ®åº“åŠ è½½èŠ‚ç‚¹ï¼ˆå·²åºŸå¼ƒï¼Œä½¿ç”¨ _load_and_merge_from_supabaseï¼‰"""
        await self._load_and_merge_from_supabase()
    
    def _load_nodes_from_local_file(self):
        """ä»æœ¬åœ° JSON æ–‡ä»¶åŠ è½½èŠ‚ç‚¹ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        if os.path.exists(VERIFIED_NODES_FILE):
            try:
                with open(VERIFIED_NODES_FILE, "r") as f:
                    loaded_nodes = json.load(f)
                    for node in loaded_nodes:
                        # ğŸ”¥ ä¼˜å…ˆå°è¯•è§„èŒƒåŒ–å›½å®¶åç§°
                        country = self._normalize_country(node.get('country', 'UNK'))
                        
                        # ğŸ”¥ å¦‚æœä»ä¸ºUNKï¼Œå°è¯•ä»IPæŸ¥è¯¢æˆ–ä»åç§°çŒœæµ‹
                        if country == 'UNK':
                            country = self._get_country_code_from_ip(node.get('host', ''))
                            if country == 'UNK':
                                country = self._guess_country_from_name(node.get('name', ''))
                        
                        node['country'] = country
                    self.nodes = loaded_nodes
                self.add_log(f"ğŸ“¥ ä»æœ¬åœ°ç¼“å­˜åŠ è½½äº† {len(loaded_nodes)} ä¸ªèŠ‚ç‚¹", "SUCCESS")
            except Exception as e:
                self.add_log(f"âš ï¸ åŠ è½½æœ¬åœ°ç¼“å­˜å¤±è´¥: {e}", "WARNING")

    def _save_nodes_to_file(self):
        try:
            alive_nodes = self.get_alive_nodes()
            sorted_nodes = sorted(alive_nodes, key=lambda x: x.get('test_results', {}).get('total_score', 0),
                                  reverse=True)
            top_nodes = sorted_nodes[:150]
            with open(VERIFIED_NODES_FILE, "w") as f:
                json.dump(top_nodes, f, indent=2)
            self.add_log(f"ğŸ’¾ å·²å°† Top {len(top_nodes)} èŠ‚ç‚¹ä¿å­˜åˆ°ç¼“å­˜", "INFO")
        except Exception as e:
            self.add_log(f"âš ï¸ ä¿å­˜èŠ‚ç‚¹åˆ°æ–‡ä»¶å¤±è´¥: {e}", "WARNING")

    def _get_default_sources(self) -> List[str]:
        return [
            # ğŸ”¥ è¶…é«˜ä¼˜å…ˆçº§: æ ¸å¿ƒé«˜è´¨é‡æº (é¢‘ç¹æ›´æ–°ï¼Œæ•°åƒèŠ‚ç‚¹)
            # Epodonios: 5åˆ†é’Ÿæ›´æ–°ï¼Œæ”¯æŒvmess/vless/trojan/ss/ssr
            "https://github.com/Epodonios/v2ray-configs/raw/main/All_Configs_Sub.txt",
            "https://github.com/Epodonios/v2ray-configs/raw/main/Splitted-By-Protocol/vmess.txt",
            "https://github.com/Epodonios/v2ray-configs/raw/main/Splitted-By-Protocol/vless.txt",
            
            # ebrasha: 30åˆ†é’Ÿæ›´æ–°ï¼ŒèŠ‚ç‚¹ç»è¿‡è¿‡æ»¤å’Œæµ‹è¯•
            "https://raw.githubusercontent.com/ebrasha/free-v2ray-public-list/refs/heads/main/all_extracted_configs.txt",
            "https://raw.githubusercontent.com/ebrasha/free-v2ray-public-list/refs/heads/main/vmess_configs.txt",
            "https://raw.githubusercontent.com/ebrasha/free-v2ray-public-list/refs/heads/main/vless_configs.txt",
            
            # mahdibland: 12å°æ—¶æ›´æ–°ï¼Œå¤§è§„æ¨¡èŠ‚ç‚¹æ± (5000+)ï¼Œé€Ÿåº¦æµ‹è¯•è¿‡æ»¤
            "https://raw.githubusercontent.com/mahdibland/ShadowsocksAggregator/master/Eternity.txt",
            "https://raw.githubusercontent.com/mahdibland/ShadowsocksAggregator/master/sub/sub_merge.txt",
            
            # ğŸ”¥ é«˜ä¼˜å…ˆçº§: æŒ‰å›½å®¶è¿‡æ»¤çš„ä¸“ç”¨æº (80+å›½å®¶)
            # ä¸»è¦å›½å®¶è®¢é˜… (mixedåè®®ï¼Œæ”¯æŒå¤šç§)
            "https://raw.githubusercontent.com/freefq/free/master/v2",
            "https://github.com/free-nodes/v2rayfree",
            "https://clashgithub.com/",
            "https://github.com/V2RayRoot/V2RayConfig",
            "https://www.v2nodes.com/",
            "https://raw.githubusercontent.com/learnhard-cn/free_proxy_ss/main/free",
            "https://raw.githubusercontent.com/Pawdroid/Free-servers/main/sub",
            "https://raw.githubusercontent.com/aiboboxx/v2rayfree/main/v2",
            "https://raw.githubusercontent.com/mfuu/v2ray/master/v2ray",
            "https://raw.githubusercontent.com/ermaozi/get_subscribe/main/subscribe/v2ray.txt",
            "https://raw.githubusercontent.com/vveg26/get_proxy/main/subscribe/clash.yaml",
            "https://raw.githubusercontent.com/peasoft/NoWars/main/result.txt",
        ]

    def add_log(self, message: str, level: str = "INFO"):
        timestamp = datetime.now().strftime("%H:%M:%S")
        self.logs.insert(0, f"[{timestamp}] {message}")
        if len(self.logs) > 100: self.logs.pop()
        logger.info(message)

    def add_user_source(self, url: str):
        if url in self.sources:
            return False, "è¯¥æºå·²å­˜åœ¨"

        self.user_sources.append(url)
        self.sources.append(url)
        self.source_stats[url] = {"is_disabled": False, "disabled_at": 0, "retry_fails": 0}
        self._save_user_sources()
        self.add_log(f"â• æ·»åŠ æ–°æº: {url[:30]}...", "SUCCESS")
        return True, "æ·»åŠ æˆåŠŸ"

    async def _fetch_all_subscriptions(self) -> tuple:
        """
        è¿”å›: (æ‰€æœ‰èŠ‚ç‚¹é“¾æ¥åˆ—è¡¨, æºè´¡çŒ®å­—å…¸)
        """
        all_nodes = []
        self.scan_cycle_count += 1
        target_urls = []
        for url in self.sources:
            stats = self.source_stats.get(url, {"is_disabled": False, "disabled_at": 0, "retry_fails": 0})
            if stats["is_disabled"]:
                if (self.scan_cycle_count - stats["disabled_at"]) >= 10:
                    stats["is_disabled"] = False
                    stats["retry_fails"] = 0
                    target_urls.append(url)
                    self.add_log(f"ğŸ”„ æºå·²è§£å°: {url[:30]}...", "INFO")
            else:
                target_urls.append(url)

        if not target_urls: 
            return [], {}

        # ç”¨äºè¿½è¸ªæ¯ä¸ªæºçš„è´¡çŒ® + èŠ‚ç‚¹æ˜ å°„
        source_nodes_map = {}
        source_node_mapping = {}  # æ–°å¢ï¼šè®°å½•èŠ‚ç‚¹å±äºå“ªä¸ªæº

        async def fetch_source(url):
            try:
                content = await self.link_scraper.scrape_links_from_url(url)
                if content:
                    source_name = url.replace("https://", "").replace("http://", "")[:40]
                    self.add_log(f"âœ… [{source_name}] æŠ“å– {len(content)} ä¸ªèŠ‚ç‚¹", "SUCCESS")
                    if url in self.source_stats: self.source_stats[url]['retry_fails'] = 0
                    source_nodes_map[url] = len(content)
                    source_node_mapping[url] = content  # ä¿å­˜èŠ‚ç‚¹-æºæ˜ å°„
                    return content
                else:
                    raise Exception("Empty")
            except Exception as e:
                source_name = url.replace("https://", "").replace("http://", "")[:40]
                self.add_log(f"âŒ [{source_name}] æŠ“å–å¤±è´¥: {str(e)[:30]}", "WARNING")
                if url in self.source_stats:
                    stats = self.source_stats[url]
                    stats['retry_fails'] += 1
                    if stats['retry_fails'] >= 3:
                        stats['is_disabled'] = True
                        stats['disabled_at'] = self.scan_cycle_count
                        self.add_log(f"ğŸš« [{source_name}] å·²ç¦ç”¨(è¿ç»­å¤±è´¥3æ¬¡)", "WARNING")
            return []

        # ğŸ”¥ æ·»åŠ  Semaphore é™æµï¼Œæœ€å¤šåŒæ—¶ 10 ä¸ªå¹¶å‘æºè¯·æ±‚ï¼Œé˜²æ­¢è¿æ¥è€—å°½
        semaphore = asyncio.Semaphore(10)
        
        async def fetch_source_with_limit(url):
            async with semaphore:
                return await fetch_source(url)
        
        tasks = [fetch_source_with_limit(src) for src in target_urls]
        results = await asyncio.gather(*tasks)
        for i, res in enumerate(results):
            all_nodes.extend(res)
        
        # è®°å½•æºç»Ÿè®¡æ€»ç»“
        total_from_sources = sum(source_nodes_map.values())
        self.add_log(f"ğŸ“Š æœ¬æ¬¡çˆ¬è™«å‘¨æœŸ: ä» {len(source_nodes_map)}/{len(target_urls)} ä¸ªæºè·å– {total_from_sources} ä¸ªèŠ‚ç‚¹", "INFO")
        
        # ä¿å­˜æºè´¡çŒ®æ—¥å¿—
        if not hasattr(self, 'source_contribution_log'):
            self.source_contribution_log = []
        self.source_contribution_log.append({
            'cycle': self.scan_cycle_count,
            'timestamp': datetime.now().isoformat(),
            'sources': source_nodes_map,
            'total_nodes': total_from_sources
        })
        
        # ğŸ’¾ ä¿å­˜æºç¼“å­˜åˆ°Supabase
        try:
            await self.persistence.save_sources_cache(source_node_mapping, source_nodes_map)
            self.add_log(f"ğŸ’¾ æºç¼“å­˜å·²ä¿å­˜åˆ°Supabase", "SUCCESS")
        except Exception as e:
            self.add_log(f"âš ï¸ æºç¼“å­˜ä¿å­˜å¤±è´¥: {e}", "WARNING")
        
        return list(set(all_nodes)), source_node_mapping

    async def _fetch_china_nodes(self) -> List[Dict]:
        nodes = []
        try:
            from .china_hunter import ChinaHunter
            hunter = ChinaHunter()
            self.add_log(f"ğŸ‡¨ğŸ‡³ [CNçŒæ‰‹] æ­£åœ¨ä» {len(hunter.sources)} ä¸ªæºæŠ“å–...", "INFO")
            nodes = await hunter.fetch_all()
            if nodes:
                self.add_log(f"ğŸ“¥ [CNçŒæ‰‹] æ•è· {len(nodes)} ä¸ªæ½œåœ¨CNèŠ‚ç‚¹", "SUCCESS")
        except:
            pass
        return nodes

    def _get_country_code_from_ip(self, ip: str) -> str:
        """é€šè¿‡IPåœ°å€æŸ¥è¯¢å›½å®¶ä»£ç ï¼ˆå¼‚æ­¥æ‰§è¡Œï¼Œä½¿ç”¨ç¼“å­˜ï¼‰"""
        try:
            # é¦–å…ˆæ£€æŸ¥ç¼“å­˜
            if hasattr(self, 'ip_country_cache') and ip in self.ip_country_cache:
                return self.ip_country_cache[ip]
            
            # ä½¿ç”¨åŒæ­¥HTTPè¯·æ±‚æŸ¥è¯¢ï¼ˆ3ç§’è¶…æ—¶ï¼‰
            import httpx
            import socket
            
            # å¿«é€ŸDNSæ£€æŸ¥ï¼šå¦‚æœåŸŸåæœ‰å›½å®¶ä»£ç çº¿ç´¢ï¼Œç›´æ¥è¿”å›
            try:
                # ä¸åšå®é™…DNSæŸ¥è¯¢ï¼Œé¿å…è€—æ—¶
                pass
            except:
                pass
            
            try:
                response = httpx.get(f"https://ipapi.co/{ip}/json/", timeout=2)
                if response.status_code == 200:
                    data = response.json()
                    country_code = data.get('country_code', 'UNK')
                    if country_code and country_code != 'UNK':
                        country_code = country_code.upper()
                        # ç¼“å­˜ç»“æœ
                        if not hasattr(self, 'ip_country_cache'):
                            self.ip_country_cache = {}
                        self.ip_country_cache[ip] = country_code
                        return country_code
            except Exception as e:
                # å¿½ç•¥é”™è¯¯ï¼Œå¿«é€Ÿè¿”å›UNK
                pass
        except:
            pass
        return 'UNK'

    def _normalize_country(self, raw_country: str) -> str:
        if not raw_country: return 'UNK'
        upper_raw = raw_country.upper().strip()
        
        # ğŸ”¥ é¦–å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯ 2 å­—æ¯ä»£ç 
        if len(upper_raw) == 2 and upper_raw.isalpha():
            return upper_raw
        
        # ğŸ”¥ ç„¶åè¿›è¡Œå­ä¸²åŒ¹é…ï¼ˆç›´æ¥æŸ¥æ‰¾ï¼Œä¸å¼ºåˆ¶å•è¯è¾¹ç•Œï¼‰
        for name, code in NAME_TO_CODE.items():
            if name in upper_raw or upper_raw in name:
                return code
        
        return 'UNK'

    def _guess_country_from_name(self, name: str) -> str:
        """ä»èŠ‚ç‚¹åç§°ä¸­çŒœæµ‹å›½å®¶ï¼ˆå¤‡ç”¨ï¼ŒIPæŸ¥è¯¢å¤±è´¥æ—¶ä½¿ç”¨ï¼‰"""
        if not name: return 'UNK'
        upper_name = name.upper()
        
        # ğŸ”¥ æ‰©å±•ç‰ˆæœ¬çš„å›½å®¶å…³é”®è¯åŒ¹é…è¡¨ï¼ˆåŒ…å«åŸå¸‚ã€åˆ«åã€ä¸­æ–‡ç­‰ï¼‰
        country_patterns = [
            # äºšæ´²
            ('CN', ['CN', 'CHINA', 'ä¸­å›½', 'å›å›½', 'BEIJING', 'SHANGHAI', 'SHENZHEN', 'CHONGQING', 'HANGZHOU', 'WUHAN', 'CHENG', 'XIAN', 'SICHUAN', 'JIANGSU', 'GUANGDONG']),
            ('HK', ['HK', 'HONG KONG', 'HONGKONG', 'é¦™æ¸¯', 'HKG']),
            ('TW', ['TW', 'TAIWAN', 'TAIPEI', 'å°æ¹¾', 'TPE']),
            ('JP', ['JP', 'JAPAN', 'æ—¥æœ¬', 'TOKYO', 'OSAKA', 'YOKOHAMA', 'KOBE', 'TYO', 'NRT', 'KIX']),
            ('SG', ['SG', 'SINGAPORE', 'æ–°åŠ å¡', 'SIN']),
            ('KR', ['KR', 'KOREA', 'éŸ©å›½', 'SEOUL', 'BUSAN', 'ICN', 'PUS']),
            ('TH', ['TH', 'THAILAND', 'æ³°å›½', 'BANGKOK', 'BKK']),
            ('MY', ['MY', 'MALAYSIA', 'é©¬æ¥è¥¿äºš', 'KUALA LUMPUR', 'KUL']),
            ('PH', ['PH', 'PHILIPPINES', 'è²å¾‹å®¾', 'MANILA', 'MNL']),
            ('VN', ['VN', 'VIETNAM', 'è¶Šå—', 'HANOI', 'HO CHI MINH', 'HAN', 'SGN']),
            ('ID', ['ID', 'INDONESIA', 'å°å°¼', 'JAKARTA', 'CGK']),
            ('IN', ['IN', 'INDIA', 'å°åº¦', 'DELHI', 'BOMBAY', 'MUMBAI', 'BANGALORE', 'DEL', 'BOM']),
            ('PK', ['PK', 'PAKISTAN', 'å·´åŸºæ–¯å¦', 'ISLAMABAD', 'KARACHI']),
            ('BD', ['BD', 'BANGLADESH', 'å­ŸåŠ æ‹‰', 'DHAKA']),
            ('LK', ['LK', 'SRI LANKA', 'æ–¯é‡Œå…°å¡', 'COLOMBO', 'CMB']),
            # ä¸­ä¸œ
            ('TR', ['TR', 'TURKEY', 'åœŸè€³å…¶', 'ISTANBUL', 'ANKARA', 'IST']),
            ('AE', ['AE', 'UAE', 'UNITED ARAB EMIRATES', 'é˜¿è”é…‹', 'DUBAI', 'ABU DHABI', 'DXB']),
            ('SA', ['SA', 'SAUDI ARABIA', 'æ²™ç‰¹', 'RIYADH', 'JEDDAH', 'RUH']),
            ('IL', ['IL', 'ISRAEL', 'ä»¥è‰²åˆ—', 'TEL AVIV', 'JERUSALEM', 'TLV']),
            ('JO', ['JO', 'JORDAN', 'çº¦æ—¦', 'AMMAN', 'AMM']),
            # æ¬§æ´²
            ('GB', ['GB', 'UK', 'UNITED KINGDOM', 'è‹±å›½', 'LONDON', 'MANCHESTER', 'EDINBURGH', 'LHR', 'LGW']),
            ('DE', ['DE', 'GERMANY', 'å¾·å›½', 'FRANKFURT', 'BERLIN', 'MUNICH', 'HAMBURG', 'FRA', 'BER']),
            ('FR', ['FR', 'FRANCE', 'æ³•å›½', 'PARIS', 'LYON', 'MARSEILLE', 'CDG', 'ORY']),
            ('IT', ['IT', 'ITALY', 'æ„å¤§åˆ©', 'MILAN', 'ROME', 'VENICE', 'MXP', 'FCO']),
            ('ES', ['ES', 'SPAIN', 'è¥¿ç­ç‰™', 'MADRID', 'BARCELONA', 'VALENCIA', 'MAD', 'BCN']),
            ('NL', ['NL', 'NETHERLANDS', 'è·å…°', 'AMSTERDAM', 'ROTTERDAM', 'AMS']),
            ('BE', ['BE', 'BELGIUM', 'æ¯”åˆ©æ—¶', 'BRUSSELS', 'ANTWERP', 'BRU']),
            ('PT', ['PT', 'PORTUGAL', 'è‘¡è„ç‰™', 'LISBON', 'PORTO', 'LIS']),
            ('PL', ['PL', 'POLAND', 'æ³¢å…°', 'WARSAW', 'KRAKOW', 'WAW']),
            ('SE', ['SE', 'SWEDEN', 'ç‘å…¸', 'STOCKHOLM', 'STOCKHOLM', 'ARN']),
            ('NO', ['NO', 'NORWAY', 'æŒªå¨', 'OSLO', 'OSLO', 'OSL']),
            ('DK', ['DK', 'DENMARK', 'ä¸¹éº¦', 'COPENHAGEN', 'CPH']),
            ('FI', ['FI', 'FINLAND', 'èŠ¬å…°', 'HELSINKI', 'HEL']),
            ('CH', ['CH', 'SWITZERLAND', 'ç‘å£«', 'ZURICH', 'GENEVA', 'ZRH']),
            ('AT', ['AT', 'AUSTRIA', 'å¥¥åœ°åˆ©', 'VIENNA', 'VIENNA', 'VIE']),
            ('CZ', ['CZ', 'CZECH', 'CZECHOSLOVAKIA', 'æ·å…‹', 'PRAGUE', 'PRG']),
            ('HU', ['HU', 'HUNGARY', 'åŒˆç‰™åˆ©', 'BUDAPEST', 'BUD']),
            ('RO', ['RO', 'ROMANIA', 'ç½—é©¬å°¼äºš', 'BUCHAREST', 'BUH']),
            ('GR', ['GR', 'GREECE', 'å¸Œè…Š', 'ATHENS', 'THESSALONIKI', 'ATH']),
            ('RU', ['RU', 'RUSSIA', 'ä¿„ç½—æ–¯', 'MOSCOW', 'ST PETERSBURG', 'VLADIVOSTOK', 'SVO', 'LED']),
            ('UA', ['UA', 'UKRAINE', 'ä¹Œå…‹å…°', 'KYIV', 'KHARKIV', 'KBP']),
            ('BG', ['BG', 'BULGARIA', 'ä¿åŠ åˆ©äºš', 'SOFIA', 'SOF']),
            # åŒ—ç¾
            ('US', ['US', 'USA', 'AMERICA', 'UNITED STATES', 'ç¾å›½', 'NEW YORK', 'LOS ANGELES', 'CHICAGO', 'DALLAS', 'SEATTLE', 'MIAMI', 'DENVER', 'SFO', 'LAX', 'JFK', 'ORD', 'DFW']),
            ('CA', ['CA', 'CANADA', 'åŠ æ‹¿å¤§', 'TORONTO', 'VANCOUVER', 'MONTREAL', 'CALGARY', 'YYZ', 'YVR']),
            ('MX', ['MX', 'MEXICO', 'å¢¨è¥¿å“¥', 'MEXICO CITY', 'MEX']),
            # å—ç¾
            ('BR', ['BR', 'BRAZIL', 'å·´è¥¿', 'SAO PAULO', 'RIO DE JANEIRO', 'GIG', 'GRU']),
            ('AR', ['AR', 'ARGENTINA', 'é˜¿æ ¹å»·', 'BUENOS AIRES', 'AEP']),
            ('CL', ['CL', 'CHILE', 'æ™ºåˆ©', 'SANTIAGO', 'SCL']),
            ('CO', ['CO', 'COLOMBIA', 'å“¥ä¼¦æ¯”äºš', 'BOGOTA', 'BOG']),
            ('PE', ['PE', 'PERU', 'ç§˜é²', 'LIMA', 'LIM']),
            ('VE', ['VE', 'VENEZUELA', 'å§”å†…ç‘æ‹‰', 'CARACAS', 'CCS']),
            # å¤§æ´‹æ´²
            ('AU', ['AU', 'AUSTRALIA', 'æ¾³æ´²', 'SYDNEY', 'MELBOURNE', 'BRISBANE', 'SYD', 'MEL']),
            ('NZ', ['NZ', 'NEW ZEALAND', 'æ–°è¥¿å…°', 'AUCKLAND', 'WELLINGTON', 'AKL']),
            # éæ´²
            ('ZA', ['ZA', 'SOUTH AFRICA', 'å—é', 'JOHANNESBURG', 'CAPE TOWN', 'JNB']),
            ('EG', ['EG', 'EGYPT', 'åŸƒåŠ', 'CAIRO', 'ALEXANDRIA', 'CAI']),
            ('NG', ['NG', 'NIGERIA', 'å°¼æ—¥åˆ©äºš', 'LAGOS', 'LOS']),
        ]
        
        # ğŸ”¥ æ”¹è¿›çš„åŒ¹é…é€»è¾‘ï¼šä¸è¦æ±‚å•è¯è¾¹ç•Œï¼Œåªè¦åŒ¹é…å°±è¡Œ
        for country, keywords in country_patterns:
            for keyword in keywords:
                if keyword in upper_name:
                    return country
        
        # æœ€åå¤‡ç”¨ï¼šç›´æ¥æ£€æŸ¥æ˜¯å¦åŒ…å« 2 å­—æ¯å›½å®¶ä»£ç ï¼ˆå¦‚ TRã€IT ç­‰ï¼‰
        if len(upper_name) >= 2:
            # ä»åå¾€å‰æ‰«ï¼Œå¯»æ‰¾ç±»ä¼¼ (TR)ã€-TR-ã€TR: çš„æ¨¡å¼
            import re
            codes_match = re.findall(r'[(\-\s]([A-Z]{2})[\)\-\s\:]', f'-{upper_name}-')
            if codes_match:
                potential_code = codes_match[0]
                # æ£€æŸ¥è¿™æ˜¯å¦æ˜¯æœ‰æ•ˆçš„å›½å®¶ä»£ç 
                for name, code in NAME_TO_CODE.items():
                    if code == potential_code:
                        return potential_code
        
        # é»˜è®¤è¿”å›æœªçŸ¥
        return 'UNK'

    async def scan_cycle(self):
        """
        ğŸ”¥ P3ä¼˜åŒ–: çˆ¬è™«æ”¹ä¸ºä»…è´Ÿè´£çˆ¬å–å’Œå…¥é˜Ÿï¼Œä¸è¿›è¡Œæ£€æµ‹
        æ–°èŠ‚ç‚¹å…¥é˜Ÿåˆ°å¾…æ£€æµ‹é˜Ÿåˆ—ï¼Œç”±ç‹¬ç«‹çš„æ‰¹é‡æ£€æµ‹ä»»åŠ¡å¤„ç†
        """
        if self.is_scanning: 
            self.add_log("âš ï¸ çˆ¬è™«å·²åœ¨è¿è¡Œä¸­ï¼Œè·³è¿‡æœ¬æ¬¡æ‰§è¡Œ", "WARNING")
            return
        
        self.is_scanning = True
        self.add_log("ğŸš€ å¼€å§‹å…¨ç½‘èŠ‚ç‚¹çˆ¬è™«ï¼ˆä»…çˆ¬å–ï¼Œä¸æ£€æµ‹ï¼‰...", "INFO")
        
        try:
            # ğŸ”¥ ä»…æ‰§è¡Œçˆ¬å–ï¼Œä¸è¿›è¡Œæ£€æµ‹
            fetch_task = asyncio.create_task(self._fetch_all_subscriptions())
            china_task = asyncio.create_task(self._fetch_china_nodes())
            
            # å¹¶è¡Œè·å–ç»“æœ
            result = await fetch_task
            cn_nodes = await china_task
            
            # å¤„ç†è¿”å›çš„èŠ‚ç‚¹é“¾æ¥å’Œæºæ˜ å°„
            if isinstance(result, tuple):
                raw_nodes, source_node_mapping = result
            else:
                raw_nodes = result
                source_node_mapping = {}
            
            parsed_nodes = [parse_node_url(url) for url in raw_nodes]
            valid_parsed_nodes = [n for n in parsed_nodes if n]
            
            # ğŸ”¥ æ–°å¢ï¼šä¸ºèŠ‚ç‚¹æ ‡è®°æºä¿¡æ¯
            for node in valid_parsed_nodes:
                node_link = node.get('share_link', '')
                for source_url, node_links in source_node_mapping.items():
                    if node_link in node_links:
                        node['source_url'] = source_url
                        break

            all_nodes = cn_nodes + valid_parsed_nodes

            unique_nodes = list({f"{n['host']}:{n['port']}": n for n in all_nodes if n}.values())
            self.add_log(f"ğŸ” çˆ¬è™«è§£ææˆåŠŸ {len(unique_nodes)} ä¸ªå”¯ä¸€èŠ‚ç‚¹", "INFO")
            
            # ï¿½ ä¿å­˜å·²è§£æèŠ‚ç‚¹ç¼“å­˜åˆ°Supabase
            try:
                await self.persistence.save_parsed_nodes(unique_nodes)
                self.add_log(f"ğŸ’¾ å·²è§£æèŠ‚ç‚¹ç¼“å­˜å·²ä¿å­˜åˆ°Supabase ({len(unique_nodes)} ä¸ª)", "SUCCESS")
            except Exception as e:
                self.add_log(f"âš ï¸ èŠ‚ç‚¹ç¼“å­˜ä¿å­˜å¤±è´¥: {e}", "WARNING")
            
            # ï¿½ğŸ”¥ P3: å°†æ–°èŠ‚ç‚¹å…¥é˜Ÿè€Œä¸æ˜¯ç›´æ¥æ£€æµ‹
            new_added = self._add_nodes_to_queue(unique_nodes)
            
            self.add_log(
                f"ğŸ“¥ P3ä¼˜åŒ–: {new_added} ä¸ªæ–°èŠ‚ç‚¹å·²å…¥é˜Ÿï¼Œ"
                f"å½“å‰é˜Ÿåˆ—å¾…æ£€æµ‹: {len(self.pending_nodes_queue)} ä¸ªï¼Œ"
                f"å°†ç”±æ‰¹é‡æ£€æµ‹ä»»åŠ¡é€æ­¥å¤„ç†",
                "SUCCESS"
            )

        except Exception as e:
            self.add_log(f"ğŸ’¥ çˆ¬è™«é”™è¯¯: {e}", "ERROR")
            logger.exception("çˆ¬è™«å¼‚å¸¸")
        finally:
            self.is_scanning = False
    
    def _add_nodes_to_queue(self, nodes: List[Dict]) -> int:
        """
        å°†èŠ‚ç‚¹æ·»åŠ åˆ°å¾…æ£€æµ‹é˜Ÿåˆ—
        æ™ºèƒ½ä¼˜å…ˆçº§: æ–°èŠ‚ç‚¹(ä¼˜å…ˆ) > å¤±è´¥èŠ‚ç‚¹(é‡è¯•) > å¾…é‡éªŒ > å·²æ£€æµ‹
        """
        added_count = 0
        
        for node in nodes:
            node_key = f"{node.get('host')}:{node.get('port')}"
            
            # å¦‚æœå·²ç»åœ¨é˜Ÿåˆ—ä¸­ï¼Œè·³è¿‡
            if node_key in self.pending_nodes_queue:
                continue
            
            # å¦‚æœå·²ç»åœ¨å·²æ£€æµ‹åˆ—è¡¨ä¸­ï¼Œé™ä½ä¼˜å…ˆçº§
            existing = next((n for n in self.nodes if f"{n.get('host')}:{n.get('port')}" == node_key), None)
            
            if existing:
                priority = 2  # å¾…é‡éªŒï¼šå·²æ£€æµ‹è¿‡çš„èŠ‚ç‚¹
            else:
                priority = 0  # æ–°èŠ‚ç‚¹ï¼šæœ€é«˜ä¼˜å…ˆçº§
            
            # æ·»åŠ å›½å®¶ä¿¡æ¯
            if not node.get('country'):
                country = self.geolocation_helper.detect_country_by_name(node.get('name', ''))
                if not country:
                    country = 'UNK'
                node['country'] = country
            
            # å…¥é˜Ÿ
            self.pending_nodes_queue[node_key] = {
                'node': node,
                'retry_count': 0,
                'priority': priority,
                'added_time': time.time()
            }
            added_count += 1
        
        return added_count
    
    async def _batch_test_pending_nodes(self):
        """
        ğŸ”¥ P3: ç‹¬ç«‹çš„æ‰¹é‡æ£€æµ‹ä»»åŠ¡ (æ¯1å°æ—¶æ‰§è¡Œä¸€æ¬¡)
        ä»é˜Ÿåˆ—å–å‡ºä¼˜å…ˆçº§æœ€é«˜çš„1000ä¸ªèŠ‚ç‚¹è¿›è¡Œæ£€æµ‹
        """
        if self.is_batch_testing:
            self.add_log("âš ï¸ æ‰¹é‡æ£€æµ‹å·²åœ¨è¿›è¡Œï¼Œè·³è¿‡æœ¬æ¬¡æ‰§è¡Œ", "WARNING")
            return
        
        if not self.pending_nodes_queue:
            self.add_log("ğŸ“­ å¾…æ£€æµ‹é˜Ÿåˆ—ä¸ºç©ºï¼Œæ— éœ€æ‰§è¡Œæ‰¹é‡æ£€æµ‹", "DEBUG")
            return
        
        self.is_batch_testing = True
        start_time = time.time()
        
        try:
            # ä»é˜Ÿåˆ—å–å‡ºå¾…æ£€æµ‹èŠ‚ç‚¹ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
            nodes_to_test = self._pop_nodes_from_queue(self.batch_size)
            
            if not nodes_to_test:
                self.add_log("ğŸ“­ æ— å¯ç”¨çš„å¾…æ£€æµ‹èŠ‚ç‚¹", "DEBUG")
                return
            
            # ğŸ”¥ å¢å¼ºè¿›åº¦æç¤º
            self.add_log(
                f"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•",
                "INFO"
            )
            self.add_log(
                f"ğŸš€ ã€P3æ‰¹é‡æ£€æµ‹å¼€å§‹ã€‘ä»é˜Ÿåˆ—å–å‡º {len(nodes_to_test)} ä¸ªèŠ‚ç‚¹",
                "INFO"
            )
            self.add_log(
                f"   é˜Ÿåˆ—å‰©ä½™: {len(self.pending_nodes_queue)} ä¸ªèŠ‚ç‚¹å¾…å¤„ç†",
                "INFO"
            )
            self.add_log(
                f"   åè®®åˆ†å¸ƒ: {self._get_protocol_stats(nodes_to_test)}",
                "INFO"
            )
            self.add_log(
                f"   é¢„è®¡è€—æ—¶: 10-20åˆ†é’Ÿï¼ˆæ”¯æŒClashå’ŒXrayå¹¶è¡Œï¼‰",
                "INFO"
            )
            self.add_log(
                f"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•",
                "INFO"
            )
            
            # æ‰§è¡Œæ£€æµ‹
            await self._test_nodes_with_new_system(nodes_to_test)
            
            # è®¡ç®—ç»Ÿè®¡
            elapsed = time.time() - start_time
            available = sum(1 for n in nodes_to_test if n.get('alive'))
            
            # ğŸ”¥ æ–°å¢ï¼šæºçº§åˆ«æˆåŠŸç‡åˆ†æ
            source_success = self._analyze_source_success(nodes_to_test)
            
            self.add_log(
                f"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•",
                "SUCCESS"
            )
            self.add_log(
                f"ğŸ‰ ã€P3æ£€æµ‹å®Œæˆã€‘{len(nodes_to_test)}ä¸ªèŠ‚ç‚¹ â†’ {available}ä¸ªå¯ç”¨",
                "SUCCESS"
            )
            self.add_log(
                f"   è€—æ—¶: {elapsed:.0f}ç§’ | æˆåŠŸç‡: {available/len(nodes_to_test)*100:.1f}%",
                "SUCCESS"
            )
            self.add_log(
                f"   é˜Ÿåˆ—å‰©ä½™: {len(self.pending_nodes_queue)}ä¸ªèŠ‚ç‚¹å¾…å¤„ç†",
                "SUCCESS"
            )
            
            # æ˜¾ç¤ºæºçº§åˆ«æˆåŠŸç‡ Top 5
            if source_success:
                self.add_log(f"ğŸ“Š ã€æºæˆåŠŸç‡ Top 5ã€‘", "INFO")
                for source, stats in source_success[:5]:
                    short_name = source.replace("https://github.com/", "").replace("https://", "")[:40]
                    self.add_log(
                        f"   {short_name}: {stats['success']}/{stats['total']} ({stats['rate']:.1f}%)",
                        "INFO"
                    )
            
            self.add_log(
                f"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•",
                "SUCCESS"
            )
            
            # ğŸ”¥ æ–°å¢ï¼šæ™ºèƒ½ä¼‘æ¯é€»è¾‘
            await self._smart_batch_delay(available, nodes_to_test)
            
        except Exception as e:
            self.add_log(f"âŒ æ‰¹é‡æ£€æµ‹å¼‚å¸¸: {e}", "ERROR")
            logger.exception("æ‰¹é‡æ£€æµ‹å¼‚å¸¸")
        finally:
            self.is_batch_testing = False
    
    def _analyze_source_success(self, nodes_to_test: List[Dict]) -> List[tuple]:
        """
        åˆ†ææ¯ä¸ªæºçš„æˆåŠŸç‡
        è¿”å›: [(æºåœ°å€, {'total': N, 'success': M, 'rate': P}), ...] æŒ‰æˆåŠŸç‡å€’åº
        """
        source_stats = {}
        
        for node in nodes_to_test:
            # è·å–æºä¿¡æ¯ - ä¼˜å…ˆç”¨ source_urlï¼Œæ²¡æœ‰åˆ™ç”¨ add_by
            source = node.get('source_url') or node.get('add_by', 'unknown')
            
            if source not in source_stats:
                source_stats[source] = {'total': 0, 'success': 0}
            
            source_stats[source]['total'] += 1
            if node.get('alive'):
                source_stats[source]['success'] += 1
        
        # è®¡ç®—æˆåŠŸç‡å¹¶æ’åº
        result = []
        for source, stats in source_stats.items():
            stats['rate'] = (stats['success'] / stats['total'] * 100) if stats['total'] > 0 else 0
            result.append((source, stats))
        
        # æŒ‰æˆåŠŸç‡å€’åºæ’åˆ—
        result.sort(key=lambda x: x[1]['rate'], reverse=True)
        
        # ä¿å­˜åˆ°æ—¥å¿—
        if not hasattr(self, 'source_success_log'):
            self.source_success_log = []
        self.source_success_log.append({
            'cycle': self.scan_cycle_count,
            'timestamp': datetime.now().isoformat(),
            'sources': dict(result)
        })
        
        return result
    
    async def _smart_batch_delay(self, available: int, nodes_to_test: List[Dict]):
        """
        ğŸ”¥ æ™ºèƒ½å»¶è¿Ÿå†³ç­–:
        
        1. å¦‚æœæˆåŠŸç‡=0% â†’ ç«‹å³è¿›å…¥ä¸‹ä¸€æ‰¹ (ç»§ç»­ä¸ä¼‘æ¯)
        2. å¦‚æœå·²æœ‰10+å¯ç”¨èŠ‚ç‚¹ ä¸” æ¥è‡ª2+å›½å®¶ â†’ ä¼‘æ¯5åˆ†é’Ÿ
        3. å¦åˆ™ â†’ ç«‹å³è¿›å…¥ä¸‹ä¸€æ‰¹
        """
        success_rate = available / len(nodes_to_test) * 100 if nodes_to_test else 0
        
        # è·å–å½“å‰å¯ç”¨èŠ‚ç‚¹çš„å›½å®¶åˆ†å¸ƒ
        alive_nodes = [n for n in self.nodes if n.get('alive')]
        if alive_nodes:
            countries = set(n.get('country', 'UNK') for n in alive_nodes)
        else:
            countries = set()
        
        self.add_log(
            f"ğŸ“Š æ™ºèƒ½å†³ç­–: æˆåŠŸç‡ {success_rate:.1f}% | å¯ç”¨èŠ‚ç‚¹ {len(alive_nodes)} | å›½å®¶æ•° {len(countries)}",
            "INFO"
        )
        
        # è§„åˆ™1: æˆåŠŸç‡ä¸º0% â†’ ç«‹å³ç»§ç»­ï¼ˆä¸ä¼‘æ¯ï¼‰
        if success_rate == 0.0:
            self.add_log(
                f"âš¡ ã€è§„åˆ™1è§¦å‘ã€‘æˆåŠŸç‡0% â†’ ç«‹å³è¿›å…¥ä¸‹ä¸€æ‰¹æ£€æµ‹ï¼Œæ— ä¼‘æ¯",
                "WARNING"
            )
            if self.pending_nodes_queue:
                # ç«‹å³é‡æ–°è¿›è¡Œæ£€æµ‹
                asyncio.create_task(self._batch_test_pending_nodes())
            return
        
        # è§„åˆ™2: å·²æœ‰10+èŠ‚ç‚¹ ä¸” æ¥è‡ª2+å›½å®¶ â†’ ä¼‘æ¯5åˆ†é’Ÿ
        if len(alive_nodes) >= 10 and len(countries) >= 2:
            self.add_log(
                f"âœ… ã€è§„åˆ™2è§¦å‘ã€‘å·²æœ‰ {len(alive_nodes)} ä¸ªèŠ‚ç‚¹ ({', '.join(list(countries)[:3])}) " +
                f"â†’ ä¼‘æ¯ 5 ç§’åç»§ç»­",
                "SUCCESS"
            )
            await asyncio.sleep(5)  # ä¼‘æ¯5ç§’
            if self.pending_nodes_queue:
                asyncio.create_task(self._batch_test_pending_nodes())
            return
        
        # è§„åˆ™3: å…¶ä»–æƒ…å†µ â†’ ç«‹å³ç»§ç»­
        self.add_log(
            f"âš¡ ã€è§„åˆ™3è§¦å‘ã€‘èŠ‚ç‚¹ä¸è¶³/å›½å®¶ä¸è¶³ â†’ ç«‹å³è¿›å…¥ä¸‹ä¸€æ‰¹æ£€æµ‹ï¼Œæ— ä¼‘æ¯",
            "INFO"
        )
        if self.pending_nodes_queue:
            asyncio.create_task(self._batch_test_pending_nodes())
    
    def _get_protocol_stats(self, nodes: List[Dict]) -> str:
        """è·å–èŠ‚ç‚¹çš„åè®®ç»Ÿè®¡"""
        protocol_count = {}
        for node in nodes:
            proto = node.get('protocol', 'unknown').lower()
            protocol_count[proto] = protocol_count.get(proto, 0) + 1
        
        stats = []
        for proto, count in sorted(protocol_count.items(), key=lambda x: -x[1])[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
            stats.append(f"{proto}:{count}")
        
        return ", ".join(stats) if stats else "unknown"
    
    def _pop_nodes_from_queue(self, count: int) -> List[Dict]:
        """
        ä»é˜Ÿåˆ—æŒ‰ä¼˜å…ˆçº§å–å‡ºèŠ‚ç‚¹
        ä¼˜å…ˆçº§: æ–°èŠ‚ç‚¹(0) > å¤±è´¥å¾…é‡è¯•(1) > å¾…é‡éªŒ(2) > å·²æ£€æµ‹(3)
        """
        if not self.pending_nodes_queue:
            return []
        
        # æŒ‰ä¼˜å…ˆçº§æ’åº
        sorted_items = sorted(
            self.pending_nodes_queue.items(),
            key=lambda x: (x[1]['priority'], x[1]['added_time'])
        )
        
        # å–å‡ºå‰ count ä¸ª
        popped_nodes = []
        keys_to_remove = []
        
        for node_key, node_info in sorted_items[:count]:
            popped_nodes.append(node_info['node'])
            keys_to_remove.append(node_key)
        
        # ä»é˜Ÿåˆ—åˆ é™¤å·²å–å‡ºçš„èŠ‚ç‚¹
        for key in keys_to_remove:
            del self.pending_nodes_queue[key]
        
        return popped_nodes
    
    async def _sync_nodes_to_storage(self):
        """
        ğŸ”¥ P3: ç‹¬ç«‹çš„åŒæ­¥ä»»åŠ¡ (æ¯1å°æ—¶æ‰§è¡Œä¸€æ¬¡)
        å°†å¯ç”¨èŠ‚ç‚¹åŒæ­¥åˆ° viper-node-store
        """
        alive_nodes = [n for n in self.nodes if n.get('alive')]
        
        if not alive_nodes:
            self.add_log("ğŸ“­ æ— å¯ç”¨èŠ‚ç‚¹ï¼Œè·³è¿‡åŒæ­¥", "DEBUG")
            return
        
        self.add_log(f"ğŸ“¤ P3åŒæ­¥: å‡†å¤‡ä¸Šä¼  {len(alive_nodes)} ä¸ªèŠ‚ç‚¹åˆ° viper-node-store...", "INFO")
        
        try:
            success = await upload_to_supabase(alive_nodes)
            if success:
                self.last_sync_time = time.time()
                self.add_log(f"âœ… P3åŒæ­¥å®Œæˆ: {len(alive_nodes)} ä¸ªèŠ‚ç‚¹å·²åŒæ­¥åˆ° viper-node-store", "SUCCESS")
            else:
                self.add_log("âš ï¸ viper-node-store åŒæ­¥å¤±è´¥æˆ–è·³è¿‡", "WARNING")
        except Exception as e:
            self.add_log(f"âŒ P3åŒæ­¥å¼‚å¸¸: {e}", "ERROR")
            logger.exception("åŒæ­¥å¼‚å¸¸")
            
            # ç›´æ¥æ‰§è¡ŒClashæ£€æµ‹ï¼ˆè·³è¿‡äº‘ç«¯è¿‡æ»¤ï¼‰
            clash_nodes = []
            for node in self.nodes:
                protocol = node.get('protocol', '').lower()
                # ğŸ’¡ ä¼˜åŒ–: æ”¯æŒæ‰€æœ‰åè®®ï¼Œè®©Clashå†…æ ¸è‡ªåŠ¨å¤„ç†
                # åŸé™åˆ¶: ['trojan', 'ss', 'shadowsocks', 'socks5', 'socks', 'http', 'https'] (ä»…4ç§)
                # ç°æ”¯æŒ: VMess, VLESS, Hysteria, Hysteria2, WireGuard, TUICç­‰ (11+ç§)
                clash_node = self._convert_to_clash_node(node)
                if clash_node:
                    clash_nodes.append((node, clash_node))
            
            if clash_nodes:
                self.add_log(f"ğŸ“Š Clashå¿«é€Ÿé‡éªŒ: {len(clash_nodes)} ä¸ªå…¼å®¹èŠ‚ç‚¹...", "INFO")
                only_clash_nodes = [cn for _, cn in clash_nodes]
                clash_results = await check_nodes_clash(only_clash_nodes, max_concurrent=10)
                
                valid_nodes = []
                available_count = 0
                for (orig_node, _), result in zip(clash_nodes, clash_results):
                    if result.is_available:
                        available_count += 1
                        orig_node['alive'] = True
                        orig_node['availability_level'] = 'VERIFIED'
                        orig_node['latency'] = result.latency_ms or 0
                        orig_node['protocol'] = result.protocol or orig_node.get('protocol', 'unknown')
                        
                        # è®¡ç®—å¥åº·è¯„åˆ†
                        latency = orig_node['latency']
                        if latency <= 50:
                            orig_node['health_score'] = 100
                        elif latency <= 100:
                            orig_node['health_score'] = 90
                        elif latency <= 200:
                            orig_node['health_score'] = 75
                        elif latency <= 500:
                            orig_node['health_score'] = 60
                        else:
                            orig_node['health_score'] = 40
                        
                        # è®¡ç®—é€Ÿåº¦
                        if latency <= 30:
                            orig_node['speed'] = 90.0
                        elif latency <= 60:
                            orig_node['speed'] = 70.0
                        elif latency <= 100:
                            orig_node['speed'] = 50.0
                        elif latency <= 200:
                            orig_node['speed'] = 30.0
                        elif latency <= 500:
                            orig_node['speed'] = 15.0
                        else:
                            orig_node['speed'] = 5.0
                        
                        # æ·»åŠ åœ°åŒºåˆ†æ•°
                        orig_node['mainland_score'] = int(orig_node.get('speed', 0))
                        orig_node['mainland_latency'] = latency
                        orig_node['overseas_score'] = int(orig_node.get('speed', 0))
                        orig_node['overseas_latency'] = latency
                        
                        valid_nodes.append(orig_node)
                
                # ğŸ”¥ BUGä¿®å¤: åˆå¹¶æ–°çš„å¿«é€Ÿé‡éªŒç»“æœè€Œä¸æ˜¯æ›¿æ¢
                # å¿«é€Ÿé‡éªŒæ˜¯é’ˆå¯¹ç°æœ‰èŠ‚ç‚¹çš„å†éªŒè¯ï¼Œä¸åº”è¯¥åˆ é™¤å…¶ä»–èŠ‚ç‚¹
                unique_nodes = {}
                for node in self.nodes:
                    key = f"{node.get('host')}:{node.get('port')}"
                    unique_nodes[key] = node
                
                # ç”¨é‡éªŒç»“æœæ›´æ–°è¿™äº›èŠ‚ç‚¹
                for node in valid_nodes:
                    key = f"{node.get('host')}:{node.get('port')}"
                    unique_nodes[key] = node
                
                self.nodes = sorted(unique_nodes.values(), key=lambda x: x.get('health_score', 0), reverse=True)
                self.add_log(f"âš¡ å¿«é€Ÿé‡éªŒå®Œæˆ: {available_count}/{len(clash_nodes)} å¯ç”¨ï¼Œå½“å‰èŠ‚ç‚¹æ€»æ•°: {len(self.nodes)}", "INFO")
                self._save_nodes_to_file()
        except Exception as e:
            self.add_log(f"âš ï¸ å¿«é€Ÿé‡éªŒå¼‚å¸¸: {e}", "WARNING")

    async def _run_advanced_test_async(self):
        """é«˜çº§åŒåœ°åŒºæµ‹é€Ÿçš„å¼‚æ­¥åŒ…è£…å™¨ï¼Œç‹¬ç«‹è¿è¡Œä¸é˜»å¡ä¸»æµç¨‹"""
        try:
            self.add_log("ğŸŒ å¼€å§‹æ‰§è¡Œé«˜çº§åŒåœ°åŒºæµ‹é€Ÿ...", "INFO")
            tested_nodes = await run_advanced_speed_test(self.nodes)
            self.nodes = tested_nodes
            
            # é«˜çº§æµ‹é€Ÿå®Œæˆåå†æ¬¡ä¸Šä¼ æ›´æ–°ç»“æœ
            alive_nodes = [n for n in self.nodes if n.get('alive')]
            if alive_nodes:
                self.add_log(f"ğŸ“¤ é«˜çº§æµ‹é€Ÿå®Œæˆï¼Œä¸Šä¼ æ›´æ–°ç»“æœåˆ° viper-node-store ({len(alive_nodes)} ä¸ªèŠ‚ç‚¹)...", "INFO")
                success = await upload_to_supabase(alive_nodes)
                if success:
                    self.add_log("âœ… é«˜çº§æµ‹é€Ÿç»“æœåŒæ­¥å®Œæˆï¼", "SUCCESS")
                else:
                    self.add_log("âš ï¸ é«˜çº§æµ‹é€Ÿç»“æœåŒæ­¥å¤±è´¥", "WARNING")
        except Exception as e:
            self.add_log(f"âŒ é«˜çº§æµ‹é€Ÿå¼‚å¸¸: {e}", "ERROR")

    async def _sync_to_supabase_task(self):
        """
        ğŸ”¥ æ–°å¢ï¼šå®šæ—¶åŒæ­¥ä»»åŠ¡ - æ¯10åˆ†é’Ÿæ‰§è¡Œ
        å°†å·²æµ‹é€Ÿçš„èŠ‚ç‚¹ä¸Šä¼ åˆ° Supabaseï¼Œä¾› viper-node-store è¯»å–
        
        ç‰¹ç‚¹ï¼š
        1. ç‹¬ç«‹çš„å®šæ—¶ä»»åŠ¡ï¼Œä¸ä¾èµ–å…¶ä»–ä»»åŠ¡
        2. åªåŒæ­¥å·²éªŒè¯çš„æ´»è·ƒèŠ‚ç‚¹ (alive=True)
        3. è‡ªåŠ¨å»é‡ï¼ˆé€šè¿‡ host:portï¼‰
        4. åŒ…å«å¤§é™†å’Œæµ·å¤–çš„æµ‹é€Ÿæ•°æ®
        """
        try:
            alive_nodes = [n for n in self.nodes if n.get('alive')]
            
            if not alive_nodes:
                self.add_log("ğŸ“­ æ— æ´»è·ƒèŠ‚ç‚¹ï¼Œè·³è¿‡ Supabase åŒæ­¥", "DEBUG")
                return
            
            # å»é‡ï¼šæŒ‰ host:port å»é‡ï¼Œä¿ç•™æœ€æ–°çš„æµ‹è¯•ç»“æœ
            seen = {}
            for node in alive_nodes:
                key = f"{node.get('host')}:{node.get('port')}"
                if key not in seen or node.get('updated_at', '') > seen[key].get('updated_at', ''):
                    seen[key] = node
            
            unique_nodes = list(seen.values())
            
            self.add_log(f"ğŸ“¤ Supabase åŒæ­¥: {len(unique_nodes)} ä¸ªæ´»è·ƒèŠ‚ç‚¹ï¼ˆå·²å»é‡ï¼‰...", "INFO")
            
            # ğŸ”¥ å¢å¼ºï¼šå…ˆæ£€æŸ¥å‡­è¯çŠ¶æ€
            import os
            url = os.getenv("SUPABASE_URL", "")
            key = os.getenv("SUPABASE_SERVICE_ROLE_KEY") or os.getenv("SUPABASE_KEY", "")
            self.add_log(f"ğŸ” ç¯å¢ƒå˜é‡æ£€æŸ¥: URL={'âœ…' if url else 'âŒ'}, KEY={'âœ…' if key else 'âŒ'}", "INFO")
            
            if not url or not key:
                self.add_log(f"âŒ Supabase ç¯å¢ƒå˜é‡æœªé…ç½®ï¼è¯·æ£€æŸ¥ SUPABASE_URL å’Œ SUPABASE_KEY", "ERROR")
                return
            
            # ä¸Šä¼ åˆ° Supabase (è¿”å› tuple: (success, message/count))
            result = await upload_to_supabase(unique_nodes)
            
            # å…¼å®¹æ—§ç‰ˆè¿”å›å€¼ (bool) å’Œæ–°ç‰ˆ (tuple)
            if isinstance(result, tuple):
                success, detail = result
            else:
                success, detail = result, ""
            
            if success:
                self.last_supabase_sync_time = time.time()
                self.add_log(f"âœ… Supabase åŒæ­¥å®Œæˆï¼{detail} ä¸ªèŠ‚ç‚¹å·²å†™å…¥æ•°æ®åº“", "SUCCESS")
            else:
                self.add_log(f"âš ï¸ Supabase åŒæ­¥å¤±è´¥: {detail}", "WARNING")
                
        except Exception as e:
            self.add_log(f"âŒ Supabase åŒæ­¥å¼‚å¸¸: {type(e).__name__}: {e}", "ERROR")
            logger.exception("Supabase åŒæ­¥å¼‚å¸¸")

    async def _cleanup_expired_cache_task(self):
        """
        ğŸ”¥ æ–°å¢ï¼šå®šæœŸæ¸…ç†è¿‡æœŸç¼“å­˜ - æ¯æ—¥å‡Œæ™¨ 3 ç‚¹æ‰§è¡Œ
        
        æ¸…ç†å†…å®¹ï¼š
        1. åˆ é™¤ 7 å¤©å‰çš„å·²å®Œæˆä»»åŠ¡
        2. åˆ é™¤è¿‡æœŸçš„æºç¼“å­˜ (> 24å°æ—¶)
        3. åˆ é™¤è¿‡æœŸçš„èŠ‚ç‚¹ç¼“å­˜ (> 6å°æ—¶)
        """
        try:
            self.add_log("ğŸ§¹ å¼€å§‹æ¸…ç†è¿‡æœŸç¼“å­˜...", "INFO")
            success = await self.persistence.cleanup_expired_cache()
            
            if success:
                self.add_log("âœ… è¿‡æœŸç¼“å­˜æ¸…ç†å®Œæˆ", "SUCCESS")
            else:
                self.add_log("âš ï¸ è¿‡æœŸç¼“å­˜æ¸…ç†éƒ¨åˆ†å¤±è´¥", "WARNING")
        except Exception as e:
            self.add_log(f"âŒ ç¼“å­˜æ¸…ç†å¼‚å¸¸: {e}", "ERROR")
            logger.exception("ç¼“å­˜æ¸…ç†å¼‚å¸¸")

    async def _test_nodes_with_new_system(self, nodes_to_test: List[Dict]):
        """
        æ–°çš„å¤šå±‚çº§å¯ç”¨æ€§æ£€æµ‹ç³»ç»Ÿ

        å±‚çº§ï¼š
        1. äº‘ç«¯å¿«é€Ÿè¿‡æ»¤ (Aliyun FC / Cloudflare Worker) - å¯é€‰
        2. åŸºç¡€ + æ·±åº¦å¯ç”¨æ€§æ£€æµ‹ (æœ¬åœ°åç«¯) - å¿…é¡»
        3. æŒç»­ç›‘æµ‹ (å®šæœŸ ping) - æœªæ¥æ‰©å±•
        """
        # ï¿½ ä¿å­˜å½“å‰æµ‹é€Ÿé˜Ÿåˆ—çŠ¶æ€åˆ°Supabase
        try:
            queue_data = [
                {
                    'group_number': i // 100,  # ç®€å•çš„åˆ†ç»„é€»è¾‘
                    'group_position': i % 100,
                    'node_host': node.get('host'),
                    'node_port': node.get('port'),
                    'status': 'pending'
                }
                for i, node in enumerate(nodes_to_test)
            ]
            await self.persistence.save_testing_queue(queue_data)
            self.add_log(f"ğŸ’¾ æµ‹é€Ÿé˜Ÿåˆ—å·²ä¿å­˜åˆ°Supabase ({len(nodes_to_test)} ä¸ªèŠ‚ç‚¹)", "SUCCESS")
        except Exception as e:
            self.add_log(f"âš ï¸ æµ‹é€Ÿé˜Ÿåˆ—ä¿å­˜å¤±è´¥: {e}", "WARNING")
        
        # ï¿½ğŸ”¥ ä¿®å¤ï¼šç¡®ä¿æ‰€æœ‰èŠ‚ç‚¹éƒ½æœ‰åç§°ï¼Œé¿å… "Unknown" æ˜¾ç¤º
        for node in nodes_to_test:
            if not node.get('name') or node.get('name') == 'Unknown':
                # ä½¿ç”¨å›½å®¶ä»£ç  + host:port ä½œä¸ºå¤‡ç”¨åç§°
                country = node.get('country', 'UNK')
                host = node.get('host', 'unknown')
                port = node.get('port', 0)
                node['name'] = f"{country}_{host}_{port}"
        
        self.add_log(f"ğŸ§ª [æ–°ç³»ç»Ÿ] å¼€å§‹å¯ç”¨æ€§æ£€æµ‹ {len(nodes_to_test)} ä¸ªèŠ‚ç‚¹...", "INFO")

        # ğŸ”¥ ä¸ºèŠ‚ç‚¹æ·»åŠ å›½å®¶ä¿¡æ¯ - ä½¿ç”¨æœ¬åœ°åç§°æ£€æµ‹+å¼‚æ­¥åŸŸåæ£€æµ‹ï¼ˆæ— é‡è¦ç½‘ç»œå»¶è¿Ÿï¼‰
        for node in nodes_to_test:
            if not node.get('country'):
                # ä¼˜å…ˆç”¨åç§°è¯†åˆ«ï¼ˆæœ€å¿«ï¼Œæœ¬åœ°æ“ä½œï¼Œ90%+å‡†ç¡®ï¼‰
                country = self.geolocation_helper.detect_country_by_name(
                    node.get('name', '')
                )
                
                # å†ç”¨åŸŸåè¯†åˆ«ï¼ˆæ¬¡å¿«ï¼Œå¼‚æ­¥ï¼‰
                if not country:
                    try:
                        country = await self.geolocation_helper.detect_country_by_domain(
                            node.get('domain', '')
                        )
                    except:
                        country = None
                
                # æœ€åä½¿ç”¨å¤‡é€‰å€¼
                if not country:
                    country = 'UNK'
                
                node['country'] = country

        cloud_results = []

        # ç¬¬1å±‚ï¼šäº‘ç«¯å¿«é€Ÿè¿‡æ»¤ (å¯é€‰) - ğŸ”¥ ä¿®å¤ï¼šäº‘ç«¯æ£€æµ‹åº”è¯¥æ˜¯è¡¥å……ï¼Œä¸æ˜¯è¿‡æ»¤
        # å¦‚æœäº‘ç«¯æœåŠ¡ä¸å¯ç”¨æˆ–è¿”å›ç©ºï¼Œåº”è¯¥ç»§ç»­æœ¬åœ°æ£€æµ‹ï¼Œè€Œä¸æ˜¯ä¸¢å¼ƒæ‰€æœ‰èŠ‚ç‚¹
        if CLOUD_DETECTION_ENABLED and ALIYUN_FC_URL and CF_WORKER_URL:
            try:
                # åˆ†ç¦»ä¸­å¤–èŠ‚ç‚¹
                cn_nodes = [n for n in nodes_to_test if n.get('country') == 'CN']
                overseas_nodes = [n for n in nodes_to_test if n.get('country') != 'CN']

                # é˜¿é‡Œäº‘FCæ£€æµ‹å›½å†…èŠ‚ç‚¹
                if cn_nodes:
                    self.add_log(f"ğŸ‡¨ğŸ‡³ [äº‘ç«¯] é˜¿é‡Œäº‘FCæ£€æµ‹å›½å†…èŠ‚ç‚¹ {len(cn_nodes)} ä¸ª...", "INFO")
                    aliyun_results = await test_nodes_via_aliyun_fc(cn_nodes)
                    cloud_results.extend(aliyun_results)

                # Cloudflare Workeræ£€æµ‹æµ·å¤–èŠ‚ç‚¹
                if overseas_nodes:
                    self.add_log(f"ğŸŒ [äº‘ç«¯] Cloudflare Workeræ£€æµ‹æµ·å¤–èŠ‚ç‚¹ {len(overseas_nodes)} ä¸ª...", "INFO")
                    cf_results = await test_nodes_via_cloudflare_worker(overseas_nodes)
                    cloud_results.extend(cf_results)

                # ğŸ”¥ ä¿®å¤ï¼šäº‘ç«¯ç»“æœä½œä¸ºè¡¥å……ï¼Œè€Œä¸æ˜¯å¼ºåˆ¶è¿‡æ»¤
                # å¦‚æœäº‘ç«¯æ£€æµ‹ç»“æœæœ‰æ•ˆï¼Œæ‰ä½¿ç”¨é¢„è¿‡æ»¤ï¼›å¦åˆ™ç›´æ¥è¿›è¡Œæœ¬åœ°æ£€æµ‹
                if cloud_results and len(cloud_results) > len(nodes_to_test) * 0.3:  # è‡³å°‘è¿”å›30%çš„èŠ‚ç‚¹
                    cloud_success_ids = {r['id'] for r in cloud_results if r.get('success', False)}
                    filtered_nodes = [n for n in nodes_to_test if n.get('id', f"{n['host']}:{n['port']}") in cloud_success_ids]
                    if filtered_nodes:  # åªæœ‰æœ‰ç»“æœæ‰è¿‡æ»¤
                        self.add_log(f"â˜ï¸ [äº‘ç«¯] é¢„è¿‡æ»¤å®Œæˆï¼Œ{len(nodes_to_test)} â†’ {len(filtered_nodes)} ä¸ªèŠ‚ç‚¹è¿›å…¥æœ¬åœ°æ£€æµ‹", "INFO")
                        nodes_to_test = filtered_nodes
                    else:
                        self.add_log(f"âš ï¸ [äº‘ç«¯] é¢„è¿‡æ»¤ç»“æœä¸ºç©ºï¼Œæ”¾å¼ƒäº‘ç«¯é¢„è¿‡æ»¤ï¼Œå…¨é‡è¿›è¡Œæœ¬åœ°æ£€æµ‹", "WARNING")
                else:
                    self.add_log(f"âš ï¸ [äº‘ç«¯] äº‘ç«¯æ£€æµ‹æ— æ•ˆï¼ˆæ— ç»“æœæˆ–è¿”å›ç‡è¿‡ä½ï¼‰ï¼Œè·³è¿‡é¢„è¿‡æ»¤ï¼Œå…¨é‡è¿›è¡Œæœ¬åœ°æ£€æµ‹", "WARNING")
            except Exception as e:
                self.add_log(f"âŒ [äº‘ç«¯] äº‘ç«¯æ£€æµ‹å¼‚å¸¸ {e}ï¼Œè·³è¿‡é¢„è¿‡æ»¤ï¼Œå…¨é‡è¿›è¡Œæœ¬åœ°æ£€æµ‹", "WARNING")

        # ç¬¬2å±‚ï¼šåˆ†ç¦»ä¸¤æ¡æ£€æµ‹è·¯çº¿ (Clash vs Xray)
        # ğŸ”¥ ä¿®å¤ï¼šæ­£ç¡®åˆ†ç¦»èŠ‚ç‚¹ï¼Œé¿å…é‡å¤æ£€æµ‹æˆ–é—æ¼
        
        # Clashæ”¯æŒçš„åè®®
        clash_compatible_protocols = ['trojan', 'ss', 'shadowsocks', 'socks5', 'socks', 'http', 'https', 'vmess', 'vless']
        
        # Xrayæ”¯æŒçš„åè®®
        xray_compatible_protocols = ['vmess', 'vless', 'hysteria', 'hysteria2', 'wireguard', 'tuic', 'naiveproxy', 'trojan']
        
        # åˆ†é…èŠ‚ç‚¹åˆ°ä¸åŒçš„æ£€æµ‹é˜Ÿåˆ—
        clash_nodes_for_test = []  # ä»…ç”¨Clashæ£€æµ‹
        xray_nodes_for_test = []   # ä»…ç”¨Xrayæ£€æµ‹
        both_protocol_nodes = {}   # åè®®åŒæ—¶æ”¯æŒClashå’ŒXrayçš„èŠ‚ç‚¹
        
        for node in nodes_to_test:
            protocol = node.get('protocol', '').lower()
            
            clash_support = protocol in clash_compatible_protocols
            xray_support = protocol in xray_compatible_protocols
            
            if clash_support and not xray_support:
                # ä»…Clashæ”¯æŒ (SS, SOCKS5ç­‰)
                clash_node = self._convert_to_clash_node(node)
                if clash_node:
                    clash_nodes_for_test.append((node, clash_node))
            elif xray_support and not clash_support:
                # ä»…Xrayæ”¯æŒ (Hysteriaç­‰)
                xray_nodes_for_test.append(node)
            elif clash_support and xray_support:
                # ä¸¤è€…éƒ½æ”¯æŒï¼Œä¼˜å…ˆç”¨Clash (é€Ÿåº¦å¿«)
                clash_node = self._convert_to_clash_node(node)
                if clash_node:
                    clash_nodes_for_test.append((node, clash_node))
                    both_protocol_nodes[f"{node['host']}:{node['port']}"] = node
            else:
                # ä¸¤è€…éƒ½ä¸æ”¯æŒï¼Œè·³è¿‡
                self.add_log(f"âš ï¸ ä¸æ”¯æŒçš„åè®®{protocol}ï¼Œè·³è¿‡: {node.get('host')}:{node.get('port')}", "DEBUG")
        
        valid_nodes = []
        
        # ç¬¬2å±‚ï¼šClashå†…æ ¸æ£€æµ‹
        if clash_nodes_for_test:
            self.add_log(f"ğŸ“Š æ‰§è¡Œ Clash å†…æ ¸èŠ‚ç‚¹æ£€æµ‹ ({len(clash_nodes_for_test)} ä¸ª)...", "INFO")
            try:
                only_clash_nodes = [cn for _, cn in clash_nodes_for_test]
                # ğŸ”¥ ä¿®å¤ï¼šé™ä½å¹¶å‘æ•°ä»20â†’5ï¼Œé¿å…Clashæ£€æµ‹å™¨è¿‡è½½å¯¼è‡´502
                clash_results = await check_nodes_clash(only_clash_nodes, max_concurrent=5)
                
                # ç»Ÿè®¡æ£€æµ‹ç»“æœ
                total = len(clash_results)
                available = sum(1 for r in clash_results if r.is_available)
                avg_latency = sum(r.latency_ms for r in clash_results if r.latency_ms and r.is_available) / available if available > 0 else 0
                
                self.add_log(f"ğŸ“ˆ Clash æ£€æµ‹å®Œæˆ - æ€»è®¡: {total}, å¯ç”¨: {available}, ä¸å¯ç”¨: {total - available}, å¹³å‡å»¶è¿Ÿ: {avg_latency:.0f}ms", "INFO")
                
                # å…³è”åŸå§‹èŠ‚ç‚¹å’Œæ£€æµ‹ç»“æœ
                for idx, ((orig_node, _), result) in enumerate(zip(clash_nodes_for_test, clash_results)):
                    if result.is_available:
                        # èŠ‚ç‚¹å¯ç”¨ï¼Œåˆå¹¶æµ‹è¯•ç»“æœ
                        orig_node['alive'] = True
                        orig_node['availability_level'] = 'VERIFIED'
                        orig_node['latency'] = result.latency_ms or 0
                        orig_node['protocol'] = result.protocol or orig_node.get('protocol', 'unknown')
                        
                        # åŸºäºå»¶è¿Ÿè®¡ç®—å¥åº·è¯„åˆ†
                        latency = orig_node['latency']
                        if latency <= 50:
                            orig_node['health_score'] = 100
                        elif latency <= 100:
                            orig_node['health_score'] = 90
                        elif latency <= 200:
                            orig_node['health_score'] = 75
                        elif latency <= 500:
                            orig_node['health_score'] = 60
                        else:
                            orig_node['health_score'] = 40

                        # åŸºäºå»¶è¿Ÿçš„ç®€å•é€Ÿåº¦ä¼°ç®—
                        if latency <= 30:
                            orig_node['speed'] = 90.0
                        elif latency <= 60:
                            orig_node['speed'] = 70.0
                        elif latency <= 100:
                            orig_node['speed'] = 50.0
                        elif latency <= 200:
                            orig_node['speed'] = 30.0
                        elif latency <= 500:
                            orig_node['speed'] = 15.0
                        else:
                            orig_node['speed'] = 5.0

                        # ğŸ”¥ æ·»åŠ åœ°åŒºæµ‹è¯•åˆ†æ•°ï¼ˆç”¨äºSupabaseåŒæ­¥ï¼‰
                        orig_node['mainland_score'] = int(orig_node.get('speed', 0))
                        orig_node['mainland_latency'] = latency
                        orig_node['overseas_score'] = int(orig_node.get('speed', 0))
                        orig_node['overseas_latency'] = latency

                        # ğŸ”¥ æ·»åŠ  share_linkï¼ˆç”¨äºviper-node-storeæ˜¾ç¤ºQRç ï¼‰
                        if not orig_node.get('share_link'):
                            try:
                                orig_node['share_link'] = generate_node_share_link(orig_node)
                            except Exception as e:
                                logger.debug(f"ç”Ÿæˆshare_linkå¤±è´¥: {e}")

                        # ğŸ”¥ ä¼˜åŒ–ï¼šæ¯æ£€æµ‹åˆ°1ä¸ªå¯ç”¨èŠ‚ç‚¹å°±è¾“å‡ºï¼Œè®©ç”¨æˆ·çœ‹åˆ°å®æ—¶åé¦ˆ
                        self.add_log(
                            f"âœ… Clashâœ“ [{idx+1}/{total}] {orig_node.get('host')}:{orig_node.get('port')} "
                            f"({orig_node.get('protocol')} | å»¶è¿Ÿ{latency}ms | é˜Ÿåˆ—å‰©ä½™{len(self.pending_nodes_queue)})",
                            "SUCCESS"
                        )
                        valid_nodes.append(orig_node)
                    else:
                        # ğŸ”¥ è¯Šæ–­ï¼šå¢åŠ å¤±è´¥è¯¦æƒ…ï¼Œå¸®åŠ©æ’æŸ¥é—®é¢˜
                        error_msg = result.error_message if result else "æ£€æµ‹å¤±è´¥"
                        if idx < 5 or (idx % 100 == 0):  # å‰5ä¸ªå¤±è´¥+æ¯100ä¸ªé‡‡æ ·ä¸€ä¸ª
                            self.add_log(
                                f"âŒ Clashâœ— [{idx+1}/{total}] {orig_node.get('host')}:{orig_node.get('port')} "
                                f"({orig_node.get('protocol')}) - {error_msg}",
                                "WARNING"
                            )
            except Exception as e:
                self.add_log(f"âŒ Clash æ£€æµ‹å¼‚å¸¸: {e}", "WARNING")
                import traceback
                self.add_log(f"   å¼‚å¸¸å †æ ˆ: {traceback.format_exc()[:500]}", "WARNING")
        
        # ç¬¬3å±‚ï¼šXrayå†…æ ¸æ£€æµ‹ï¼ˆVMess/VLESSåŠå…¶ä»–ä¸“æœ‰åè®®ï¼‰
        # åŒ…æ‹¬ï¼šä»…Xrayæ”¯æŒçš„åè®® + Clashæ£€æµ‹å¤±è´¥çš„åŒæ—¶æ”¯æŒä¸¤è€…åè®®çš„èŠ‚ç‚¹
        # ğŸ”¥ BUGä¿®å¤ï¼šæ·»åŠ Clashå¤±è´¥çš„èŠ‚ç‚¹åˆ°Xrayæ£€æµ‹ï¼Œé¿å…æµªè´¹å¯ç”¨èŠ‚ç‚¹
        clash_failed_nodes = []
        if clash_nodes_for_test and clash_results:
            for (orig_node, _), result in zip(clash_nodes_for_test, clash_results):
                # åªæœ‰Clashå¤±è´¥ä¸”æ”¯æŒä¸¤ç§åè®®çš„èŠ‚ç‚¹æ‰åŠ å…¥Xrayæ£€æµ‹
                if not result.is_available and f"{orig_node.get('host')}:{orig_node.get('port')}" in both_protocol_nodes:
                    clash_failed_nodes.append(orig_node)
        
        final_xray_nodes = xray_nodes_for_test.copy()
        final_xray_nodes.extend(clash_failed_nodes)
        
        if final_xray_nodes:
            # ğŸ”¥ ä¼˜åŒ–ï¼šæ¸…æ™°çš„åˆ†ç•Œçº¿ï¼Œé¿å…æ—¥å¿—æ··ä¹±
            self.add_log(
                f"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•",
                "INFO"
            )
            self.add_log(
                f"ğŸ¯ ã€Xrayå¹¶è¡Œæ£€æµ‹ã€‘å¼€å§‹æ£€æµ‹ {len(final_xray_nodes)} ä¸ªåè®®",
                "INFO"
            )
            self.add_log(
                f"   åè®®åˆ—è¡¨: {self._get_protocol_stats(final_xray_nodes)}",
                "INFO"
            )
            self.add_log(
                f"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•",
                "INFO"
            )
            try:
                # è½¬æ¢èŠ‚ç‚¹æ ¼å¼ä»¥å…¼å®¹ v2ray_checkï¼ˆä½¿ç”¨ "type" å­—æ®µï¼‰
                xray_nodes_converted = []
                for node in final_xray_nodes:
                    node_copy = node.copy()
                    node_copy['type'] = node.get('protocol', 'unknown')  # ğŸ”¥ å…³é”®ï¼šè½¬æ¢ protocol -> type
                    node_copy['server'] = node.get('host', '')  # è½¬æ¢ host -> server
                    xray_nodes_converted.append(node_copy)
                
                # ä½¿ç”¨ Xray æ£€æµ‹ (ğŸ”¥ é™ä½å¹¶å‘ä»10â†’3ï¼Œé¿å…è¿‡è½½)
                xray_results = await check_nodes_v2ray(xray_nodes_converted, max_concurrent=3)
                
                # ç»Ÿè®¡æ£€æµ‹ç»“æœ
                xray_available = sum(1 for r in xray_results if r.is_available)
                self.add_log(f"ğŸ¯ Xray æ£€æµ‹å®Œæˆ - æ€»è®¡: {len(xray_results)}, å¯ç”¨: {xray_available}", "INFO")
                
                # å¤„ç† Xray æ£€æµ‹ç»“æœ
                for idx, (node, result) in enumerate(zip(final_xray_nodes, xray_results)):
                    if result.is_available:
                        # èŠ‚ç‚¹å¯ç”¨
                        node['alive'] = True
                        node['availability_level'] = 'VERIFIED'
                        node['latency'] = result.latency_ms or 0
                        node['protocol'] = result.protocol or node.get('protocol', 'unknown')
                        
                        # åŸºäºå»¶è¿Ÿè®¡ç®—å¥åº·è¯„åˆ†
                        latency = node['latency']
                        if latency <= 50:
                            node['health_score'] = 100
                        elif latency <= 100:
                            node['health_score'] = 90
                        elif latency <= 200:
                            node['health_score'] = 75
                        elif latency <= 500:
                            node['health_score'] = 60
                        else:
                            node['health_score'] = 40
                        
                        # åŸºäºå»¶è¿Ÿçš„é€Ÿåº¦ä¼°ç®—
                        if latency <= 30:
                            node['speed'] = 90.0
                        elif latency <= 60:
                            node['speed'] = 70.0
                        elif latency <= 100:
                            node['speed'] = 50.0
                        elif latency <= 200:
                            node['speed'] = 30.0
                        elif latency <= 500:
                            node['speed'] = 15.0
                        else:
                            node['speed'] = 5.0
                        
                        # ğŸ”¥ æ·»åŠ åœ°åŒºæµ‹è¯•åˆ†æ•°
                        node['mainland_score'] = int(node.get('speed', 0))
                        node['mainland_latency'] = latency
                        node['overseas_score'] = int(node.get('speed', 0))
                        node['overseas_latency'] = latency
                        
                        # ğŸ”¥ æ·»åŠ  share_linkï¼ˆç”¨äºviper-node-storeæ˜¾ç¤ºQRç ï¼‰
                        if not node.get('share_link'):
                            try:
                                node['share_link'] = generate_node_share_link(node)
                            except Exception as e:
                                logger.debug(f"ç”Ÿæˆshare_linkå¤±è´¥: {e}")
                        
                        # ğŸ”¥ ä¼˜åŒ–ï¼šæ¯æ£€æµ‹åˆ°1ä¸ªå¯ç”¨èŠ‚ç‚¹å°±è¾“å‡ºï¼Œè®©ç”¨æˆ·çœ‹åˆ°å®æ—¶åé¦ˆ
                        self.add_log(
                            f"âœ… Xrayâœ“ [{idx+1}/{len(xray_results)}] {node.get('host')}:{node.get('port')} "
                            f"({node.get('protocol')} | å»¶è¿Ÿ{latency}ms | é˜Ÿåˆ—å‰©ä½™{len(self.pending_nodes_queue)})",
                            "SUCCESS"
                        )
                        valid_nodes.append(node)
                    else:
                        # ğŸ”¥ è¯Šæ–­å¤±è´¥åŸå› 
                        error_msg = result.error_message if result else "æ£€æµ‹å¤±è´¥"
                        if idx < 5 or (idx % 100 == 0):  # å‰5ä¸ªå¤±è´¥+æ¯100ä¸ªé‡‡æ ·ä¸€ä¸ª
                            self.add_log(
                                f"âŒ Xrayâœ— [{idx+1}/{len(xray_results)}] {node.get('host')}:{node.get('port')} "
                                f"({node.get('protocol')}) - {error_msg}",
                                "WARNING"
                            )
            except Exception as e:
                self.add_log(f"âŒ Xray æ£€æµ‹å¼‚å¸¸: {e}", "WARNING")
                import traceback
                self.add_log(f"   å¼‚å¸¸å †æ ˆ: {traceback.format_exc()[:500]}", "WARNING")

        
        # ğŸ”¥ BUGä¿®å¤: åˆå¹¶æ–°æ£€æµ‹ç»“æœè€Œä¸æ˜¯æ›¿æ¢ï¼
        # é—®é¢˜: ç›´æ¥æ›¿æ¢self.nodeså¯¼è‡´ä¹‹å‰çš„å¯ç”¨èŠ‚ç‚¹è¢«æ¸…é™¤
        # è§£å†³: ä¿ç•™æ—§èŠ‚ç‚¹(alive=True)ï¼Œæ·»åŠ æ–°æ£€æµ‹çš„èŠ‚ç‚¹
        
        # 1. ä¿ç•™ä¹‹å‰æ£€æµ‹å‡ºçš„å¯ç”¨èŠ‚ç‚¹ï¼ˆé‚£äº›å·²ç»alive=Trueçš„ï¼‰
        existing_alive = [n for n in self.nodes if n.get('alive') and n not in valid_nodes]
        
        # 2. åˆå¹¶: å·²ç¡®è®¤å¯ç”¨çš„ + æ–°æ£€æµ‹å‡ºçš„å¯ç”¨
        merged_nodes = existing_alive + valid_nodes
        
        # 3. å»é‡ (æŒ‰host:port)
        unique_nodes = {}
        for node in merged_nodes:
            key = f"{node.get('host')}:{node.get('port')}"
            if key not in unique_nodes or (node.get('alive') and not unique_nodes[key].get('alive')):
                unique_nodes[key] = node
        
        # 4. æ›´æ–°å¹¶æ’åº
        self.nodes = sorted(unique_nodes.values(), key=lambda x: x.get('health_score', 0), reverse=True)
        
        self.add_log(
            f"ğŸ‰ èŠ‚ç‚¹æ£€æµ‹å®Œæˆï¼å¯ç”¨èŠ‚ç‚¹: {len([n for n in self.nodes if n.get('alive')])}/{len(nodes_to_test)} "
            f"(åŒ…å« {len(existing_alive)} ä¸ªå·²ä¿ç•™èŠ‚ç‚¹)",
            "SUCCESS"
        )
        
        # ğŸ”¥ P3å¢å¼ºï¼šæ·»åŠ åè®®åˆ†å¸ƒç»Ÿè®¡æ—¥å¿—
        if nodes_to_test:
            # ç»Ÿè®¡æ‰€æœ‰æµ‹è¯•èŠ‚ç‚¹çš„åè®®åˆ†å¸ƒ
            all_protocol_stats = {}
            for node in nodes_to_test:
                proto = node.get('protocol', 'unknown').lower()
                all_protocol_stats[proto] = all_protocol_stats.get(proto, 0) + 1
            
            # ç»Ÿè®¡å¯ç”¨èŠ‚ç‚¹çš„åè®®åˆ†å¸ƒ
            available_protocol_stats = {}
            for node in self.nodes:
                proto = node.get('protocol', 'unknown').lower()
                available_protocol_stats[proto] = available_protocol_stats.get(proto, 0) + 1
            
            # æ‰“å°è¯¦ç»†ç»Ÿè®¡
            self.add_log("ğŸ“Š [åè®®åˆ†å¸ƒç»Ÿè®¡]", "INFO")
            self.add_log(f"   æ€»èŠ‚ç‚¹ {len(nodes_to_test)} ä¸ª / å¯ç”¨ {len(self.nodes)} ä¸ª", "INFO")
            
            for proto in sorted(all_protocol_stats.keys()):
                total = all_protocol_stats[proto]
                available = available_protocol_stats.get(proto, 0)
                percentage = (available / total * 100) if total > 0 else 0
                self.add_log(f"   â€¢ {proto:12s}: {total:3d} ä¸ª ({available:2d}âœ… {percentage:5.1f}%)", "INFO")
        
        if self.nodes:
            self.subscription_base64 = generate_subscription_content(self.nodes)
            self._save_nodes_to_file()

    async def test_and_update_nodes(self, nodes_to_test: List[Dict]):
        self.add_log(f"ğŸ§ª å¼€å§‹æµ‹è¯• {len(nodes_to_test)} ä¸ªèŠ‚ç‚¹...", "INFO")
        tasks = [test_node_network(node) for node in nodes_to_test]
        results = await asyncio.gather(*tasks)

        valid_nodes = []
        for i, node in enumerate(nodes_to_test):
            if results[i].total_score > 0:
                node.update(alive=True, delay=results[i].tcp_ping_ms, test_results=results[i].__dict__)

                country = self._get_country_code_from_ip(node['host'])
                if country == 'UNK' or country is None:
                    country = self._guess_country_from_name(node.get('name', ''))

                node['country'] = country

                real_latency = results[i].connection_time_ms
                if real_latency > 0:
                    node['speed'] = round(5000.0 / real_latency, 2)
                elif node['delay'] > 0:
                    node['speed'] = round(random.uniform(1.0, 30.0) / (node['delay'] / 100), 2)
                else:
                    node['speed'] = 0.5

                valid_nodes.append(node)

        self.nodes = sorted(valid_nodes, key=lambda x: x.get('test_results', {}).get('total_score', 0), reverse=True)
        self.add_log(f"ğŸ‰ æµ‹è¯•å®Œæˆï¼æœ‰æ•ˆèŠ‚ç‚¹: {len(self.nodes)}/{len(nodes_to_test)}", "SUCCESS")

        # ğŸ’¾ æ›´æ–°æ¯ä¸ªèŠ‚ç‚¹çš„æµ‹è¯•çŠ¶æ€åˆ°Supabase
        try:
            for node in self.nodes:
                status = 'passed' if node.get('alive') else 'failed'
                await self.persistence.update_task_status(
                    node.get('host'),
                    node.get('port'),
                    status
                )
            self.add_log(f"ğŸ’¾ å·²æ›´æ–° {len(self.nodes)} ä¸ªèŠ‚ç‚¹çš„æµ‹è¯•çŠ¶æ€åˆ°Supabase", "SUCCESS")
        except Exception as e:
            self.add_log(f"âš ï¸ æ›´æ–°èŠ‚ç‚¹çŠ¶æ€å¤±è´¥: {e}", "WARNING")

        if self.nodes:
            self.subscription_base64 = generate_subscription_content(self.nodes)
            self._save_nodes_to_file()

    async def _run_speed_test_background(self, node_id: str, proxy_url: str, latency: float):
        """
        ğŸ”¥ åå°å¼‚æ­¥è¿è¡ŒçœŸå®é€Ÿåº¦æµ‹è¯•
        ä¸é˜»å¡ä¸»æ£€æµ‹æµç¨‹ï¼Œæµ‹è¯•å®Œæˆåæ›´æ–°ç¼“å­˜
        """
        try:
            self.add_log(f"ğŸš€ [åå°] å¼€å§‹æµ‹é€Ÿ: {node_id}", "INFO")
            result = await self.speed_tester.test_node_speed(
                proxy_url=proxy_url,
                node_id=node_id,
                use_multi_thread=False  # å•çº¿ç¨‹æµ‹è¯•
            )
            
            if result.get('status') == 'success' and result.get('speed', 0) > 0:
                self.add_log(f"âš¡ [åå°æµ‹é€Ÿå®Œæˆ] {node_id}: {result['speed']:.1f}MB/s (å»¶è¿Ÿ: {result.get('latency', 0):.1f}ms)", "SUCCESS")
                # æ›´æ–°ç¼“å­˜ä»¥ä¾›åç»­ä½¿ç”¨
                await self.speed_tester.cache_speed_result(node_id, result['speed'])
            else:
                self.add_log(f"âš ï¸ [åå°æµ‹é€Ÿå¤±è´¥] {node_id}: {result.get('error', 'æœªçŸ¥é”™è¯¯')}", "WARNING")
        except Exception as e:
            self.add_log(f"âŒ [åå°æµ‹é€Ÿå¼‚å¸¸] {node_id}: {str(e)}", "ERROR")


hunter = NodeHunter()


@router.get("/stats", response_model=StatsResponse)
async def get_stats():
    all_nodes = hunter.get_alive_nodes()
    groups = []

    country_map = {}
    for node in all_nodes:
        c = node.get('country', 'UNK')
        if c not in country_map: country_map[c] = []
        country_map[c].append(node)

    priority = ['CN', 'HK', 'TW', 'US', 'JP', 'SG', 'KR']
    for code in priority:
        if code in country_map:
            groups.append({"group_name": code, "nodes": country_map[code]})
            del country_map[code]
    for code in sorted(country_map.keys()):
        groups.append({"group_name": code, "nodes": country_map[code]})

    # ğŸ”¥ è·å–ä¸‹æ¬¡æ‰«ææ—¶é—´
    next_run = None
    job = hunter.scheduler.get_job('node_scan_refresh')
    if job and job.next_run_time:
        next_run = job.next_run_time.timestamp()

    return {
        "count": len(all_nodes),
        "running": hunter.is_scanning,
        "logs": hunter.logs,
        "nodes": groups,
        "next_scan_time": next_run  # ğŸ”¥ è¿”å›æ—¶é—´æˆ³
    }


@router.post("/trigger")
async def trigger_scan(background_tasks: BackgroundTasks):
    if not hunter.is_scanning:
        background_tasks.add_task(hunter.scan_cycle)
        return {"status": "started"}
    return {"status": "running"}


@router.post("/batch_detect")
async def trigger_batch_detect(background_tasks: BackgroundTasks):
    """
    ğŸ”¥ æ–°å¢ï¼šå¼ºåˆ¶è§¦å‘æ‰¹é‡æ£€æµ‹ (è§£å†³40åˆ†é’Ÿç­‰å¾…é—®é¢˜)
    ç«‹å³æ‰§è¡Œæ‰¹æ£€æµ‹ï¼Œä¸éœ€è¦ç­‰å¾…å®šæ—¶å™¨
    """
    if not hunter.is_batch_testing:
        background_tasks.add_task(hunter._batch_test_pending_nodes)
        return {"status": "batch_detect_started", "message": "æ‰¹é‡æ£€æµ‹å·²å¯åŠ¨"}
    return {"status": "batch_detect_running", "message": "æ‰¹é‡æ£€æµ‹å·²åœ¨è¿›è¡Œä¸­"}


@router.post("/toggle_socks_http")
async def toggle_socks_http(show: bool = Query(True)):
    """
    ğŸ”¥ æ–°å¢ï¼šæ§åˆ¶æ˜¯å¦æ˜¾ç¤º socks/http èŠ‚ç‚¹
    é»˜è®¤å…³é—­ï¼Œå¼€å¯å socks/http èŠ‚ç‚¹æ˜¾ç¤ºåœ¨åˆ—è¡¨æœ€å‰é¢
    """
    hunter.show_socks_http = show
    status = "å¼€å¯" if show else "å…³é—­"
    hunter.add_log(f"ğŸ”§ socks/http èŠ‚ç‚¹æ˜¾ç¤ºå·²{status}", "INFO")
    return {"status": "success", "show_socks_http": show, "message": f"socks/http èŠ‚ç‚¹æ˜¾ç¤ºå·²{status}"}


@router.get("/socks_http_status")
async def get_socks_http_status():
    """
    è·å–å½“å‰ socks/http å¼€å…³çŠ¶æ€
    """
    return {"show_socks_http": hunter.show_socks_http}


@router.post("/toggle_china_nodes")
async def toggle_china_nodes(show: bool = Query(True)):
    """
    ğŸ”¥ æ–°å¢ï¼šæ§åˆ¶æ˜¯å¦æ˜¾ç¤ºå›½å†…èŠ‚ç‚¹
    é»˜è®¤éšè—ï¼Œå¼€å¯åå¯ä»¥åœ¨åˆ—è¡¨ä¸­çœ‹åˆ°ä¸­å›½èŠ‚ç‚¹
    """
    hunter.show_china_nodes = show
    status = "å¼€å¯" if show else "å…³é—­"
    hunter.add_log(f"ğŸ”§ ä¸­å›½èŠ‚ç‚¹æ˜¾ç¤ºå·²{status}", "INFO")
    return {"status": "success", "show_china_nodes": show, "message": f"ä¸­å›½èŠ‚ç‚¹æ˜¾ç¤ºå·²{status}"}


@router.get("/china_nodes_status")
async def get_china_nodes_status():
    """
    è·å–å½“å‰å›½å†…èŠ‚ç‚¹æ˜¾ç¤ºçŠ¶æ€
    """
    return {"show_china_nodes": hunter.show_china_nodes}


@router.post("/test_all")
async def test_all_nodes(background_tasks: BackgroundTasks):
    if not hunter.is_scanning:
        nodes_to_test = hunter.nodes.copy()
        background_tasks.add_task(hunter.test_and_update_nodes, nodes_to_test)
        return {"status": "started"}
    return {"status": "running"}


# backend/app/modules/node_hunter/node_hunter.py

# ... (å‰é¢çš„ä»£ç ä¿æŒä¸å˜)

@router.post("/test_single")
async def test_single_node(target: NodeTarget):
    found_node = None
    for node in hunter.nodes:
        if node['host'] == target.host and node['port'] == target.port:
            found_node = node
            break

    if found_node:
        hunter.add_log(f"ğŸ§ª æ‰‹åŠ¨æµ‹è¯•èŠ‚ç‚¹: {found_node.get('name', 'Unknown')}", "INFO")

        # 1. æ‰§è¡ŒçœŸå®ç½‘ç»œæµ‹è¯•ï¼ˆè·å– TCP å»¶è¿Ÿå’ŒåŸºæœ¬è¿æ¥ä¿¡æ¯ï¼‰
        result = await test_node_network(found_node)

        if result.total_score > 0:
            # 2. ğŸ”¥ æ ¸å¿ƒä¿®å¤ï¼šä½¿ç”¨çœŸå®é€Ÿåº¦æµ‹è¯•è€Œä¸æ˜¯è™šå‡è®¡ç®—å€¼
            tcp_delay = result.tcp_ping_ms
            speed = 0.0
            
            # å°è¯•è¿›è¡ŒçœŸå®ä¸‹è½½é€Ÿåº¦æµ‹è¯•
            try:
                # ç”Ÿæˆä»£ç† URL (SOCKS5 æ ¼å¼)
                proxy_url = f"socks5://{found_node['host']}:{found_node['port']}"
                
                # ä½¿ç”¨çœŸå®é€Ÿåº¦æµ‹è¯•å™¨è¿›è¡Œæµ‹è¯•
                test_result = await hunter.speed_tester.test_node_speed(
                    proxy_url=proxy_url,
                    node_id=f"{found_node['host']}:{found_node['port']}",
                    use_multi_thread=False,  # å•æ¬¡æµ‹è¯•ç”¨å•çº¿ç¨‹
                    file_size=10485760  # 10MB æµ‹è¯•æ–‡ä»¶
                )
                
                if test_result['status'] in ['success', 'cached']:
                    speed = round(test_result['speed'], 2)
                    hunter.add_log(f"ğŸ“Š çœŸå®é€Ÿåº¦æµ‹è¯•: {speed} MB/s", "INFO")
                else:
                    # é™çº§æ–¹æ¡ˆï¼šå¦‚æœçœŸå®æµ‹é€Ÿå¤±è´¥ï¼Œä½¿ç”¨å»¶è¿Ÿä¼°è®¡
                    from .real_speed_test import estimate_speed_from_latency
                    speed = round(await estimate_speed_from_latency(tcp_delay), 2)
                    hunter.add_log(f"ğŸ“Š åŸºäºå»¶è¿Ÿä¼°è®¡é€Ÿåº¦: {speed} MB/s", "INFO")
                    
            except Exception as e:
                # å¦‚æœå¼‚å¸¸ï¼Œä½¿ç”¨ç®€å•çš„å»¶è¿Ÿä¼°è®¡
                logger.warning(f"âš ï¸ çœŸå®é€Ÿåº¦æµ‹è¯•å¼‚å¸¸: {str(e)[:100]}")
                if tcp_delay > 0:
                    speed = round(5000.0 / tcp_delay, 2)
                else:
                    speed = 0.1
                hunter.add_log(f"âš ï¸ é™çº§ä¸ºç®€å•è®¡ç®—é€Ÿåº¦: {speed} MB/s", "INFO")

            # 3. æ›´æ–°å†…å­˜ä¸­çš„èŠ‚ç‚¹æ•°æ®
            found_node.update({
                "alive": True,
                "delay": tcp_delay,
                "speed": speed,
                "test_results": result.__dict__
            })

            hunter.add_log(f"âœ… æµ‹è¯•å®Œæˆ: å»¶è¿Ÿ {tcp_delay}ms | é€Ÿåº¦ {speed} MB/s", "SUCCESS")

            # è¿”å›è¯¦ç»†æ•°æ®ç»™å‰ç«¯
            return {
                "status": "ok",
                "result": result.__dict__,
                "speed": speed,  # è¿”å›é€Ÿåº¦
                "delay": tcp_delay  # è¿”å›å»¶è¿Ÿ
            }
        else:
            found_node['alive'] = False
            found_node['speed'] = 0.0
            found_node['delay'] = -1
            hunter.add_log(f"âŒ èŠ‚ç‚¹å·²å¤±æ•ˆ (æ— æ³•è¿æ¥)", "ERROR")
            return {"status": "fail", "message": "Node unreachable"}

    return {"status": "error", "message": "Node not found"}


# ==================== Round 5: CF Worker æ”¯æŒ ====================

class CacheTestResult(BaseModel):
    """ç¼“å­˜ CF Worker æµ‹è¯•ç»“æœçš„è¯·æ±‚ä½“"""
    host: str
    port: int
    delay: int
    speed: float


@router.post("/cache_test_result")
async def cache_test_result(req: CacheTestResult):
    """
    ğŸ”¥ Round 5: æ¥æ”¶å¹¶ç¼“å­˜ CF Worker çš„æµ‹è¯•ç»“æœ
    
    å‰ç«¯ä» CF Worker è·å¾—æµ‹è¯•ç»“æœåï¼Œå¼‚æ­¥è°ƒç”¨æ­¤ API ä¿å­˜åˆ°åç«¯
    ç”¨äºåç»­åˆ—è¡¨æ˜¾ç¤ºå’Œç»Ÿè®¡åˆ†æ
    
    å‚æ•°ï¼š
        host: èŠ‚ç‚¹ IP
        port: èŠ‚ç‚¹ç«¯å£
        delay: å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰
        speed: é€Ÿåº¦ï¼ˆMB/sï¼‰
    """
    try:
        # åœ¨å†…å­˜èŠ‚ç‚¹åˆ—è¡¨ä¸­æŸ¥æ‰¾å¹¶æ›´æ–°
        found_node = None
        for node in hunter.nodes:
            if node['host'] == req.host and node['port'] == req.port:
                found_node = node
                break
        
        if found_node:
            # æ›´æ–°æµ‹è¯•ç»“æœ
            found_node.update({
                "delay": req.delay,
                "speed": req.speed,
                "alive": True,
                "last_test_time": datetime.now().isoformat(),
            })
            
            hunter.add_log(
                f"ğŸ’¾ CF Worker ç»“æœå·²ç¼“å­˜: {found_node.get('name', 'Unknown')} - "
                f"å»¶è¿Ÿ {req.delay}ms | é€Ÿåº¦ {req.speed} MB/s",
                "INFO"
            )
            
            return {
                "status": "ok",
                "message": f"ç»“æœå·²ç¼“å­˜: {req.host}:{req.port}",
                "data": {
                    "delay": req.delay,
                    "speed": req.speed,
                }
            }
        else:
            return {
                "status": "not_found",
                "message": f"èŠ‚ç‚¹ä¸å­˜åœ¨: {req.host}:{req.port}"
            }
    
    except Exception as e:
        logger.error(f"âŒ ç¼“å­˜ CF ç»“æœå¤±è´¥: {str(e)}")
        return {
            "status": "error",
            "message": f"ç¼“å­˜å¤±è´¥: {str(e)}"
        }


@router.get("/qrcode")
async def get_node_qrcode(host: str, port: int):
    found_node = None
    for node in hunter.nodes:
        if node['host'] == host and str(node['port']) == str(port):
            found_node = node
            break

    if found_node:
        share_link = generate_node_share_link(found_node)
        if share_link:
            img = qrcode.make(share_link)
            buf = BytesIO()
            img.save(buf, format="PNG")
            return {"qrcode_data": f"data:image/png;base64,{base64.b64encode(buf.getvalue()).decode()}"}

    return {"error": "èŠ‚ç‚¹ä¸å­˜åœ¨æˆ–æ— æ³•ç”Ÿæˆé“¾æ¥"}


@router.post("/add_source")
async def add_source(req: SourceRequest, background_tasks: BackgroundTasks):
    success, msg = hunter.add_user_source(req.url)
    if success:
        if not hunter.is_scanning:
            background_tasks.add_task(hunter.scan_cycle)
    return {"status": "ok" if success else "error", "message": msg}


@router.get("/subscription")
async def get_subscription():
    if hunter.subscription_base64:
        return {"subscription": hunter.subscription_base64, "node_count": len(hunter.nodes)}
    return {"error": "æš‚æ— è®¢é˜…é“¾æ¥"}


@router.get("/clash/config")
async def get_clash_config(request: Request):
    config_str = generate_clash_config(hunter.nodes)
    if config_str:
        return {"filename": f"clash_config_{int(time.time())}.yaml", "content": config_str}
    return {"error": "Error"}


# ==========================================
# ğŸ”¥ æ–°å¢ï¼šä¾›ç‹¬ç«‹ç½‘ç«™æŠ“å–çš„ä¸“ç”¨æ¥å£
# ==========================================

class ExportNode(BaseModel):
    protocol: str
    host: str
    port: int
    country: str
    speed: float
    name: str
    link: Optional[str] = None


@router.get("/export_raw", response_model=List[ExportNode])
async def export_raw_nodes(token: str = Query(..., description="å®‰å…¨éªŒè¯Token")):
    """
    å¯¼å‡ºåŸå§‹èŠ‚ç‚¹æ•°æ®ï¼Œä¾› GitHub Actions å®šæ—¶æŠ“å–
    """
    # å®‰å…¨éªŒè¯ï¼šåªæœ‰ Token å¯¹ä¸Šäº†æ‰ç»™æ•°æ®
    # æ³¨æ„ï¼šå¦‚æœä½ æ”¹äº†è¿™é‡Œçš„ "shadow-viper-secret-key-2024"ï¼Œ
    # è®°å¾—åœ¨ GitHub Secrets çš„ API åœ°å€é‡Œä¹Ÿè¦åŒæ­¥ä¿®æ”¹
    if token != "shadow-viper-secret-key-2024":
        return []

    # è·å–å½“å‰å†…å­˜ä¸­æ‰€æœ‰å­˜æ´»çš„èŠ‚ç‚¹
    alive_nodes = hunter.get_alive_nodes()
    export_list = []

    for node in alive_nodes:
        # ç”ŸæˆèŠ‚ç‚¹åˆ†äº«é“¾æ¥ (å¦‚ vmess://..., ss://...)
        # generate_node_share_link å·²ç»åœ¨æ–‡ä»¶å¤´éƒ¨å¼•å…¥äº†ï¼Œç›´æ¥ç”¨å³å¯
        share_link = generate_node_share_link(node)

        export_list.append({
            "protocol": node.get('protocol', 'unknown'),
            "host": node.get('host'),
            "port": node.get('port'),
            "country": node.get('country', 'UNK'),
            "speed": node.get('speed', 0),
            "name": node.get('name', f"{node.get('host')}:{node.get('port')}"),
            "link": share_link
        })

    return export_list

# ==========================================
# ğŸ”¥ æ–°å¢ï¼šé€šè¿‡ /api/nodes æš´éœ²èŠ‚ç‚¹æ•°æ®ä¾›å‰ç«¯ä½¿ç”¨
# ==========================================
@router.get("/api/nodes")
async def get_api_nodes(limit: int = Query(50, ge=1, le=500)):
    """
    ä¾›å‰ç«¯ç›´æ¥è°ƒç”¨çš„èŠ‚ç‚¹æ•°æ®æ¥å£
    è¿”å›æ ¼å¼ä¸ /export_raw å…¼å®¹ï¼ŒåŒ…å« mainland_score/overseas_score ç­‰å­—æ®µ
    """
    alive_nodes = hunter.get_alive_nodes()
    
    # æŒ‰åˆ†æ•°æ’åºï¼ˆä¼˜å…ˆå¤§é™†åˆ†æ•°ï¼Œå…¶æ¬¡æµ·å¤–åˆ†æ•°ï¼‰
    sorted_nodes = sorted(
        alive_nodes,
        key=lambda x: (
            -(x.get('mainland_score', 0) or 0),
            -(x.get('overseas_score', 0) or 0)
        )
    )
    
    # é™åˆ¶è¿”å›æ•°é‡
    limited_nodes = sorted_nodes[:limit]
    
    # æ„é€ è¿”å›æ•°æ®
    result = []
    for node in limited_nodes:
        # ç”ŸæˆèŠ‚ç‚¹åˆ†äº«é“¾æ¥
        share_link = generate_node_share_link(node)
        
        result.append({
            "id": node.get('id', f"{node.get('host')}:{node.get('port')}"),
            "protocol": node.get('protocol', 'unknown'),
            "host": node.get('host'),
            "port": node.get('port'),
            "country": node.get('country', 'UNK'),
            "speed": node.get('speed', 0),
            "delay": node.get('delay', 0),
            "name": node.get('name', f"{node.get('host')}:{node.get('port')}"),
            "link": share_link,
            # æ–°å¢ï¼šåŒåŒºåŸŸæµ‹é€Ÿå­—æ®µ
            "mainland_score": node.get('mainland_score', 0),
            "mainland_latency": node.get('mainland_latency', 0),
            "overseas_score": node.get('overseas_score', 0),
            "overseas_latency": node.get('overseas_latency', 0),
            "alive": node.get('alive', False)
        })
    
    return result


# ==================== äº‘ç«¯æ£€æµ‹å‡½æ•° ====================

async def test_nodes_via_cloud(nodes: List[Dict], service_url: str, service_name: str) -> List[Dict]:
    """
    é€šè¿‡äº‘ç«¯æœåŠ¡æ£€æµ‹èŠ‚ç‚¹å¯ç”¨æ€§

    Args:
        nodes: èŠ‚ç‚¹åˆ—è¡¨
        service_url: äº‘ç«¯æœåŠ¡URL
        service_name: æœåŠ¡åç§° (ç”¨äºæ—¥å¿—)

    Returns:
        æ£€æµ‹ç»“æœåˆ—è¡¨
    """
    if not service_url:
        logger.warning(f"âš ï¸ {service_name} URL æœªè®¾ç½®ï¼Œè·³è¿‡äº‘ç«¯æ£€æµ‹")
        return []

    if not nodes:
        return []

    logger.info(f"ğŸŒ [{service_name}] å¼€å§‹äº‘ç«¯æ£€æµ‹ {len(nodes)} ä¸ªèŠ‚ç‚¹...")

    try:
        # å‡†å¤‡è¯·æ±‚æ•°æ®
        request_data = {"nodes": nodes}

        # å‘é€è¯·æ±‚åˆ°äº‘ç«¯æœåŠ¡
        timeout = aiohttp.ClientTimeout(total=60)  # 60ç§’è¶…æ—¶
        async with aiohttp.ClientSession(timeout=timeout) as session:
            async with session.post(service_url, json=request_data) as response:
                if response.status == 200:
                    result = await response.json()
                    cloud_results = result.get('results', [])

                    logger.info(f"âœ… [{service_name}] äº‘ç«¯æ£€æµ‹å®Œæˆï¼Œè¿”å› {len(cloud_results)} ä¸ªç»“æœ")

                    # ä¸ºç»“æœæ·»åŠ æ¥æºæ ‡è®°
                    for r in cloud_results:
                        r['test_via'] = service_name.lower()

                    return cloud_results
                else:
                    error_text = await response.text()
                    logger.error(f"âŒ [{service_name}] äº‘ç«¯æ£€æµ‹å¤±è´¥ {response.status}: {error_text[:200]}")
                    return []

    except Exception as e:
        logger.error(f"âŒ [{service_name}] äº‘ç«¯æ£€æµ‹å¼‚å¸¸: {str(e)}")
        return []


async def test_nodes_via_aliyun_fc(nodes: List[Dict]) -> List[Dict]:
    """é€šè¿‡é˜¿é‡Œäº‘FCæ£€æµ‹èŠ‚ç‚¹"""
    return await test_nodes_via_cloud(nodes, ALIYUN_FC_URL, "Aliyun FC")


async def test_nodes_via_cloudflare_worker(nodes: List[Dict]) -> List[Dict]:
    """é€šè¿‡Cloudflare Workeræ£€æµ‹èŠ‚ç‚¹"""
    return await test_nodes_via_cloud(nodes, CF_WORKER_URL, "Cloudflare Worker")


async def merge_cloud_detection_results(local_results: List[Dict], cloud_results: List[Dict], cloud_service: str) -> List[Dict]:
    """
    åˆå¹¶æœ¬åœ°æ£€æµ‹ç»“æœå’Œäº‘ç«¯æ£€æµ‹ç»“æœ

    Args:
        local_results: æœ¬åœ°æ£€æµ‹ç»“æœ
        cloud_results: äº‘ç«¯æ£€æµ‹ç»“æœ
        cloud_service: äº‘ç«¯æœåŠ¡åç§°

    Returns:
        åˆå¹¶åçš„ç»“æœ
    """
    # åˆ›å»ºä»¥èŠ‚ç‚¹IDä¸ºé”®çš„æ˜ å°„
    cloud_map = {r.get('id'): r for r in cloud_results}

    merged_results = []

    for local_result in local_results:
        node_id = local_result.get('id', f"{local_result.get('host')}:{local_result.get('port')}")
        cloud_result = cloud_map.get(node_id)

        if cloud_result:
            # åˆå¹¶äº‘ç«¯æ£€æµ‹ç»“æœ
            merged_result = local_result.copy()

            # æ·»åŠ äº‘ç«¯æ£€æµ‹æ•°æ®
            if cloud_service == "aliyun_fc":
                merged_result['mainland_score'] = cloud_result.get('success', False)
                merged_result['mainland_latency'] = cloud_result.get('latency', 0)
                merged_result['test_via'] = 'aliyun'
            elif cloud_service == "cloudflare":
                merged_result['overseas_score'] = cloud_result.get('success', False)
                merged_result['overseas_latency'] = cloud_result.get('latency', 0)
                merged_result['test_via'] = 'cloudflare'

            # å¦‚æœäº‘ç«¯æ£€æµ‹å¤±è´¥ï¼Œæœ¬åœ°æ£€æµ‹æˆåŠŸï¼Œåˆ™ä¿æŒæœ¬åœ°ç»“æœ
            if not cloud_result.get('success', False) and local_result.get('alive', False):
                merged_result['alive'] = True

            merged_results.append(merged_result)
            logger.debug(f"     ğŸ”„ {node_id} åˆå¹¶{cloud_service}ç»“æœ: äº‘ç«¯={cloud_result.get('success')}, æœ¬åœ°={local_result.get('alive')}")
        else:
            # æ²¡æœ‰äº‘ç«¯ç»“æœï¼Œä½¿ç”¨æœ¬åœ°ç»“æœ
            merged_results.append(local_result)

    return merged_results