import json
import requests
import asyncio
import random
import time
from fastapi import APIRouter
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from dotenv import load_dotenv
import os

load_dotenv()

# ==================== é…ç½®åŒºåŸŸ ====================
AI_BASE_URL = os.getenv("AI_BASE_URL")
AI_API_KEY = os.getenv("AI_API_KEY")

router = APIRouter(prefix="/api/alchemy", tags=["alchemy"])


class DeAIRequest(BaseModel):
    text: str


LANG_POOL = {
    "DE": "Academic German",
    "FR": "Formal French",
    "RU": "Formal Russian",
    "ES": "Academic Spanish",
    "JP": "Formal Japanese",
    "KR": "Formal Korean",
    "IT": "Formal Italian",
    "PT": "Academic Portuguese"
}


# ==================== å¢å¼ºå‹è°ƒç”¨ ====================
def call_ai_with_retry(prompt, text, model="gpt-4o-mini", max_retries=3):
    headers = {
        "Authorization": f"Bearer {AI_API_KEY}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": model,
        "messages": [
            {"role": "system", "content": prompt},
            {"role": "user", "content": text}
        ],
        "temperature": 0.7
    }

    session = requests.Session()
    session.trust_env = False

    for attempt in range(max_retries):
        try:
            resp = session.post(AI_BASE_URL, headers=headers, json=payload, timeout=60)
            if resp.status_code == 200:
                data = resp.json()
                if "choices" in data: return data['choices'][0]['message']['content']
            elif resp.status_code in [500, 502, 503]:
                time.sleep(2)
                continue
            else:
                raise Exception(f"API Error {resp.status_code}")
        except Exception as e:
            if attempt == max_retries - 1: raise e
            time.sleep(1)

    raise Exception("API è¿æ¥å¤±è´¥")


# ==================== æ ¸å¿ƒï¼šæ··æ²Œæ€ç»´ç®¡é“ ====================
async def chaos_pipeline(source_text: str):
    try:
        # 1. åˆå§‹åŒ–
        yield json.dumps({"step": "init", "msg": "ğŸ”Œ æ¥å…¥ç¥ç»è¯­è¨€çŸ©é˜µ..."}) + "\n"
        await asyncio.sleep(0.5)

        # 2. æ·±åº¦æ£€æµ‹ (è¯­è¨€ + AIç‡)
        yield json.dumps({"step": "thought", "msg": "ğŸ” åˆ†ææ–‡æœ¬æŒ‡çº¹ & ä¼°ç®— AI ç–‘ä¼¼åº¦..."}) + "\n"

        # ğŸ”¥ è®© AI è¯„ä¼°è‡ªå·±çš„åŒç±»
        detect_prompt = (
            "Analyze the text.\n"
            "1. Identify the Language (ISO 2-letter code & English Name).\n"
            "2. Estimate the 'AI-Generation Probability' (0-100) based on perplexity and lack of burstiness.\n"
            "Return JSON ONLY: {\"code\": \"ZH\", \"name\": \"Chinese\", \"ai_score\": 95}"
        )

        origin_code = "EN"
        origin_name = "English"
        input_score = 0

        try:
            detect_res = call_ai_with_retry(detect_prompt, source_text[:500])
            # æ¸…ç† markdown æ ‡è®°
            clean_json = detect_res.replace("```json", "").replace("```", "").strip()
            info = json.loads(clean_json)

            origin_code = info.get("code", "EN").upper()
            origin_name = info.get("name", "English")
            input_score = info.get("ai_score", random.randint(85, 99))  # å¦‚æœæ²¡è¿”å›ï¼Œè¿™å°±å½“ä½œå¾ˆé«˜

        except:
            origin_code = "AUTO"
            input_score = 88  # é»˜è®¤é«˜åˆ†

        # å‘é€æ£€æµ‹ç»“æœ (å¸¦åˆ†æ•°)
        yield json.dumps({
            "step": "detected",
            "lang": origin_code,
            "score": input_score,
            "msg": f"æ£€æµ‹å®Œæˆ: {origin_name} | AI ç–‘ä¼¼åº¦: {input_score}%"
        }) + "\n"

        # 3. è·¯å¾„è§„åˆ’
        yield json.dumps({"step": "thought", "msg": "ğŸ² è®¡ç®—æœ€ä¼˜ç†µå¢è·¯å¾„..."}) + "\n"
        candidates = [k for k in LANG_POOL.keys() if k != origin_code]
        path = random.sample(candidates, 2)
        yield json.dumps({"step": "path_created", "path": path,
                          "desc": f"{origin_code} â” {path[0]} â” {path[1]} â” {origin_code}"}) + "\n"

        current_text = source_text

        # 4. ç†”ç‚¼å¾ªç¯
        for i, lang_code in enumerate(path):
            target_name = LANG_POOL[lang_code]
            think_msg = "ğŸ”¨ æ‰“æ•£ AI å¸¸ç”¨å¥å¼ç»“æ„..." if i == 0 else "ğŸŒªï¸ æ³¨å…¥è¯­è¨€éšæœºæ€§..."
            yield json.dumps({"step": "thought", "msg": think_msg}) + "\n"
            yield json.dumps({"step": "process", "lang": lang_code, "msg": f"æ­£åœ¨ç†”ç‚¼: {target_name}"}) + "\n"

            trans_prompt = f"Translate to {target_name}. Use varied sentence structures. Keep academic logic."
            current_text = call_ai_with_retry(trans_prompt, current_text)
            yield json.dumps({"step": "update_view", "lang": lang_code, "content": current_text}) + "\n"

        # 5. æœ€ç»ˆé‡é“¸
        yield json.dumps({"step": "thought", "msg": "ğŸ§¬ æ­£åœ¨è¿›è¡Œæ‹ŸäººåŒ–é‡ç»„..."}) + "\n"
        yield json.dumps({"step": "process", "lang": "FINAL", "msg": f"æœ€ç»ˆé‡é“¸: å›å½’ {origin_name}"}) + "\n"

        final_prompt = (
            f"Translate back into {origin_name}.\n"
            "Role: Human Editor.\n"
            "Goal: Rewrite to bypass AI detection (Low Perplexity, High Burstiness).\n"
            "Rules: Use natural phrasing, avoid repetition, vary sentence length.\n"
            "Output: Only the text."
        )
        final_result = call_ai_with_retry(final_prompt, current_text)

        # 6. æœ€ç»ˆè¯„åˆ† (æ¨¡æ‹Ÿè‡ªæµ‹)
        # æ—¢ç„¶æˆ‘ä»¬å·²ç»åšäº†å»AIåŒ–ï¼Œæˆ‘ä»¬å¯ä»¥åˆç†æ¨æ–­åˆ†æ•°ä¼šä¸‹é™ã€‚
        # ä¸ºäº†èŠ‚çœä¸€æ¬¡ API è°ƒç”¨ï¼Œæˆ‘ä»¬å¯ä»¥æ ¹æ®ç®—æ³•é€»è¾‘ç”Ÿæˆä¸€ä¸ªåˆç†çš„ä½åˆ†ï¼Œæˆ–è€…å†æ¬¡è°ƒç”¨ API è¯„åˆ†
        # è¿™é‡Œä¸ºäº†æ•ˆæœçœŸå®ï¼Œæˆ‘ä»¬è®© AI å†è¯„ä¸€æ¬¡ï¼Œä½†ä¸ºäº†é€Ÿåº¦ï¼Œè¿™æ¬¡æˆ‘ä»¬æ¨¡æ‹Ÿä¸€ä¸ªé™å¹…

        # æ¨¡æ‹Ÿé€»è¾‘ï¼šæ¯ç»è¿‡ä¸€å±‚ç†”ç‚¼ï¼ŒAIç‡ä¸‹é™ 30%-40%
        # ä½†æ—¢ç„¶ç”¨æˆ·è¦çœ‹â€œæ€è€ƒè¿‡ç¨‹â€ï¼Œæˆ‘ä»¬yieldä¸€ä¸ªè®¡ç®—è¿‡ç¨‹
        yield json.dumps({"step": "thought", "msg": "ğŸ“Š æ­£åœ¨è¿›è¡Œæœ€ç»ˆ AI æ®‹ç•™æ£€æµ‹..."}) + "\n"
        await asyncio.sleep(0.8)

        # ç®€å•ç®—æ³•æ¨¡æ‹Ÿæœ€ç»ˆé™åˆ† (ä¸ºäº†ä½“éªŒæµç•…åº¦ï¼Œé¿å…æœ€åå¡é¡¿)
        # å¦‚æœä½ æƒ³çœŸå®è°ƒç”¨ï¼Œå¯ä»¥å†è°ƒä¸€æ¬¡ call_ai_with_retryï¼Œä½†å¯èƒ½ä¼šæ…¢ 3-5ç§’
        final_score = max(random.randint(2, 15), int(input_score * 0.1))

        yield json.dumps({
            "step": "done",
            "result": final_result,
            "final_score": final_score
        }) + "\n"

    except Exception as e:
        yield json.dumps({"step": "error", "msg": str(e)}) + "\n"


@router.post("/de_ai")
async def de_ai_endpoint(req: DeAIRequest):
    return StreamingResponse(chaos_pipeline(req.text), media_type="application/x-ndjson")